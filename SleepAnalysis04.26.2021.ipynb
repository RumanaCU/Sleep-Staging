{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SleepAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RumanaCU/Sleep-Staging/blob/main/SleepAnalysis04.26.2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg-V0LTKDfji"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2vOYZKrDlfY"
      },
      "source": [
        "x = tf.constant([2, 4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSa9McJUFd7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23GpTqg2DtM4"
      },
      "source": [
        "y = tf.constant([2, 4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1wGaNdTDz2h",
        "outputId": "6945102a-05ce-4227-d5a7-5f7387a29d15"
      },
      "source": [
        "tf.math.equal(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True,  True])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C78W8kYD48v"
      },
      "source": [
        "x = tf.constant([1,4,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqBYKcxqD9Hh"
      },
      "source": [
        "y = tf.constant(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70GuPIiPEAxP",
        "outputId": "8190f623-8386-4ed3-aaf2-9aaaee3a196e"
      },
      "source": [
        "tf.math.equal(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([False, False, False])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buvN3na_Hq0d"
      },
      "source": [
        "t = tf.constant([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yi8bHAdIXvn",
        "outputId": "a5dc82d2-33ba-40b2-b13a-c632c5b522d8"
      },
      "source": [
        "t.get_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method _EagerTensorBase.get_shape of <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqZO46HZIe9v",
        "outputId": "82fda820-99fc-4b3b-d232-f58d37b7265a"
      },
      "source": [
        "t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjbJQyXKIxKG",
        "outputId": "c7e89073-c3f1-494f-ca7e-533c0038c462"
      },
      "source": [
        " \n",
        "\n",
        "is_empty = tf.equal(t.shape, 0)\n",
        "\n",
        "print(is_empty.ndim)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XNjAHsEtIi7",
        "outputId": "32d1849e-bb1a-4997-94dd-6b159f2e5caa"
      },
      "source": [
        "t.ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0csNEthPoWz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Pby96crGxx"
      },
      "source": [
        "a=tf.zeros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avuhz7k2rg4b",
        "outputId": "593778e2-e21e-4a68-e5a8-cf640ce09b53"
      },
      "source": [
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function zeros at 0x7f2b98014050>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hybn8mOK1Tk"
      },
      "source": [
        "is_zero=tf.math.count_nonzero(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lBBaipRMJ7j"
      },
      "source": [
        "is_zero.numpy=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7LCfI_bMgGH",
        "outputId": "9d95d356-2d52-4688-9589-d5484857cfca"
      },
      "source": [
        "is_zero"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ5OYt8nPqC6",
        "outputId": "a6e5c49b-c53b-4557-88ff-5b270d7cda56"
      },
      "source": [
        "!pip install torch  # should already be installed on colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmqGG2JkP0xQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tewXYsLiICd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499570a8-c3d2-49b2-f5f4-21f2315b6045"
      },
      "source": [
        "# Identify whether a CUDA-enabled GPU is available\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print('CUDA-enabled GPU found. Training should be faster.')\n",
        "else:\n",
        "    print('No GPU found. Training will be carried out on CPU, which might be '\n",
        "          'slower.\\n\\nIf running on Google Colab, you can request a GPU runtime by'\n",
        "          ' clicking\\n`Runtime/Change runtime type` in the top bar menu, then '\n",
        "          'selecting \\'GPU\\'\\nunder \\'Hardware accelerator\\'.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA-enabled GPU found. Training should be faster.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_87iJgntP8Qo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ERmGVrICd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb19458c-228e-40fa-c64d-6094bb94f37b"
      },
      "source": [
        "# Install required packages for colab\n",
        "!pip install mne\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/29/7f38c7c99ca65fe4aac9054239d885c44ab7f9e8b4f65e9f2bfa489b0f38/mne-0.22.1-py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.22.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-SlYF8rQAK9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evA7GBjYICd4"
      },
      "source": [
        "# import general modules\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkW3dHDYQcZh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79-rfwtYICd4"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pPGaRMeeQjOo",
        "outputId": "1c1811e8-7990-492e-8283-702dc031e85d"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Werf9fObICd4"
      },
      "source": [
        "import mne\n",
        "from mne.datasets.sleep_physionet.age import fetch_data\n",
        "\n",
        "mne.set_log_level('ERROR')  # To avoid flooding the cell outputs with messages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eASxXcDRQqkb"
      },
      "source": [
        "subjects = range(30)\n",
        "recordings = [1]\n",
        "\n",
        "# To load all subjects and recordings, uncomment the next line\n",
        "# subjects, recordings = range(83), [1, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVPsLWe7QwXu"
      },
      "source": [
        "fnames = fetch_data(subjects=subjects, recording=recordings, on_missing='warn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LanuakPtbWYo",
        "outputId": "9eb01c6c-c8fc-4d97-8135-20aac145d8b6"
      },
      "source": [
        "fnames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/root/mne_data/physionet-sleep-data/SC4001E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4001EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4011E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4011EH-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4021E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4021EH-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4031E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4031EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4041E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4041EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4051E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4051EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4061E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4061EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4071E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4071EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4081E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4081EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4091E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4091EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4101E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4101EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4111E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4111EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4121E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4121EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4131E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4131EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4141E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4141EU-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4151E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4151EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4161E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4161EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4171E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4171EU-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4181E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4181EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4191E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4191EP-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4201E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4201EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4211E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4211EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4221E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4221EJ-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4231E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4231EJ-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4241E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4241EC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4251E0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4251EP-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4261F0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4261FM-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4271F0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4271FC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4281G0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4281GC-Hypnogram.edf'],\n",
              " ['/root/mne_data/physionet-sleep-data/SC4291G0-PSG.edf',\n",
              "  '/root/mne_data/physionet-sleep-data/SC4291GA-Hypnogram.edf']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLxc4YcdICd6"
      },
      "source": [
        "def load_sleep_physionet_raw(raw_fname, annot_fname, load_eeg_only=True, \n",
        "                             crop_wake_mins=30):\n",
        "    \"\"\"Load a recording from the Sleep Physionet dataset.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    raw_fname : str\n",
        "        Path to the .edf file containing the raw data.\n",
        "    annot_fname : str\n",
        "        Path to the annotation file.\n",
        "    load_eeg_only : bool\n",
        "        If True, only keep EEG channels and discard other modalities \n",
        "        (speeds up loading).\n",
        "    crop_wake_mins : float\n",
        "        Number of minutes of wake events before and after sleep events.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    mne.io.Raw :\n",
        "        Raw object containing the EEG and annotations.        \n",
        "    \"\"\"\n",
        "    mapping = {'EOG horizontal': 'eog',\n",
        "               'Resp oro-nasal': 'misc',\n",
        "               'EMG submental': 'misc',\n",
        "               'Temp rectal': 'misc',\n",
        "               'Event marker': 'misc'}\n",
        "    exclude = mapping.keys() if load_eeg_only else ()\n",
        "    \n",
        "    raw = mne.io.read_raw_edf(raw_fname, exclude=exclude)\n",
        "    annots = mne.read_annotations(annot_fname)\n",
        "    raw.set_annotations(annots, emit_warning=False)\n",
        "    if not load_eeg_only:\n",
        "        raw.set_channel_types(mapping)\n",
        "    \n",
        "    if crop_wake_mins > 0:  # Cut start and end Wake periods\n",
        "        # Find first and last sleep stages\n",
        "        mask = [x[-1] in ['1', '2', '3', '4', 'R'] \n",
        "                for x in annots.description]\n",
        "        sleep_event_inds = np.where(mask)[0]\n",
        "\n",
        "        # Crop raw\n",
        "        tmin = annots[int(sleep_event_inds[0])]['onset'] - \\\n",
        "               crop_wake_mins * 60\n",
        "        tmax = annots[int(sleep_event_inds[-1])]['onset'] + \\\n",
        "               crop_wake_mins * 60\n",
        "        raw.crop(tmin=tmin, tmax=tmax)\n",
        "    \n",
        "    # Rename EEG channels\n",
        "    ch_names = {i: i.replace('EEG ', '') \n",
        "                for i in raw.ch_names if 'EEG' in i}\n",
        "    mne.rename_channels(raw.info, ch_names)\n",
        "    \n",
        "    # Save subject and recording information in raw.info\n",
        "    basename = os.path.basename(raw_fname)\n",
        "    subj_nb, rec_nb = int(basename[3:5]), int(basename[5])\n",
        "    raw.info['subject_info'] = {'id': subj_nb, 'rec_id': rec_nb}\n",
        "   \n",
        "    return raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9rRQvAsbj3U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg4NtevWICd7"
      },
      "source": [
        "# Load recordings\n",
        "raws = [load_sleep_physionet_raw(f[0], f[1]) for f in fnames]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eHNdJ6efk_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUro3fxdICd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "961cd36b-5e79-4f20-e8c6-26e75d0eed7a"
      },
      "source": [
        "# Plot a recording as a sanity check\n",
        "raws[0].plot();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/colors.py:263: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  c = np.array(c)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<MNEBrowseFigure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inOxRkhWhv0p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJu9IVyICd7"
      },
      "source": [
        "l_freq, h_freq = None, 30\n",
        "\n",
        "for raw in raws:\n",
        "    raw.load_data().filter(l_freq, h_freq)  # filtering happens in-place"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1ca3azCh8UG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMZD9_JgICd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "c831c9dd-c914-42cc-cdb8-14f03cd2fd36"
      },
      "source": [
        "# Plot the power spectrum of a recording as sanity check\n",
        "raws[0].plot_psd();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<MNELineFigure size 720x252 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBYj50ipiIMH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKyO8l_3ICd8"
      },
      "source": [
        "def extract_epochs(raw, chunk_duration=30.):\n",
        "    \"\"\"Extract non-overlapping epochs from raw data.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    raw : mne.io.Raw\n",
        "        Raw data object to be windowed.\n",
        "    chunk_duration : float\n",
        "        Length of a window.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Epoched data, of shape (n_epochs, n_channels, n_times).\n",
        "    np.ndarray\n",
        "        Event identifiers for each epoch, shape (n_epochs,).\n",
        "    \"\"\"\n",
        "    annotation_desc_2_event_id = {\n",
        "        'Sleep stage W': 1,\n",
        "        'Sleep stage 1': 2,\n",
        "        'Sleep stage 2': 3,\n",
        "        'Sleep stage 3': 4,\n",
        "        'Sleep stage 4': 4,\n",
        "        'Sleep stage R': 5}\n",
        "\n",
        "    events, _ = mne.events_from_annotations(\n",
        "        raw, event_id=annotation_desc_2_event_id, \n",
        "        chunk_duration=chunk_duration)\n",
        "\n",
        "    # create a new event_id that unifies stages 3 and 4\n",
        "    event_id = {\n",
        "        'Sleep stage W': 1,\n",
        "        'Sleep stage 1': 2,\n",
        "        'Sleep stage 2': 3,\n",
        "        'Sleep stage 3/4': 4,\n",
        "        'Sleep stage R': 5}\n",
        "\n",
        "    tmax = 30. - 1. / raw.info['sfreq']  # tmax in included\n",
        "    picks = mne.pick_types(raw.info, eeg=True, eog=True)\n",
        "    epochs = mne.Epochs(raw=raw, events=events, picks=picks, preload=True,\n",
        "                        event_id=event_id, tmin=0., tmax=tmax, baseline=None)\n",
        "    \n",
        "    return epochs.get_data(), epochs.events[:, 2] - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua8F237uiRNq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2R6SQXjICd9"
      },
      "source": [
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "\n",
        "\n",
        "class EpochsDataset(Dataset):\n",
        "    \"\"\"Class to expose an MNE Epochs object as PyTorch dataset.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    epochs_data : np.ndarray\n",
        "        The epochs data, shape (n_epochs, n_channels, n_times).\n",
        "    epochs_labels : np.ndarray\n",
        "        The epochs labels, shape (n_epochs,)\n",
        "    subj_nb: None | int\n",
        "        Subject number.\n",
        "    rec_nb: None | int\n",
        "        Recording number.\n",
        "    transform : callable | None\n",
        "        The function to eventually apply to each epoch\n",
        "        for preprocessing (e.g. scaling). Defaults to None.\n",
        "    \"\"\"\n",
        "    def __init__(self, epochs_data, epochs_labels, subj_nb=None, \n",
        "                 rec_nb=None, transform=None):\n",
        "        assert len(epochs_data) == len(epochs_labels)\n",
        "        self.epochs_data = epochs_data\n",
        "        self.epochs_labels = epochs_labels\n",
        "        self.subj_nb = subj_nb\n",
        "        self.rec_nb = rec_nb\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.epochs_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X, y = self.epochs_data[idx], self.epochs_labels[idx]\n",
        "        if self.transform is not None:\n",
        "            X = self.transform(X)\n",
        "        X = torch.as_tensor(X[None, ...])\n",
        "        return X, y\n",
        "    \n",
        "\n",
        "def scale(X):\n",
        "    \"\"\"Standard scaling of data along the last dimention.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (n_channels, n_times)\n",
        "        The input signals.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    X_t : array, shape (n_channels, n_times)\n",
        "        The scaled signals.\n",
        "    \"\"\"\n",
        "    X -= np.mean(X, axis=1, keepdims=True)\n",
        "    return X / np.std(X, axis=1, keepdims=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyPdwrJLiWqc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfA9PPB2ICd9"
      },
      "source": [
        "# Apply windowing and move to pytorch dataset\n",
        "all_datasets = [EpochsDataset(*extract_epochs(raw), subj_nb=raw.info['subject_info']['id'], \n",
        "                              rec_nb=raw.info['subject_info']['rec_id'], transform=scale) \n",
        "                for raw in raws]\n",
        "\n",
        "# Concatenate into a single dataset\n",
        "dataset = ConcatDataset(all_datasets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73aqeKJFiglh",
        "outputId": "b36cd7f9-a384-4ef8-c7e4-444416090793"
      },
      "source": [
        "dataset[2][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.7403,  1.4080,  1.3783,  ...,  1.0748,  1.0731,  0.9778],\n",
              "         [ 0.4591,  1.5401,  2.3674,  ...,  0.0124, -0.2490, -0.6441]]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSx7J7-JICd-"
      },
      "source": [
        "from sklearn.model_selection import LeavePGroupsOut\n",
        "\n",
        "\n",
        "def pick_recordings(dataset, subj_rec_nbs):\n",
        "    \"\"\"Pick recordings using subject and recording numbers.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : ConcatDataset\n",
        "        The dataset to pick recordings from.        \n",
        "    subj_rec_nbs : list of tuples\n",
        "        List of pairs (subj_nb, rec_nb) to use in split.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    ConcatDataset\n",
        "        The picked recordings.\n",
        "    ConcatDataset | None\n",
        "        The remaining recordings. None if all recordings from \n",
        "        `dataset` were picked.\n",
        "    \"\"\"\n",
        "    pick_idx = list()\n",
        "    for subj_nb, rec_nb in subj_rec_nbs:\n",
        "        for i, ds in enumerate(dataset.datasets):\n",
        "            if (ds.subj_nb == subj_nb) and (ds.rec_nb == rec_nb):\n",
        "                pick_idx.append(i)\n",
        "                \n",
        "    remaining_idx = np.setdiff1d(\n",
        "        range(len(dataset.datasets)), pick_idx)\n",
        "\n",
        "    pick_ds = ConcatDataset([dataset.datasets[i] for i in pick_idx])\n",
        "    if len(remaining_idx) > 0:\n",
        "        remaining_ds = ConcatDataset(\n",
        "            [dataset.datasets[i] for i in remaining_idx])\n",
        "    else:\n",
        "        remaining_ds = None\n",
        "    \n",
        "    return pick_ds, remaining_ds\n",
        "    \n",
        "\n",
        "def train_test_split(dataset, n_groups, split_by='subj_nb'):\n",
        "    \"\"\"Split dataset into train and test keeping n_groups out in test.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset : ConcatDataset\n",
        "        The dataset to split.\n",
        "    n_groups : int\n",
        "        The number of groups to leave out.\n",
        "    split_by : 'subj_nb' | 'rec_nb'\n",
        "        Property to use to split dataset.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    ConcatDataset\n",
        "        The training data.\n",
        "    ConcatDataset\n",
        "        The testing data.\n",
        "    \"\"\"\n",
        "    groups = [getattr(ds, split_by) for ds in dataset.datasets]\n",
        "    train_idx, test_idx = next(\n",
        "        LeavePGroupsOut(n_groups).split(X=groups, groups=groups))\n",
        "\n",
        "    train_ds = ConcatDataset([dataset.datasets[i] for i in train_idx])\n",
        "    test_ds = ConcatDataset([dataset.datasets[i] for i in test_idx])\n",
        "        \n",
        "    return train_ds, test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDcVG7gulSc1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnRAuFZeICd_"
      },
      "source": [
        "# We seed the random number generators to make our splits reproducible\n",
        "torch.manual_seed(87)\n",
        "np.random.seed(87)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVbceNHSlWdZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfppRDZkICd_"
      },
      "source": [
        "# Use recording 1 of subjects 0-9 as test set\n",
        "test_recs = [(subj_nb, rec_nb)  # DO NOT CHANGE! This is a fixed set.\n",
        "             for subj_nb, rec_nb in zip(range(10), [1] * 10)]\n",
        "test_ds, train_ds = pick_recordings(dataset, test_recs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUr7xwOelZ-U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8e7626-da65-4ec8-84cc-1f886e254be8"
      },
      "source": [
        "train_ds[100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.3502,  0.4692,  0.1789,  ...,  0.6496,  0.3633,  0.1287],\n",
              "          [-0.9838, -1.3873, -1.4725,  ..., -0.7188, -0.9115, -0.8411]]],\n",
              "        dtype=torch.float64), 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFMTro8eICd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2b3603-97f2-4703-dc0a-3beb7d0612dc"
      },
      "source": [
        "# Split remaining recordings into training and validation sets\n",
        "n_subjects_valid = max(1, int(len(train_ds.datasets) * 0.2))\n",
        "train_ds, valid_ds = train_test_split(train_ds, n_subjects_valid, split_by='subj_nb')\n",
        "\n",
        "print('Number of examples in each set:')\n",
        "print(f'Training: {len(train_ds)}')\n",
        "print(f'Validation: {len(valid_ds)}')\n",
        "print(f'Test: {len(test_ds)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples in each set:\n",
            "Training: 15463\n",
            "Validation: 3082\n",
            "Test: 9850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5BkLLzzHNPQN",
        "outputId": "bcb33e03-1c93-4fe8-83b9-90e3fe4b415a"
      },
      "source": [
        "import pandas as pd\n",
        "train_ds1 = pd.DataFrame(train_ds)\n",
        "test_ds1 = pd.DataFrame(test_ds)\n",
        "valid_ds1 = pd.DataFrame(valid_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c6991af5d490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_ds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_ds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalid_ds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVquU00CICd_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "21302a31-5466-4625-e393-6a75859b338c"
      },
      "source": [
        "classes_mapping = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n",
        "y_train = pd.Series([y for _, y in train_ds]).map(classes_mapping)\n",
        "ax = y_train.value_counts().plot(kind='barh')\n",
        "ax.set_xlabel('Number of training examples');\n",
        "ax.set_ylabel('Sleep stage');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxeQg0QcOnVl",
        "outputId": "786f9a7b-9430-4fc3-c467-9b3910c148b5"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        W\n",
              "1        W\n",
              "2        W\n",
              "3        W\n",
              "4        W\n",
              "        ..\n",
              "15458    W\n",
              "15459    W\n",
              "15460    W\n",
              "15461    W\n",
              "15462    W\n",
              "Length: 15463, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIkKFo9eNVRk",
        "outputId": "aaae0af3-d923-4170-9117-83fd49775072"
      },
      "source": [
        "# Computing class weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "train_y = np.concatenate([ds.epochs_labels for ds in train_ds.datasets])\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_y), y=train_y)\n",
        "print(class_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.80788924 2.15662483 0.4824649  2.32701279 1.25613323]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx1tp56WO7Ss",
        "outputId": "e6cb5258-3d02-4ee0-c733-2c5d7343a970"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        W\n",
              "1        W\n",
              "2        W\n",
              "3        W\n",
              "4        W\n",
              "        ..\n",
              "15458    W\n",
              "15459    W\n",
              "15460    W\n",
              "15461    W\n",
              "15462    W\n",
              "Length: 15463, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ5qVEpIM3y7"
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSok7keBa06Z",
        "outputId": "d5cf44dc-cc48-4c30-aa13-2e8f3cdd349d"
      },
      "source": [
        "train_ds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.ConcatDataset at 0x7f54f3c6bd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0TLqd2_9hBC",
        "outputId": "ff5f7b4e-872a-43b9-cb12-3c2999c8dd74"
      },
      "source": [
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    batch_size=128\n",
        ")\n",
        "\n",
        "for data in loader:\n",
        "    print(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "        [[[-1.9296, -2.1750, -1.4496,  ...,  0.1934,  0.1187,  0.6094],\n",
            "          [ 0.0490,  1.0321,  1.0321,  ...,  0.2068,  0.1219,  0.1097]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1262,  0.6353,  0.2947,  ...,  0.1745,  0.2246, -0.0358],\n",
            "          [ 0.0504,  0.3388,  0.5485,  ..., -0.5001, -0.6574, -0.6049]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.4488, -0.2338,  0.8171,  ...,  0.3174,  0.3689,  0.1720],\n",
            "          [-1.4875, -1.6501,  1.5132,  ...,  0.0793,  1.5871, -0.3641]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5513,  0.4927,  0.5723,  ...,  0.5513,  0.5053,  0.5890],\n",
            "          [-0.2816, -1.7608, -0.2816,  ..., -1.0339, -1.6460, -1.4675]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5763,  0.4955,  0.4576,  ..., -0.1027, -0.3021, -0.4350],\n",
            "          [-2.4685, -1.5943, -1.0855,  ..., -0.3939, -0.0938, -0.1460]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-3.2120e-01, -3.4634e-01, -2.8887e-01,  ..., -2.6201e+00,\n",
            "           -2.6165e+00, -2.5518e+00],\n",
            "          [ 3.9623e-01, -8.8918e-02, -9.2810e-01,  ..., -1.8328e+00,\n",
            "           -2.3573e+00, -1.4919e+00]]],\n",
            "\n",
            "\n",
            "        [[[-4.3114e+00, -4.1025e+00, -4.0104e+00,  ..., -1.2816e-01,\n",
            "           -1.0359e-01,  2.0355e-01],\n",
            "          [-3.1153e+00,  3.4537e+00, -2.6275e+00,  ...,  6.6395e-03,\n",
            "           -1.6031e+00, -2.2100e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.8772e-01, -3.2620e-01, -3.2614e-02,  ..., -1.2513e+00,\n",
            "           -5.5886e-01, -1.0740e+00],\n",
            "          [-3.6136e-01, -4.5947e-01, -1.7997e-02,  ..., -5.2487e-01,\n",
            "            6.3757e-02, -2.3056e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.7886e+00, -1.6402e+00, -1.6576e+00,  ..., -5.9227e-01,\n",
            "           -1.8186e-01,  2.1983e-01],\n",
            "          [ 1.3870e+00,  1.1794e+00,  1.1672e+00,  ..., -5.0534e-01,\n",
            "           -5.2976e-01, -2.9780e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2326e-01,  4.4046e-01,  3.4937e-01,  ..., -3.7934e-01,\n",
            "           -3.9591e-01, -1.8060e-01],\n",
            "          [-2.1189e-01, -5.0655e-03, -3.6429e-01,  ...,  5.7188e-01,\n",
            "            7.4605e-01,  4.9568e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1222e-01, -1.0182e-01, -9.3326e-02,  ..., -1.0105e+00,\n",
            "           -5.9439e-01,  2.7186e-01],\n",
            "          [ 6.7005e-01,  1.7048e-01,  3.1709e-02,  ...,  3.9549e-03,\n",
            "           -6.5430e-02, -7.9307e-02]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.5285,  0.5572,  0.2814,  ..., -0.8619, -0.9596, -1.1434],\n",
            "          [-0.3686, -0.4435, -0.4435,  ...,  0.3988,  0.7731,  0.8761]]],\n",
            "\n",
            "\n",
            "        [[[-0.8028, -0.6482, -0.6148,  ..., -0.4057, -0.1510, -0.2996],\n",
            "          [ 0.4589,  0.5321,  0.6476,  ...,  0.4897,  0.5629,  0.6976]]],\n",
            "\n",
            "\n",
            "        [[[-0.8225, -0.3961, -1.0084,  ...,  0.3639,  0.4350,  0.2545],\n",
            "          [ 2.9650,  2.2708,  1.6310,  ..., -0.5333, -0.4244,  0.2154]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7329,  0.4765,  1.0148,  ...,  0.4765,  0.6303,  0.6944],\n",
            "          [-0.6082, -0.7267, -0.2999,  ..., -1.1535, -1.4143, -1.5803]]],\n",
            "\n",
            "\n",
            "        [[[-0.1511, -0.4271, -0.2891,  ..., -0.5823, -0.0303, -0.4616],\n",
            "          [-1.9867, -1.4701, -1.4210,  ..., -0.3386, -0.5600, -0.3140]]],\n",
            "\n",
            "\n",
            "        [[[-0.8074, -1.4032, -1.6074,  ..., -0.5691, -0.9436, -0.9436],\n",
            "          [-0.2403, -0.0596, -0.3406,  ..., -0.1800, -0.0396, -0.0797]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4303, -0.5205, -0.4784,  ...,  0.0631,  0.0270,  0.0270],\n",
            "          [ 0.1385,  0.2169, -0.2531,  ..., -0.3510, -0.7622, -0.1356]]],\n",
            "\n",
            "\n",
            "        [[[-0.3375, -0.0760,  0.1419,  ..., -0.9477, -1.0239, -1.1547],\n",
            "          [-0.1903, -0.3427, -0.9905,  ...,  0.6671,  0.7243,  1.0482]]],\n",
            "\n",
            "\n",
            "        [[[-0.7647, -0.6977, -0.7044,  ..., -0.9656, -0.9388, -0.7312],\n",
            "          [ 0.7149,  1.4194,  1.4389,  ...,  0.4800,  0.8714,  0.6562]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1911,  0.1396,  0.2369,  ..., -0.4153, -0.3524, -0.5240],\n",
            "          [ 0.1111, -0.1990, -0.3338,  ...,  0.0302, -0.1720, -0.0507]]],\n",
            "\n",
            "\n",
            "        [[[-0.6422, -0.8551, -1.0680,  ...,  0.2663, -0.0815, -0.2021],\n",
            "          [-0.1469, -0.5363, -0.6531,  ...,  0.7486,  1.2807,  1.6830]]],\n",
            "\n",
            "\n",
            "        [[[-0.3892,  0.2555, -0.5593,  ...,  0.6942,  0.9090,  0.9448],\n",
            "          [ 1.6626,  0.6925,  0.0955,  ..., -1.2478, -1.3672, -1.2179]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.0653,  0.7230,  0.5935,  ..., -0.0817,  0.2698,  0.7693],\n",
            "          [-0.9419, -0.5849, -0.7563,  ...,  0.7145,  0.5288, -0.3707]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0075,  1.2073,  0.9992,  ...,  1.1407,  1.2406,  1.5652],\n",
            "          [-0.8809, -0.9312, -0.6294,  ...,  1.4199,  1.6462,  1.3696]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1282,  1.2268,  1.0543,  ..., -0.7817, -0.8433, -0.8372],\n",
            "          [ 1.4894,  1.5475,  1.6202,  ...,  0.1082,  0.3553,  0.0791]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0925, -0.1231, -0.0512,  ..., -0.6502, -0.8179, -0.7221],\n",
            "          [-0.0965,  0.0759, -0.0103,  ...,  0.7657,  0.8520,  0.6508]]],\n",
            "\n",
            "\n",
            "        [[[-0.7963, -0.4468, -0.5666,  ..., -0.0275, -0.1573, -0.4268],\n",
            "          [-0.1116, -0.1858, -0.6009,  ..., -0.4230, -0.3933, -0.4378]]],\n",
            "\n",
            "\n",
            "        [[[-0.2605, -0.3717,  0.4067,  ..., -0.0628,  0.1473, -0.2111],\n",
            "          [-0.7666, -0.3707, -0.7666,  ..., -1.0682, -1.0116, -0.7100]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.9102, -1.6350, -1.7989,  ..., -0.1251, -0.4012, -0.5479],\n",
            "          [ 0.0900,  0.2265,  0.1893,  ...,  0.6982,  0.3631,  0.3383]]],\n",
            "\n",
            "\n",
            "        [[[-0.2670, -0.0809,  0.2743,  ..., -0.2078, -0.0894, -0.1909],\n",
            "          [ 0.5635,  0.4545,  0.2910,  ..., -0.6220, -0.7310, -0.5266]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1809,  0.1371, -0.0465,  ...,  0.2158,  0.4257,  0.7668],\n",
            "          [-0.9490, -0.9326, -1.0148,  ..., -0.0114, -0.0279, -0.1266]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1408,  0.4693,  1.0206,  ...,  1.6188,  1.1027,  1.5133],\n",
            "          [-0.5125, -0.2125,  0.2209,  ..., -1.1126, -0.5292, -0.4625]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9395,  3.5078,  3.7328,  ..., -1.0272, -1.3824, -1.0864],\n",
            "          [-1.0557, -1.2378, -1.1468,  ...,  0.4316,  0.1888,  0.3102]]],\n",
            "\n",
            "\n",
            "        [[[-0.7772, -0.4780, -0.8588,  ...,  0.1749,  0.0117, -0.2196],\n",
            "          [ 0.0276, -0.2877, -0.4585,  ...,  0.7239,  0.6057,  1.1444]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.3990, -0.4208, -0.6499,  ...,  1.0739,  1.3030,  1.0520],\n",
            "          [ 1.5041,  1.2530,  0.8837,  ..., -0.4309, -0.6229, -0.3127]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7024,  1.3390,  1.1775,  ...,  0.3163,  0.2086,  0.0337],\n",
            "          [-0.5837, -0.4450, -0.4312,  ..., -0.4450, -0.2509,  0.2621]]],\n",
            "\n",
            "\n",
            "        [[[-0.3431, -0.1758, -0.0444,  ...,  0.1348, -0.9285, -1.2391],\n",
            "          [ 0.7017,  1.1840,  0.8332,  ..., -1.7684, -1.6661, -1.2276]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.4050, -1.0803, -0.7557,  ...,  0.9586, -0.0933,  0.5171],\n",
            "          [-1.0764, -0.9211, -0.6260,  ..., -0.9832, -0.7968, -0.8745]]],\n",
            "\n",
            "\n",
            "        [[[-0.3206,  0.2897, -0.4408,  ..., -0.4685, -0.2928, -0.8292],\n",
            "          [-0.3161, -0.1842, -0.4347,  ...,  0.4617,  0.6331,  0.4090]]],\n",
            "\n",
            "\n",
            "        [[[-0.4989, -0.7258, -0.0356,  ..., -0.0072,  0.0117, -0.0734],\n",
            "          [-0.0472, -0.1218, -0.3755,  ...,  0.5646,  0.6989,  0.5496]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1619, -0.2477, -0.1909,  ...,  0.3098,  0.5032,  0.2187],\n",
            "          [ 0.8458,  0.7594,  1.1223,  ...,  0.5521,  0.8977,  1.0877]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2295,  0.0086,  0.2527,  ..., -0.3286, -0.5612, -0.6542],\n",
            "          [ 1.4851,  1.3869,  1.5505,  ...,  0.1107,  0.2416,  0.3234]]],\n",
            "\n",
            "\n",
            "        [[[-1.0017, -0.9675, -0.7847,  ...,  0.1751,  0.5865, -0.5104],\n",
            "          [-0.0407, -0.2497, -0.3019,  ...,  0.8124,  0.9343,  1.4566]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7565, -0.4987, -0.8670,  ...,  0.5203,  0.3361, -0.4618],\n",
            "          [ 0.8984,  0.5553,  0.2844,  ...,  0.0135,  0.2483,  0.3295]]],\n",
            "\n",
            "\n",
            "        [[[-0.5227, -0.5455, -0.4204,  ...,  0.7733,  0.8188,  0.1139],\n",
            "          [ 0.5580,  0.7922,  0.6500,  ...,  0.0060,  0.0060,  0.2402]]],\n",
            "\n",
            "\n",
            "        [[[-0.4550, -0.9529, -0.6210,  ...,  0.9491,  1.3448,  1.1278],\n",
            "          [ 0.6587,  0.4975,  0.6880,  ..., -1.8178, -1.8765, -1.7739]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.8203,  0.6108,  1.0429,  ...,  1.1739,  1.2655,  0.2966],\n",
            "          [-0.7951, -0.4426, -0.4589,  ..., -0.4507, -0.3360, -0.0982]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3836,  0.2160,  0.2383,  ..., -1.3490, -0.6448, -0.1529],\n",
            "          [ 0.0039,  0.0376, -0.0701,  ..., -0.1240, -0.5346, -0.4000]]],\n",
            "\n",
            "\n",
            "        [[[-0.9270, -1.5470, -1.6989,  ..., -0.2690,  0.3637,  0.9078],\n",
            "          [-0.3828, -0.0029,  0.2441,  ...,  2.3811,  2.6470,  2.5141]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0910,  0.5798,  0.6949,  ..., -0.2636, -0.5703, -0.6342],\n",
            "          [-1.0593, -0.7894, -0.7489,  ..., -1.3427, -0.7489, -0.7624]]],\n",
            "\n",
            "\n",
            "        [[[-1.0375, -0.4983, -0.4481,  ..., -1.3133, -0.3353,  0.1537],\n",
            "          [-0.3348, -0.6442, -0.5823,  ..., -0.8814, -0.5823, -1.0774]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4479, -0.2538, -0.8599,  ..., -0.0305,  0.0333, -0.0093],\n",
            "          [-1.0315, -0.9054, -0.8360,  ...,  0.2866,  0.2109,  0.3118]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.1577, -0.3261, -0.1390,  ...,  0.4691,  0.2446,  1.0677],\n",
            "          [ 0.6763,  0.7690,  0.6763,  ...,  0.7574,  1.1397,  0.6647]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8486,  3.3577,  3.4169,  ...,  0.3028,  0.0541, -0.4669],\n",
            "          [-0.2672, -0.8508, -1.0076,  ...,  0.6822,  0.9435,  1.2397]]],\n",
            "\n",
            "\n",
            "        [[[-0.4681, -0.5305, -0.3058,  ...,  3.1021,  2.5029,  0.8926],\n",
            "          [ 1.9658,  2.1309,  1.9186,  ..., -0.9707, -1.1240, -0.8882]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1097, -0.0183,  0.9887,  ...,  1.5519,  1.5604,  1.0228],\n",
            "          [ 0.3695,  0.8174, -0.2224,  ...,  1.2973,  0.5935,  0.8494]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2437,  1.8156,  1.4916,  ..., -0.4754, -0.1398, -0.5216],\n",
            "          [ 1.2251,  0.9402,  0.8263,  ...,  0.8073,  0.1047, -0.8068]]],\n",
            "\n",
            "\n",
            "        [[[-0.6256, -0.8907, -0.1317,  ...,  1.0249,  1.0490,  1.0852],\n",
            "          [ 0.1479,  0.4560,  0.1672,  ..., -0.3527, -0.1794, -0.3912]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.7528,  0.6213,  1.0597,  ..., -0.0472,  0.3473, -0.5074],\n",
            "          [-0.3524, -0.1707,  0.2835,  ..., -0.5705,  1.0466,  2.4275]]],\n",
            "\n",
            "\n",
            "        [[[-0.0947, -0.1044,  0.6181,  ...,  1.5456,  1.2917,  0.9793],\n",
            "          [ 1.8043,  1.4663,  0.8889,  ...,  1.8184,  1.2410, -0.0968]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9694,  1.6283,  1.6728,  ...,  0.6043, -0.6333, -0.0457],\n",
            "          [-0.3059,  0.0296, -0.2249,  ..., -0.1439,  1.0707, -0.9306]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1179, -0.7407,  0.0229,  ...,  0.3514,  1.0126, -0.1563],\n",
            "          [-0.5601, -0.6167, -0.8263,  ..., -0.1184, -0.2939, -0.1977]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4453, -0.4897,  0.3088,  ..., -0.1836, -1.1682, -0.4276],\n",
            "          [-0.1118,  0.0462,  0.1252,  ...,  1.9683,  2.1211,  2.1474]]],\n",
            "\n",
            "\n",
            "        [[[-1.4994, -0.6992, -1.5794,  ..., -1.4816, -0.9304, -1.3705],\n",
            "          [ 2.0945,  2.0573,  1.8074,  ..., -0.2445, -0.1435, -0.2285]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.7014, -1.2348, -0.3232,  ..., -0.5851,  0.5108, -0.4978],\n",
            "          [-0.4420, -0.4486, -0.5606,  ..., -0.9428, -1.0087, -0.7780]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4323, -0.3385,  0.4853,  ...,  1.2172,  1.8430,  1.2420],\n",
            "          [-0.4281, -0.5108, -0.4670,  ..., -0.0975, -0.0781, -0.1850]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5041,  1.7679,  2.5174,  ...,  0.8622,  0.0100,  0.9648],\n",
            "          [-0.3211, -0.3441, -0.4529,  ...,  0.2863,  0.4296,  0.2347]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0627,  2.7968,  1.4553,  ...,  0.8795, -0.3245,  1.6451],\n",
            "          [-1.3306, -2.5967, -1.2155,  ..., -0.6893,  0.0341, -1.1908]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1590,  1.5468, -0.0199,  ...,  0.2453,  1.7627,  0.1528],\n",
            "          [-0.1626, -0.9985, -0.0277,  ...,  2.0037,  0.3947,  2.0126]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8732,  0.0978,  1.6176,  ..., -0.1992,  0.5607, -0.5515],\n",
            "          [ 0.2112,  1.5378, -0.2005,  ...,  0.7236, -0.0541,  0.3851]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.1443, -1.1343, -0.4721,  ..., -0.3672, -0.4328, -0.6360],\n",
            "          [ 0.1686,  0.4311,  0.0711,  ...,  1.6386,  0.7386,  1.4961]]],\n",
            "\n",
            "\n",
            "        [[[-0.4590, -0.8443, -0.6745,  ..., -0.9096, -1.6083, -1.1839],\n",
            "          [ 0.6684,  1.2788,  0.2202,  ...,  1.5416,  2.7857,  1.6498]]],\n",
            "\n",
            "\n",
            "        [[[-1.7115, -1.2459, -1.4820,  ...,  0.7279,  0.0853,  0.8525],\n",
            "          [ 2.4023,  1.1501,  2.1328,  ..., -0.5933,  0.5003, -0.4744]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.9186,  1.4774, -0.3497,  ..., -0.2711, -0.2479, -0.0537],\n",
            "          [ 2.9207,  2.3665,  3.2593,  ...,  0.4575, -0.6278,  0.1035]]],\n",
            "\n",
            "\n",
            "        [[[-0.3034, -0.1820,  0.0654,  ...,  0.0610,  0.8941,  0.4125],\n",
            "          [-0.7855, -0.0849, -0.9227,  ..., -0.4244,  0.4713, -0.3738]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1440,  0.1712,  0.9417,  ...,  0.6142, -0.4116,  0.8502],\n",
            "          [ 0.7556, -0.5060,  0.6848,  ..., -0.3410,  1.0386, -0.9423]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.2665e-01,  1.0544e+00, -1.0966e-01,  ...,  2.3445e-01,\n",
            "            7.3016e-02,  4.2562e-01],\n",
            "          [-1.0061e-01, -1.3491e+00, -3.7272e-01,  ..., -7.0086e-01,\n",
            "            1.8751e-01, -1.2051e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 9.4211e-02,  3.6091e-01, -2.4322e-02,  ...,  7.5884e-01,\n",
            "           -1.4509e+00,  6.9111e-01],\n",
            "          [-1.0725e-01, -9.4167e-01, -2.7576e-04,  ...,  1.4047e+00,\n",
            "            1.3334e+00,  1.2834e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.4799e+00,  5.3823e-01, -1.6216e+00,  ..., -7.6687e-01,\n",
            "            1.1303e+00, -6.2093e-01],\n",
            "          [ 1.2380e+00,  1.3689e+00,  1.2036e+00,  ...,  6.5271e-01,\n",
            "            7.8354e-01, -2.7693e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.0101e-01, -1.1828e-01,  1.0108e-01,  ..., -1.4511e+00,\n",
            "            1.0119e+00, -1.3484e+00],\n",
            "          [-1.0497e+00, -1.1214e+00, -9.7803e-01,  ...,  8.6550e-01,\n",
            "            3.4317e-01,  6.5042e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4121e+00, -1.1699e+00,  1.4172e+00,  ...,  1.4326e+00,\n",
            "           -1.2750e+00,  1.4838e+00],\n",
            "          [ 7.1056e-02,  4.1031e-01, -2.6820e-01,  ..., -2.4472e+00,\n",
            "           -1.8209e+00, -2.6430e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.2919e+00,  1.1791e+00, -1.3184e+00,  ...,  8.9602e-01,\n",
            "           -1.4321e+00,  1.1923e+00],\n",
            "          [-1.4124e+00, -1.5844e+00, -7.2450e-01,  ...,  6.6033e-01,\n",
            "            1.0224e+00,  7.5990e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-1.2518,  1.1945, -1.1897,  ..., -0.9709,  1.6860, -0.9547],\n",
            "          [ 1.5093,  1.2151,  1.2445,  ..., -0.3148, -1.3151, -1.0650]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8464, -0.8695,  1.3706,  ...,  0.2492, -0.2634,  0.7589],\n",
            "          [-1.3024, -0.8828, -0.9973,  ...,  0.8241,  1.2151,  1.0244]]],\n",
            "\n",
            "\n",
            "        [[[-0.1099,  0.3625, -0.5253,  ..., -0.9678,  1.1037, -1.0547],\n",
            "          [ 2.2706,  2.5829,  3.6534,  ..., -0.6399, -1.2644, -1.5209]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7442, -0.9497,  0.7206,  ...,  0.9285, -1.5569,  0.7820],\n",
            "          [-0.4481,  0.0486, -0.4301,  ...,  0.0905,  0.3986,  0.0366]]],\n",
            "\n",
            "\n",
            "        [[[-1.5130,  0.8908, -1.4850,  ...,  1.1125, -0.5071,  1.1615],\n",
            "          [ 0.7426,  0.0250,  0.6745,  ..., -0.7482,  0.6127, -0.6121]]],\n",
            "\n",
            "\n",
            "        [[[-0.3631,  0.9875, -0.3885,  ..., -1.4776,  1.2160, -1.4268],\n",
            "          [ 1.1842, -0.0443,  1.9834,  ...,  0.1481,  0.3553,  0.2369]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.1559, -1.4209,  1.0288,  ...,  1.0695, -1.3033,  1.1055],\n",
            "          [ 0.2759,  0.1290,  0.0222,  ...,  0.7498,  1.3172,  0.2692]]],\n",
            "\n",
            "\n",
            "        [[[-1.3884,  1.0517, -1.3418,  ...,  0.6127, -0.6454,  0.7721],\n",
            "          [ 0.8487,  0.0374,  1.0693,  ..., -0.3540,  1.2116, -0.4750]]],\n",
            "\n",
            "\n",
            "        [[[-0.3521,  0.4269, -0.4415,  ..., -0.6944,  0.4141, -0.6458],\n",
            "          [ 1.3321, -0.7470,  0.9587,  ..., -0.3652,  0.7211, -0.8828]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1554,  0.7258, -0.1938,  ...,  1.2996, -1.2838,  1.2108],\n",
            "          [ 0.0675,  0.4017, -0.0453,  ..., -0.5465,  1.2538, -0.5632]]],\n",
            "\n",
            "\n",
            "        [[[-1.3210,  1.1994, -1.3045,  ...,  1.1547, -0.8663,  1.0345],\n",
            "          [ 0.9912, -0.8105,  0.8961,  ..., -1.1370, -0.8395, -1.1535]]],\n",
            "\n",
            "\n",
            "        [[[-0.7469,  1.1643, -0.7754,  ..., -0.8466,  0.9340, -0.8039],\n",
            "          [-1.0263, -1.2492, -0.8447,  ...,  0.9341, -1.2409,  0.9093]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 9.4511e-01, -7.5016e-01,  8.3528e-01,  ...,  4.4131e-01,\n",
            "           -7.8836e-01,  5.0100e-01],\n",
            "          [-1.2393e+00,  9.4426e-01, -1.3179e+00,  ..., -7.3500e-02,\n",
            "           -3.0481e-01, -2.2616e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.7118e-01,  4.1359e-01, -8.9198e-01,  ...,  6.9469e-01,\n",
            "           -2.6707e-01,  4.9025e-01],\n",
            "          [-1.5906e-01, -3.8555e-04,  5.8074e-02,  ..., -1.2983e-01,\n",
            "           -3.6785e-01,  6.6425e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.9285e-02,  4.8160e-01,  4.5966e-01,  ..., -5.5467e-01,\n",
            "            9.2781e-01, -7.0829e-01],\n",
            "          [-5.4033e-01, -4.6872e-03, -8.1808e-01,  ...,  1.1261e+00,\n",
            "           -8.5379e-01,  9.9519e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 9.6623e-02, -2.4323e-02,  5.0598e-01,  ...,  4.5016e-01,\n",
            "            7.8016e-02,  2.6409e-01],\n",
            "          [-1.4653e+00, -1.1998e+00, -6.0999e-01,  ...,  5.4024e-01,\n",
            "            8.9416e-01,  1.6020e+00]]],\n",
            "\n",
            "\n",
            "        [[[-3.0462e-01, -5.6615e-01,  1.9664e-01,  ...,  7.1969e-01,\n",
            "            1.1556e+00,  5.1265e-01],\n",
            "          [ 1.5252e+00,  1.3579e+00,  8.8380e-01,  ...,  4.9338e-01,\n",
            "            2.4240e-01,  1.8663e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1398e-02, -5.9502e-02,  8.4812e-02,  ...,  7.6790e-01,\n",
            "            1.3933e+00,  5.5624e-01],\n",
            "          [-8.8382e-03,  4.4363e-01,  2.9281e-01,  ...,  1.0469e+00,\n",
            "            2.0231e-01, -3.1048e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.2922,  0.7194,  0.4212,  ..., -0.2962, -1.0942, -1.0377],\n",
            "          [-0.1099, -0.1649, -0.8252,  ...,  1.3208,  1.4033,  1.5684]]],\n",
            "\n",
            "\n",
            "        [[[-0.5874, -0.8662, -0.5449,  ...,  0.6311, -0.3752, -0.0175],\n",
            "          [ 0.1651,  0.0813, -0.0444,  ...,  0.1581,  0.2000,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3586,  0.8047,  1.1888,  ..., -1.5619, -0.8433, -2.1939],\n",
            "          [ 0.1750, -0.2861,  0.0405,  ...,  1.3279,  0.6554,  0.5593]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.6641, -0.8091, -0.8815,  ..., -0.0506,  0.1958,  0.6354],\n",
            "          [ 0.1629,  0.2389,  0.2769,  ...,  0.7708,  0.9132,  0.7423]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9564,  1.7150,  2.0207,  ..., -0.3750, -0.6691, -0.6381],\n",
            "          [ 0.6244, -0.1722, -0.4977,  ..., -1.1658, -0.9002, -0.7032]]],\n",
            "\n",
            "\n",
            "        [[[-0.9052, -1.1313, -1.1523,  ..., -0.1480,  0.0308, -0.1427],\n",
            "          [-0.7332, -0.3488, -0.1327,  ...,  0.9482,  0.6840,  0.9242]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.0129, -0.0884, -0.0992,  ...,  1.2166,  0.4347,  0.1866],\n",
            "          [ 0.7757,  1.0935,  1.1483,  ...,  0.5784,  0.9291,  0.6223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1271,  0.3090,  0.1687,  ..., -0.2732, -0.4759, -0.7826],\n",
            "          [ 0.6412,  0.4901,  0.9151,  ...,  0.0369,  0.1691,  0.1974]]],\n",
            "\n",
            "\n",
            "        [[[-1.3364, -1.2751, -1.5021,  ...,  0.9336,  0.9704,  0.6514],\n",
            "          [ 0.3687,  0.1095,  0.2546,  ...,  0.7418,  0.6278,  0.7729]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8855,  1.1982,  0.9389,  ...,  0.4736,  0.5346,  0.7177],\n",
            "          [-1.2470, -1.2923, -1.1867,  ..., -0.5832, -0.5982, -1.2772]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6851,  1.1283,  1.2374,  ...,  0.8146,  0.5146,  0.2282],\n",
            "          [-1.1203, -1.5686, -1.5422,  ..., -0.1708, -0.4741, -0.0126]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6159,  1.1666,  1.2187,  ..., -1.0438, -1.0884, -1.1033],\n",
            "          [ 0.0832,  0.3774,  0.3640,  ...,  1.1530,  1.0995,  1.1663]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.0751, -0.9559, -0.7027,  ...,  0.8538,  1.0176,  1.0400],\n",
            "          [ 0.9981,  1.1463,  0.7609,  ...,  0.0493, -0.1879, -0.5140]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9053,  0.9122,  1.0433,  ..., -0.7924, -0.6406, -0.4542],\n",
            "          [-0.7087, -0.7233, -0.9570,  ...,  0.3138,  0.2262,  0.8397]]],\n",
            "\n",
            "\n",
            "        [[[-0.3294, -0.3106,  0.1769,  ..., -0.1106,  0.4269,  0.4456],\n",
            "          [ 0.3573,  0.5701,  0.2642,  ..., -1.0925, -0.5605, -1.0925]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4967,  1.2504,  0.1010,  ..., -0.6584,  0.1729,  0.4500],\n",
            "          [ 1.1680,  1.0540,  1.6809,  ...,  2.1558,  1.8899,  1.8709]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6766,  0.8979,  1.3722,  ..., -1.3364, -1.1572, -0.9675],\n",
            "          [ 1.6137,  1.2845,  0.8779,  ..., -0.4194, -0.7099, -0.5356]]],\n",
            "\n",
            "\n",
            "        [[[-1.1559, -0.8504, -0.4922,  ...,  0.9827,  0.6140,  1.0143],\n",
            "          [-0.2258,  0.1759,  0.4246,  ..., -1.5838, -1.6029, -1.4882]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.1055,  1.2400,  1.1986,  ...,  0.6193,  0.4641,  0.7434],\n",
            "          [-1.6962, -1.6749, -2.0784,  ..., -1.3352, -0.9529, -0.9317]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6365,  0.6799,  0.4359,  ...,  0.6745,  0.5064,  0.2894],\n",
            "          [-1.0863, -1.6456, -1.3763,  ..., -1.8320, -1.8527, -1.4799]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1733,  0.2860,  0.4157,  ...,  0.5622,  0.5228,  0.4270],\n",
            "          [-0.6346, -0.6747, -0.0526,  ...,  1.3323,  1.6334,  1.1918]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7304, -0.6952, -0.7807,  ..., -0.8813, -0.9919, -0.7707],\n",
            "          [-0.2604, -0.4098, -0.4005,  ..., -0.1763, -0.0082, -0.3631]]],\n",
            "\n",
            "\n",
            "        [[[-0.6020, -0.4595, -0.4544,  ...,  1.2302,  0.9197,  0.8179],\n",
            "          [-0.3141, -0.5145, -0.3966,  ...,  0.1573,  0.5109,  0.5345]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6910,  0.7280,  0.8071,  ...,  0.0997, -0.1009, -0.0164],\n",
            "          [ 0.7840,  0.5148,  0.2042,  ..., -0.1996, -0.3445, -0.2824]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.2581, -0.2778, -0.2925,  ..., -1.4870, -1.5361, -1.3837],\n",
            "          [-0.4488, -0.5388, -0.4488,  ...,  0.2116,  0.4117,  0.1315]]],\n",
            "\n",
            "\n",
            "        [[[-1.7416, -1.5063, -1.4614,  ...,  0.2308,  0.5222,  0.3709],\n",
            "          [-0.0227, -0.5135, -0.5026,  ..., -1.3969, -1.6587, -1.8005]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3133,  0.2722,  0.1825,  ...,  0.7990,  0.7579,  0.6383],\n",
            "          [-1.2668, -1.3020, -1.0344,  ..., -0.8724, -0.8935, -0.7526]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.4359,  0.3443,  0.2628,  ...,  0.4970,  1.1894,  1.0876],\n",
            "          [ 0.0552, -0.4473, -0.4114,  ..., -0.6088, -0.5011, -0.5550]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8756,  0.4872,  0.6576,  ..., -0.1056,  0.0920, -0.0375],\n",
            "          [-0.4007, -0.5146, -0.4260,  ..., -0.3375, -0.6664, -0.5020]]],\n",
            "\n",
            "\n",
            "        [[[-0.0307, -0.0470, -0.1934,  ...,  0.3109,  0.9941,  0.6932],\n",
            "          [-0.9904, -1.0511, -1.1724,  ...,  0.9508,  0.3442, -0.0400]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.8730,  1.2644,  1.5253,  ...,  2.9044,  2.7273,  2.4664],\n",
            "          [-0.2173, -0.5164, -0.4765,  ..., -3.4876, -2.9492, -3.0090]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6972,  1.5096,  1.0064,  ...,  1.6119,  1.5181,  1.2879],\n",
            "          [-2.7659, -2.4610, -2.2171,  ..., -1.8310, -1.7903, -1.7700]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9518,  0.6375,  0.3232,  ...,  1.4315,  1.3488,  0.9187],\n",
            "          [-1.5473, -1.2797, -1.1125,  ...,  0.0248,  0.2589, -0.0087]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2734, -0.2195, -0.1931,  ..., -0.6507, -0.6155,  0.0622],\n",
            "          [-0.8556, -0.1683, -0.3557,  ...,  2.1855,  1.2273,  0.3733]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0299,  0.4012,  0.4802,  ...,  0.4802,  0.2511,  0.3380],\n",
            "          [-0.2188, -0.1763, -0.5594,  ..., -1.0491, -1.1981, -0.9426]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3359,  0.6243,  0.4414,  ..., -0.3954, -0.5924, -0.2267],\n",
            "          [-1.4616, -1.1397, -0.7947,  ...,  0.0791,  0.2400, -0.2199]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.0298, -0.4481, -0.3347,  ..., -0.0723,  0.3105,  0.6863],\n",
            "          [ 0.4788,  0.4354,  1.0867,  ...,  1.0867,  0.9130,  1.3689]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6153,  0.9214,  0.6639,  ...,  0.0370, -0.0553, -0.0650],\n",
            "          [ 0.6005,  0.9137,  0.6900,  ..., -0.2049,  0.3544, -0.0707]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1896, -0.2330,  0.1095,  ...,  0.4082,  0.4446,  0.6195],\n",
            "          [-0.0282, -0.6506, -0.7889,  ..., -0.6967, -1.1578, -0.5584]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.5509,  0.4481,  0.6589,  ..., -0.8783, -1.3461, -1.4901],\n",
            "          [-0.5114, -0.2561, -0.4925,  ...,  0.7648,  0.8877,  1.0106]]],\n",
            "\n",
            "\n",
            "        [[[-1.7609, -1.3925, -1.1447,  ..., -0.6491, -0.5221, -0.6174],\n",
            "          [ 0.7618,  0.7247,  0.5580,  ...,  0.4962,  0.5950,  0.2924]]],\n",
            "\n",
            "\n",
            "        [[[-0.2160, -0.5323, -0.3360,  ...,  0.6237,  0.0021, -0.4559],\n",
            "          [ 1.3553,  0.4745,  1.1455,  ...,  0.8519,  1.1036,  1.2085]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.6157, -0.6224, -0.5955,  ..., -0.1055, -0.5083, -0.1256],\n",
            "          [ 0.7057,  0.4721,  0.7187,  ..., -0.6437, -0.3582, -0.8383]]],\n",
            "\n",
            "\n",
            "        [[[-0.1007, -0.2169, -0.2557,  ...,  1.4102,  1.0422,  0.3707],\n",
            "          [-0.2103, -0.4226, -0.2889,  ...,  0.0570, -0.1946, -0.0688]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4951, -0.1630, -0.2736,  ..., -0.8597, -0.4560, -0.1740],\n",
            "          [-0.1338, -0.0778, -0.1245,  ...,  0.5006,  0.3607,  0.0248]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2204, -0.8985, -0.4265,  ..., -1.3801, -0.3905, -1.4424],\n",
            "          [-0.0477, -0.1329, -0.0227,  ...,  1.5457,  1.4004,  1.5307]]],\n",
            "\n",
            "\n",
            "        [[[-2.3339, -3.0574, -3.4126,  ...,  0.5646,  1.3013,  0.9724],\n",
            "          [ 4.6427,  4.3140,  3.9425,  ...,  1.5703,  2.0276,  2.7707]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7082,  1.1626,  1.7814,  ...,  0.7689,  0.3696,  0.6058],\n",
            "          [ 1.1834,  1.8729,  1.8425,  ..., -0.5708, -1.0880, -0.3173]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.0002e+00,  3.6744e-01,  1.5982e+00,  ..., -1.7673e+00,\n",
            "           -1.3293e+00, -9.5376e-01],\n",
            "          [ 1.3281e-01, -9.4943e-01,  1.5026e-01,  ..., -5.1304e-01,\n",
            "           -8.6215e-01, -9.1451e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.6715e-01, -3.6850e-01, -7.8137e-01,  ..., -5.6945e-01,\n",
            "           -1.4089e-02,  3.1109e-01],\n",
            "          [-1.7085e-01, -1.4795e-01,  1.1311e-01,  ...,  4.4412e-02,\n",
            "            1.7265e-01,  1.0395e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.9098e-01, -1.0996e-01,  1.0351e-01,  ..., -7.1916e-01,\n",
            "            5.9816e-01,  9.8307e-02],\n",
            "          [ 7.8708e-01,  4.6987e-01,  1.1229e+00,  ...,  7.6842e-01,\n",
            "            1.0110e+00,  1.3469e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.5291e-01, -1.8505e-01, -3.1919e-04,  ...,  7.3106e-01,\n",
            "            3.9176e-01,  4.3323e-01],\n",
            "          [ 1.4964e+00,  1.6553e+00,  1.8082e+00,  ..., -1.1141e+00,\n",
            "           -1.1324e+00, -9.8568e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.9095e-01,  2.1459e-01,  2.3463e-01,  ...,  3.5488e-01,\n",
            "           -5.8505e-03, -3.0646e-01],\n",
            "          [-6.8195e-01, -4.3831e-01, -2.0020e-01,  ..., -2.0573e-01,\n",
            "           -5.0686e-02,  1.8189e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.0788e-01, -5.0788e-01, -5.6886e-01,  ..., -7.9842e-01,\n",
            "           -5.9755e-01, -6.8364e-01],\n",
            "          [ 4.5864e-01,  5.9495e-01,  6.7128e-01,  ...,  6.6583e-01,\n",
            "            6.0585e-01,  4.2593e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.6758, -0.7605, -0.8644,  ...,  0.6027,  0.7876,  0.6797],\n",
            "          [ 0.2186, -0.1437, -0.9191,  ..., -0.6394, -0.8110, -0.9890]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5328,  0.4497,  0.2696,  ..., -0.6446, -0.6654, -0.4611],\n",
            "          [-0.8147, -0.7620, -0.6775,  ..., -0.0651,  0.0247,  0.1356]]],\n",
            "\n",
            "\n",
            "        [[[-0.6537, -0.5999, -0.4731,  ..., -0.0465, -0.1272, -0.1848],\n",
            "          [ 0.3505,  0.5085,  0.8071,  ...,  1.2168,  1.1817,  1.1466]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.6661, -0.5321, -0.6030,  ...,  0.1419, -0.4139, -0.4572],\n",
            "          [ 1.1735,  1.0450,  1.2347,  ...,  0.1091,  0.1335,  0.2681]]],\n",
            "\n",
            "\n",
            "        [[[-0.4725, -0.3130,  0.0421,  ..., -1.4581, -1.1247, -0.8566],\n",
            "          [ 0.3864,  0.5858,  0.7801,  ..., -0.8251, -0.9938, -1.1779]]],\n",
            "\n",
            "\n",
            "        [[[-0.5735, -0.3746, -0.2533,  ...,  0.8019,  1.1727,  1.3244],\n",
            "          [-1.4133, -2.0623, -1.4693,  ..., -0.8875, -0.8427, -0.9210]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.2632,  0.9678,  0.6238,  ...,  0.5589,  0.8380,  1.0522],\n",
            "          [-0.7443, -0.7893, -0.8433,  ...,  1.7399,  1.7984,  1.8119]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3009,  1.7232,  1.6210,  ...,  1.3418,  1.1238,  1.0080],\n",
            "          [ 2.0963,  1.9681,  1.9200,  ..., -0.6284, -0.7192, -0.6230]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9565,  1.1625,  1.1797,  ..., -0.0771, -0.0874, -0.1698],\n",
            "          [-0.3416, -0.3565, -0.2317,  ..., -0.4365, -0.3565, -0.2617]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1747, -0.6695, -0.8306,  ...,  1.2750,  0.3660,  0.3430],\n",
            "          [ 0.2769,  0.4591,  1.2163,  ...,  0.0666,  0.4591,  0.6695]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4199,  0.0670,  0.1945,  ..., -0.5798, -0.2270,  0.1552],\n",
            "          [ 0.5713,  0.5585,  0.6609,  ...,  0.2511,  0.4944,  0.1998]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5441,  0.4893, -0.0043,  ...,  1.0706,  0.4344,  0.9719],\n",
            "          [ 0.0704, -0.2343,  0.1160,  ...,  0.0399,  0.0551,  0.1313]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.6341,  0.0846,  0.0949,  ...,  0.7896,  0.7066,  0.1157],\n",
            "          [ 0.0335,  0.8530,  1.4182,  ..., -0.6024, -0.4187, -0.4187]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4602,  0.3855, -0.4508,  ..., -0.1596,  0.2959,  0.1017],\n",
            "          [-0.1878, -0.0549, -0.0075,  ...,  0.5049,  0.4195,  0.3531]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3472,  0.6495,  0.5227,  ..., -0.7550, -1.1646, -1.2329],\n",
            "          [ 0.3964,  0.2785,  0.3178,  ...,  0.4553,  0.6125,  0.6714]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7663,  0.5751,  0.7141,  ..., -0.4417, -0.0333,  0.5316],\n",
            "          [-0.4533, -0.6738, -1.2191,  ..., -0.6970, -0.5229, -0.1516]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2192,  0.3437,  0.2625,  ...,  1.0363,  1.4800,  1.6478],\n",
            "          [ 0.1539,  0.2028,  0.5291,  ..., -1.3386, -1.5588, -1.6404]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2188,  2.4990,  2.6612,  ..., -0.9811, -1.3645, -1.3867],\n",
            "          [-1.7489, -1.6318, -1.5785,  ...,  0.5088,  0.7537,  0.7111]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.1915, -0.9740, -0.9626,  ...,  0.3424,  0.2623, -0.0869],\n",
            "          [ 0.3808,  0.4120,  0.4511,  ..., -0.6749, -0.7922, -0.7687]]],\n",
            "\n",
            "\n",
            "        [[[-0.0422, -0.0301, -0.1448,  ...,  0.9775,  0.6215,  0.5431],\n",
            "          [-0.7804, -0.6920, -0.6438,  ..., -0.2018, -0.2340, -0.4107]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7314,  0.3393,  0.8225,  ..., -0.0949, -0.1719,  0.7244],\n",
            "          [-0.5129, -0.6354, -0.7403,  ...,  1.2800,  0.9739,  0.6066]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2904,  0.0609, -0.5358,  ...,  2.8793,  1.9704,  1.6766],\n",
            "          [-0.4903, -0.6717, -0.6717,  ..., -1.7109, -1.3810, -1.0346]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4933,  1.3018,  2.7229,  ...,  0.9629,  0.8536,  0.7224],\n",
            "          [-0.8906, -0.9366, -1.1208,  ...,  0.5212,  0.7053,  0.7053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3294,  0.4820,  0.4343,  ...,  0.1959, -0.6913, -0.6531],\n",
            "          [ 1.0929,  1.0064,  1.0929,  ..., -3.3330, -3.6791, -3.5493]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1166, -0.2963, -0.3749,  ..., -0.0702,  0.5490,  0.7358],\n",
            "          [-3.4312, -3.1299, -2.2832,  ..., -0.2599, -0.3890, -0.2599]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2475,  0.5529,  0.2039,  ...,  0.1385, -0.0361,  0.0512],\n",
            "          [-0.2020, -0.1527, -0.5174,  ...,  0.3008,  0.1923,  0.1233]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6060,  0.6440,  0.2036,  ...,  0.8794,  0.1732, -0.0774],\n",
            "          [-0.1620, -0.4097, -0.4488,  ..., -1.7397, -1.4398, -1.2182]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3714,  0.2539,  0.4157,  ...,  2.5075,  2.3673,  1.5155],\n",
            "          [ 0.3688,  0.0298, -0.2244,  ..., -2.0548, -2.0209, -1.7667]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4013,  0.0609,  0.1710,  ..., -0.1136,  0.3179,  0.7678],\n",
            "          [-2.0681, -1.6522, -0.7509,  ...,  0.7223,  0.2023,  0.2370]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9220,  0.9462,  0.7929,  ...,  0.8333,  0.4382,  0.9381],\n",
            "          [-0.0726, -0.3014, -0.8082,  ..., -0.6937, -1.0370, -1.2822]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.3714e+00,  5.6056e-01,  8.6788e-02,  ..., -7.9698e-01,\n",
            "           -9.1542e-01, -9.7009e-01],\n",
            "          [-1.7071e+00, -2.2407e+00, -1.4495e+00,  ...,  9.0540e-01,\n",
            "            1.0710e+00,  1.3286e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.1600e+00, -1.1397e+00, -1.1499e+00,  ...,  8.2914e-01,\n",
            "            2.2022e-01,  7.0906e-03],\n",
            "          [ 9.5939e-01,  6.6327e-01,  9.0714e-01,  ...,  1.3587e-03,\n",
            "            1.1336e+00,  1.3252e+00]]],\n",
            "\n",
            "\n",
            "        [[[-2.1014e-01, -5.5732e-01, -2.1014e-01,  ...,  1.8334e-01,\n",
            "            1.3406e+00,  8.7771e-01],\n",
            "          [ 1.1574e+00,  8.9212e-01,  8.9212e-01,  ...,  9.5108e-01,\n",
            "            7.1525e-01,  4.7942e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1943e+00,  1.0205e+00,  6.6534e-01,  ...,  3.3213e+00,\n",
            "            3.5173e+00,  3.5469e+00],\n",
            "          [-1.1794e+00, -1.2245e+00, -1.1536e+00,  ..., -1.4370e+00,\n",
            "           -1.6818e+00, -1.6947e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1500e+00,  4.2903e+00,  4.1681e+00,  ...,  2.8542e-01,\n",
            "            7.1985e-01,  9.4158e-01],\n",
            "          [-2.3057e+00, -2.5789e+00, -2.8019e+00,  ..., -5.3663e-01,\n",
            "           -9.8968e-01, -1.3780e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2196e+00,  1.2238e+00,  1.0015e+00,  ...,  2.2455e+00,\n",
            "            2.3182e+00,  2.5491e+00],\n",
            "          [-1.2755e+00, -1.2828e+00, -1.2245e+00,  ..., -1.6111e+00,\n",
            "           -1.7205e+00, -2.2457e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[ 2.9417e+00,  2.8842e+00,  2.8444e+00,  ...,  3.6410e-01,\n",
            "            5.3211e-01,  9.1234e-01],\n",
            "          [-1.3980e+00, -1.2690e+00, -1.2628e+00,  ...,  1.7166e+00,\n",
            "            1.5323e+00,  1.2927e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2120e+00,  1.5693e+00,  1.7672e+00,  ..., -6.3432e-01,\n",
            "           -8.4091e-01, -1.0991e+00],\n",
            "          [ 1.1224e+00,  8.3310e-01,  6.3518e-01,  ...,  1.7161e+00,\n",
            "            1.7923e+00,  1.8912e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.0937e+00, -1.0497e+00, -1.0737e+00,  ..., -2.8715e-03,\n",
            "           -1.3473e-01, -1.6270e-01],\n",
            "          [ 1.5988e+00,  1.5590e+00,  1.6783e+00,  ..., -1.1779e+00,\n",
            "           -9.1286e-01, -8.2008e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-6.7798e-01, -1.1930e+00,  3.9550e-01,  ..., -8.2788e-01,\n",
            "           -4.9181e-01, -8.3997e-01],\n",
            "          [ 1.6262e+00,  2.4897e-01,  1.5207e+00,  ..., -2.8886e-01,\n",
            "           -1.2037e+00,  3.9976e-01]]],\n",
            "\n",
            "\n",
            "        [[[-6.3625e-01, -7.3309e-01, -8.6397e-01,  ...,  2.2953e+00,\n",
            "            2.0335e+00,  2.3843e+00],\n",
            "          [ 1.5956e+00, -9.6199e-01,  1.5471e-01,  ...,  3.9967e-01,\n",
            "            4.8612e-01,  1.1778e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8144e+00,  3.4254e+00,  2.7591e+00,  ...,  3.7707e-01,\n",
            "            1.1470e-01,  2.7695e-01],\n",
            "          [ 7.9929e-01,  5.4177e-01,  1.3868e+00,  ..., -1.6310e+00,\n",
            "           -1.1007e-01, -1.9859e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.2374, -0.1969,  0.1500,  ..., -0.4651, -0.3631, -0.2027],\n",
            "          [ 0.8902, -0.8492, -0.2839,  ...,  0.9410,  0.1800, -0.0737]]],\n",
            "\n",
            "\n",
            "        [[[-0.2681, -0.5626, -0.4576,  ..., -1.3052, -1.0031, -1.0210],\n",
            "          [ 0.4740, -0.3676,  0.4050,  ...,  0.2188, -0.3262, -0.1193]]],\n",
            "\n",
            "\n",
            "        [[[-0.9267, -0.8890, -0.9112,  ...,  0.5192,  0.8279,  0.7213],\n",
            "          [-0.0515,  0.2410, -0.5100,  ..., -0.3616,  0.2759,  1.1754]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.6062, -0.1645,  0.3077,  ...,  1.6566,  1.3126,  1.2485],\n",
            "          [ 0.4399, -0.0291, -0.3483,  ..., -0.3027, -0.4264, -0.6479]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3448,  1.3649,  1.4554,  ...,  0.5098,  0.0337, -0.2446],\n",
            "          [-0.5957, -0.5841, -0.7925,  ...,  0.8054,  0.8343,  1.0891]]],\n",
            "\n",
            "\n",
            "        [[[-0.2579, -0.1830, -0.0488,  ..., -1.2096, -0.9568, -0.8726],\n",
            "          [ 0.9856,  1.0399,  1.0053,  ..., -0.5496, -0.4608, -0.2732]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.9040, -1.0290, -1.0052,  ...,  0.3486,  0.6402,  0.8960],\n",
            "          [-0.2689, -0.5244, -0.7340,  ...,  0.1656,  0.3956,  0.4467]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2033,  1.0883,  1.0324,  ..., -1.5899, -1.4315, -1.1891],\n",
            "          [ 0.4896,  0.5542,  0.5595,  ...,  0.9955,  0.8179,  0.4681]]],\n",
            "\n",
            "\n",
            "        [[[-1.0350, -0.3417,  0.1990,  ...,  0.5560,  0.7189,  0.7363],\n",
            "          [ 0.2412, -0.0949, -0.3484,  ..., -0.0563, -0.2602, -0.7672]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3794, -0.3648, -0.6197,  ...,  0.5272,  0.6190,  0.2265],\n",
            "          [-0.3142, -0.5029, -0.3614,  ..., -0.0725, -0.0725,  0.1574]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4357,  0.2758,  0.3175,  ..., -0.1067, -0.2666, -0.2248],\n",
            "          [ 0.1947,  0.1030, -0.1141,  ...,  0.1464,  0.0499, -0.0417]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1840,  0.3769,  0.8028,  ..., -0.1937, -0.7321, -0.8687],\n",
            "          [-0.8743, -0.8984, -0.9945,  ...,  1.3488,  1.0965,  0.9883]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.7372, -0.9053, -0.4874,  ..., -0.2694,  0.1531,  0.3212],\n",
            "          [ 0.5277,  0.3553,  0.2373,  ..., -0.4796, -0.6158, -0.8789]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7781,  0.5715,  0.3400,  ..., -2.0255, -2.2133, -2.8266],\n",
            "          [-0.9216, -0.7937, -0.2716,  ...,  2.3389,  2.3602,  2.3922]]],\n",
            "\n",
            "\n",
            "        [[[-3.2301, -3.2192, -2.9740,  ...,  1.4601,  1.1823,  1.0570],\n",
            "          [ 2.9477,  3.0440,  3.1724,  ..., -1.1839, -1.0876, -0.4775]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.1386,  2.0918,  1.3976,  ..., -0.3418, -0.0064, -0.5914],\n",
            "          [-0.6081, -1.0778, -1.4171,  ...,  0.8013,  0.5534,  0.5925]]],\n",
            "\n",
            "\n",
            "        [[[-0.0680, -0.5158, -0.4469,  ..., -1.0152, -0.5675, -0.4900],\n",
            "          [ 1.1294,  1.3350,  1.7937,  ...,  1.3350,  0.7024,  0.2279]]],\n",
            "\n",
            "\n",
            "        [[[-0.4000, -0.3121, -0.3912,  ..., -0.5318, -0.5142, -0.3560],\n",
            "          [ 0.0055,  0.0055, -0.1979,  ..., -0.2869, -0.1598,  0.3743]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4048, -0.3245, -0.3847,  ..., -1.3617, -1.0204, -0.7661],\n",
            "          [ 0.4637, -0.3812, -0.4766,  ...,  0.5454,  0.6954,  0.6817]]],\n",
            "\n",
            "\n",
            "        [[[-0.9494, -0.9644, -1.0769,  ...,  0.3182,  0.7157,  0.8057],\n",
            "          [-0.1430,  0.1328, -0.7982,  ..., -0.4189, -0.4016, -2.1429]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6734,  1.8810,  2.2489,  ...,  0.7677,  0.5696,  0.2488],\n",
            "          [-0.6924, -0.6001, -0.6924,  ..., -1.9717, -2.4597, -2.3147]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3158, -0.0593, -0.8456,  ...,  0.8640,  0.3879, -0.3695],\n",
            "          [-0.9069, -0.9069, -0.5616,  ..., -0.0545,  0.0211,  0.4742]]],\n",
            "\n",
            "\n",
            "        [[[-0.0913, -0.1872,  0.2229,  ..., -1.5185, -1.5132, -1.2789],\n",
            "          [ 0.9939,  1.0793,  0.8018,  ..., -0.3512, -0.2871, -0.3619]]],\n",
            "\n",
            "\n",
            "        [[[-1.1837, -1.2522, -0.6358,  ...,  0.9147,  0.0616, -0.9845],\n",
            "          [-0.2530, -0.4554, -0.8816,  ..., -0.1997, -0.0186,  0.9935]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.6781, -1.0760, -0.3871,  ..., -0.8386, -0.6650, -0.2597],\n",
            "          [ 2.2542,  2.8988,  2.0274,  ...,  0.6306,  0.2606, -0.1931]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1106,  0.1106,  0.0305,  ..., -0.3573, -0.2711, -0.2280],\n",
            "          [-0.5208, -0.5785, -0.3939,  ...,  0.9908,  0.9100,  0.7023]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0940, -0.1065, -0.0797,  ..., -0.1466, -0.2869,  1.5843],\n",
            "          [ 0.7690,  0.5700,  0.7192,  ...,  0.2591,  1.4033,  1.1297]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1287,  0.9463,  0.8824,  ...,  2.8889,  2.4694,  1.7124],\n",
            "          [-1.0952, -0.8213, -0.7217,  ..., -1.5932, -1.5185, -1.2944]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1118,  1.4192,  1.4480,  ...,  0.0821,  0.3514,  0.0821],\n",
            "          [-1.5061, -2.0378, -2.6455,  ..., -1.1111, -0.8680, -1.0655]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4222,  0.4610,  1.0432,  ...,  0.0534, -0.1697, -0.2086],\n",
            "          [-1.2218, -1.0583, -1.2355,  ...,  0.6316,  0.5362,  0.3727]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4821, -0.5206, -1.1270,  ...,  2.4345,  2.8003,  3.3778],\n",
            "          [ 0.5622,  0.9075,  0.9651,  ..., -0.6751, -0.6895, -0.6464]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6400,  3.3939,  3.4034,  ..., -0.5472, -0.4995, -1.1483],\n",
            "          [-1.1141, -1.3570, -2.0698,  ...,  0.2142, -0.5633, -0.4337]]],\n",
            "\n",
            "\n",
            "        [[[-1.1254, -1.5430, -1.6852,  ...,  1.2384,  0.8918,  1.1228],\n",
            "          [-0.3136, -0.1021, -0.3891,  ...,  0.2150,  0.1093,  0.2603]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2508, -0.2189, -0.3926,  ...,  1.5328,  1.6746,  1.2846],\n",
            "          [ 0.0405, -0.0534, -0.1546,  ...,  0.2645,  0.3584,  0.0622]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1139,  0.8752,  0.5664,  ...,  0.1081, -0.2325, -0.0192],\n",
            "          [-0.0098,  0.1643,  0.4673,  ..., -1.5440, -1.3958, -1.3506]]],\n",
            "\n",
            "\n",
            "        [[[-0.0673,  0.0841,  0.1251,  ...,  1.8696,  2.0399,  1.9358],\n",
            "          [-1.1772, -1.2262, -0.9380,  ..., -2.4529, -2.4039, -2.4161]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 2.4492,  2.2763,  2.5506,  ...,  0.0032, -0.1922, -0.0832],\n",
            "          [-2.2276, -2.1515, -1.8787,  ..., -1.6694, -1.0604, -0.8193]]],\n",
            "\n",
            "\n",
            "        [[[-0.4258, -0.5182, -0.9426,  ..., -0.8365, -0.9973, -0.9802],\n",
            "          [-0.2560,  0.1525,  0.3568,  ...,  0.3860,  0.2810,  0.3627]]],\n",
            "\n",
            "\n",
            "        [[[-0.8572, -0.3488,  0.1124,  ..., -0.0828, -0.2680, -0.5980],\n",
            "          [-0.0670, -0.3521, -0.5077,  ..., -1.5058, -1.4474, -1.1947]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2130,  0.0250,  0.1639,  ...,  0.6399,  1.0829,  0.9838],\n",
            "          [ 0.2043,  0.2507,  0.1579,  ..., -1.0016, -0.0430, -0.0585]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1861,  1.0165,  0.6349,  ..., -0.4181, -0.9622, -0.2979],\n",
            "          [-0.2318, -0.1712,  0.0348,  ...,  1.7313,  1.9251,  1.6949]]],\n",
            "\n",
            "\n",
            "        [[[-0.1234,  0.2988,  0.1581,  ..., -0.4257, -0.7750, -0.6968],\n",
            "          [ 1.4736,  1.0904,  1.1010,  ...,  1.0478,  1.5907,  1.3991]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.3208,  0.4324,  0.3564,  ..., -0.3485, -0.8599, -0.4936],\n",
            "          [ 0.5929, -0.1131, -0.1719,  ...,  0.4948,  1.0537,  0.9851]]],\n",
            "\n",
            "\n",
            "        [[[-0.3953,  0.1425,  0.1344,  ..., -0.5990, -1.2020, -1.5606],\n",
            "          [ 0.8018,  0.4063, -0.0880,  ..., -1.6698, -1.0272, -0.6318]]],\n",
            "\n",
            "\n",
            "        [[[-0.8862, -0.1107,  0.4565,  ...,  1.2783,  0.4333, -0.9210],\n",
            "          [-0.4007, -0.5105, -1.0493,  ..., -2.0770, -1.6080, -0.5404]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.4396, -0.6659, -1.4069,  ..., -0.4496, -0.4416, -0.4176],\n",
            "          [ 0.5968,  1.1624,  1.2947,  ...,  0.2238,  0.2118,  1.4993]]],\n",
            "\n",
            "\n",
            "        [[[-0.1892, -0.1362, -0.0444,  ..., -0.1292, -0.0126, -0.0903],\n",
            "          [-0.0774,  0.0990,  0.0679,  ...,  0.4311,  0.0160,  0.0783]]],\n",
            "\n",
            "\n",
            "        [[[-0.0696, -0.1727, -0.3027,  ...,  0.0680,  0.2973,  0.5458],\n",
            "          [ 0.6294,  0.5092, -0.2842,  ...,  0.6534,  0.1726, -0.7170]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.9926,  0.9281,  0.9880,  ..., -0.0946, -0.1822, -0.1269],\n",
            "          [-0.2300, -0.0410, -0.8206,  ..., -1.5057, -1.7419, -1.2576]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2103,  0.1801,  0.2069,  ..., -0.5016, -0.3202, -0.5754],\n",
            "          [-0.9561, -0.2692, -0.9153,  ..., -0.4460, -0.2284, -0.2148]]],\n",
            "\n",
            "\n",
            "        [[[-0.7023, -0.8409, -0.8600,  ..., -1.0512, -0.8265, -0.6258],\n",
            "          [-1.5147, -1.1865, -0.6218,  ...,  0.6782, -0.3329,  0.2055]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1348, -1.3794, -1.4533,  ...,  0.7483,  0.5378,  0.5207],\n",
            "          [ 0.1969,  0.5086,  0.6881,  ...,  1.2832,  1.6044,  1.7933]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2131,  0.0806,  0.2552,  ..., -0.3772, -0.3531, -0.0279],\n",
            "          [ 2.5130,  2.6131,  2.8465,  ..., -0.4435, -0.2879, -0.2991]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3359,  0.9071,  1.2374,  ..., -0.2185,  0.1511,  0.5767],\n",
            "          [-0.3037, -0.4751, -0.8179,  ...,  0.9246,  0.8389,  0.7056]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.8164,  1.1464,  1.5563,  ..., -0.8230, -0.7326, -1.0093],\n",
            "          [ 0.2411, -0.0560, -0.4522,  ..., -0.5760, -0.7575, -0.8896]]],\n",
            "\n",
            "\n",
            "        [[[-0.9473, -1.0121, -0.9581,  ..., -0.1085,  0.0643,  0.1687],\n",
            "          [-0.5685, -0.3755, -0.1200,  ...,  0.2661,  0.1241, -0.0121]]],\n",
            "\n",
            "\n",
            "        [[[-0.0341, -0.2362, -0.3724,  ..., -0.3812, -0.2889, -0.4163],\n",
            "          [-0.2089, -0.1463, -0.1306,  ...,  0.8474,  0.5814,  0.2606]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3753,  0.2199,  0.1326,  ...,  0.7054,  0.7993,  0.8575],\n",
            "          [-0.3581, -0.4862, -0.6433,  ..., -0.4945, -0.6185, -0.8252]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7711,  0.8137,  0.6894,  ...,  1.9082,  1.9437,  2.0823],\n",
            "          [-0.9922, -1.1015, -1.0833,  ..., -1.3703, -1.3886, -1.4934]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8846,  1.9569,  1.9192,  ...,  1.7652,  1.7746,  1.7118],\n",
            "          [-1.5499, -1.6370, -1.5820,  ..., -0.1659, -0.3950, -0.5967]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.5355e+00,  1.2907e+00,  1.1928e+00,  ...,  3.4534e-01,\n",
            "            3.7593e-01,  2.2296e-01],\n",
            "          [-8.2201e-01, -8.5395e-01, -9.4975e-01,  ..., -1.3147e+00,\n",
            "           -1.2919e+00, -1.2691e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2294e-01,  6.2609e-02,  2.2833e-03,  ..., -4.4413e-01,\n",
            "           -4.6223e-01, -3.7174e-01],\n",
            "          [-9.6603e-01, -8.4533e-01, -7.8096e-01,  ...,  3.7774e-01,\n",
            "            3.4153e-01,  2.9326e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.6722e-01, -7.2874e-01, -7.5444e-01,  ..., -2.4051e-01,\n",
            "           -1.7076e-01, -1.6709e-01],\n",
            "          [ 3.0781e-01,  2.6388e-01,  2.4924e-01,  ..., -3.9020e-01,\n",
            "           -5.8056e-01, -6.7330e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.0476e-02, -2.5144e-01, -2.5914e-01,  ...,  5.8003e-01,\n",
            "            3.2597e-01,  1.7199e-01],\n",
            "          [-1.7019e+00, -1.5942e+00, -1.3924e+00,  ...,  1.4331e+00,\n",
            "            1.9040e+00,  2.4018e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.1113e-01,  1.9236e-01,  8.1416e-01,  ...,  3.0340e-01,\n",
            "           -1.8516e-01, -5.4047e-01],\n",
            "          [ 2.4249e+00,  2.7349e+00,  2.8849e+00,  ..., -9.8495e-01,\n",
            "           -7.7496e-01, -5.1497e-01]]],\n",
            "\n",
            "\n",
            "        [[[-9.2813e-01, -8.0264e-01, -8.6120e-01,  ...,  9.5425e-01,\n",
            "            5.1921e-01,  1.3437e-01],\n",
            "          [-1.6543e-01, -4.2263e-02,  9.6305e-02,  ..., -4.7336e-01,\n",
            "           -5.8114e-01, -5.5035e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.0109, -0.0109,  0.1130,  ..., -1.5813, -1.7218, -1.2672],\n",
            "          [-0.2466, -0.3334, -0.3768,  ...,  0.2311,  0.3179,  0.2311]]],\n",
            "\n",
            "\n",
            "        [[[-0.9442, -0.6615, -0.4960,  ...,  0.0625, -0.1926, -0.1788],\n",
            "          [-0.0997, -0.3350, -0.3743,  ..., -0.2043, -0.1650, -0.2304]]],\n",
            "\n",
            "\n",
            "        [[[-0.0038,  0.6220,  1.0627,  ..., -1.0614, -1.2994, -1.4316],\n",
            "          [-0.2224, -0.4537, -0.6126,  ..., -0.1213,  0.1533,  0.1389]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.6606,  0.7209,  1.1585,  ..., -0.7050, -0.7955, -0.8634],\n",
            "          [ 0.5241,  0.3089,  0.2551,  ...,  0.2282,  0.5779,  0.6048]]],\n",
            "\n",
            "\n",
            "        [[[-0.8021, -0.8311, -0.7153,  ...,  0.4431,  0.3910,  0.5879],\n",
            "          [ 0.7974,  0.8339,  1.0646,  ...,  0.1659,  0.1295,  0.0809]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7104,  0.3147,  0.2397,  ..., -0.3060, -0.4424, -0.0809],\n",
            "          [-0.0204,  0.1343,  0.1819,  ...,  0.6579,  0.8007,  0.6698]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 4.2465e-01,  3.3841e-01,  1.2612e-01,  ...,  5.5732e-01,\n",
            "            1.3939e-01,  1.3276e-01],\n",
            "          [ 3.3279e-01, -1.7572e-01, -2.5818e-01,  ..., -9.3162e-01,\n",
            "           -4.6434e-01, -2.9941e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8742e-02,  4.8102e-01,  2.3883e-01,  ..., -7.1129e-01,\n",
            "           -6.9266e-01, -4.7531e-01],\n",
            "          [-5.3797e-01, -4.2831e-01, -8.6695e-01,  ...,  2.3759e+00,\n",
            "            1.9842e+00,  2.7049e+00]]],\n",
            "\n",
            "\n",
            "        [[[-8.2175e-02, -8.3007e-01, -4.9508e-01,  ..., -1.1962e+00,\n",
            "           -9.0019e-01, -1.0015e+00],\n",
            "          [ 2.6158e+00,  1.9791e+00,  2.6980e+00,  ..., -9.5469e-02,\n",
            "            6.8850e-02,  8.9390e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.2209e-01,  2.3160e-01, -9.4196e-02,  ..., -5.5574e-01,\n",
            "           -4.3809e-01, -1.7564e-01],\n",
            "          [-3.7896e-01, -5.3125e-01, -3.2185e-01,  ...,  1.7831e-03,\n",
            "           -1.1244e-01, -1.7254e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.6918e-01, -1.7257e-01, -1.5325e-01,  ...,  1.1993e+00,\n",
            "            1.1220e+00,  1.2573e+00],\n",
            "          [-7.2854e-02, -1.6660e-01, -1.6660e-01,  ..., -2.7910e-01,\n",
            "           -5.9784e-01, -1.0103e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1768e+00,  1.0532e+00,  1.1293e+00,  ..., -1.1718e+00,\n",
            "           -8.2001e-01, -7.9148e-01],\n",
            "          [-1.2530e+00, -1.7468e+00, -2.0290e+00,  ...,  1.3749e+00,\n",
            "            1.0221e+00,  1.0927e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[-5.2895e-01, -3.4130e-01, -4.0885e-01,  ...,  1.2575e+00,\n",
            "            1.2349e+00,  8.4463e-01],\n",
            "          [ 7.0294e-01,  6.1143e-01,  3.9793e-01,  ...,  1.6917e-01,\n",
            "            1.0817e-01,  1.4183e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.0227e-01,  7.1681e-01,  4.7501e-01,  ...,  9.9598e-02,\n",
            "           -2.1299e-02,  2.9685e-01],\n",
            "          [ 9.3744e-02,  2.3404e-01, -1.8491e-02,  ...,  1.6389e-01,\n",
            "            2.0598e-01,  2.9015e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 7.1083e-01,  1.3475e+00,  1.7754e+00,  ..., -1.4810e+00,\n",
            "           -1.3662e+00, -1.3245e+00],\n",
            "          [ 3.5974e-01,  3.2403e-01, -5.0915e-02,  ...,  1.4667e+00,\n",
            "            1.7167e+00,  1.4846e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.4755e-01,  7.4559e-01,  8.2441e-01,  ...,  1.3868e-01,\n",
            "            2.3326e-01,  3.3179e-01],\n",
            "          [-1.7929e-01, -3.1634e-01, -4.5340e-01,  ...,  5.3088e-01,\n",
            "            4.0006e-01,  2.6924e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8129e-01,  4.9177e-01,  4.3998e-01,  ..., -2.5746e-01,\n",
            "           -4.7153e-01, -5.9582e-01],\n",
            "          [ 9.9045e-02,  2.9076e-02, -5.5887e-02,  ..., -1.1454e+00,\n",
            "           -1.0904e+00, -9.6049e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.8527e-01, -5.5513e-01, -3.1071e-01,  ..., -2.6143e+00,\n",
            "           -2.5273e+00, -2.5239e+00],\n",
            "          [-1.3942e+00, -1.4848e+00, -1.7037e+00,  ...,  1.7184e-02,\n",
            "           -3.7530e-01, -6.7720e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-2.5739, -2.6694, -2.6836,  ...,  0.5164,  0.5659,  0.6225],\n",
            "          [-1.0162, -1.1536, -1.2376,  ...,  0.2966,  0.2050,  0.1821]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7876,  0.6930,  0.6211,  ..., -0.2498, -0.0074, -0.0453],\n",
            "          [ 0.0515,  0.0236,  0.0608,  ...,  0.7669,  0.5811,  0.4324]]],\n",
            "\n",
            "\n",
            "        [[[-0.3046,  0.1899,  0.3737,  ..., -0.4694, -0.5265, -0.3997],\n",
            "          [ 1.2925,  1.2142,  1.1881,  ...,  1.4882,  1.4490,  1.2142]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1671, -0.2296, -0.0056,  ...,  0.6104,  0.7505,  0.9745],\n",
            "          [ 0.7895,  0.8813,  0.4123,  ..., -0.2096, -0.0057, -0.0057]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8508,  0.7323,  0.7936,  ..., -0.9313, -0.7596, -0.6288],\n",
            "          [-0.3618, -0.0847, -0.8530,  ...,  0.8726, -0.5256,  0.4065]]],\n",
            "\n",
            "\n",
            "        [[[-0.4372, -0.4189, -0.3761,  ...,  0.2964,  0.0090,  0.2291],\n",
            "          [ 0.6127,  0.4038,  0.4502,  ...,  0.5198,  0.5663,  0.5431]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.7788,  0.3516,  0.8059,  ...,  0.7517,  0.6839,  0.5889],\n",
            "          [ 0.8138,  0.8474,  0.0073,  ...,  0.3321, -0.2616, -0.4968]]],\n",
            "\n",
            "\n",
            "        [[[-0.0360, -0.0391, -0.0576,  ...,  0.7132,  0.1900,  0.1219],\n",
            "          [-0.1004,  0.0552,  0.2482,  ..., -0.0071,  0.2855, -0.6607]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0878, -0.0165,  0.2330,  ...,  0.8551,  0.7322,  0.9743],\n",
            "          [-0.5791,  0.4305,  0.7618,  ...,  1.5032,  0.5251,  0.1939]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.4186,  0.4752,  0.4578,  ...,  0.4143,  0.5274,  0.5839],\n",
            "          [-1.2235, -1.1143, -1.2672,  ..., -0.7138, -0.7429, -0.6629]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5504,  0.5621,  0.6089,  ..., -0.3397,  0.1834,  0.4489],\n",
            "          [-0.5812, -0.5668, -0.5092,  ...,  0.3552, -0.0049, -0.3147]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5864,  0.5754,  0.3113,  ...,  0.8212,  0.9239,  0.8946],\n",
            "          [-0.5594, -0.8577, -0.8293,  ...,  0.5839,  0.3069, -0.0623]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.8071,  0.8261,  0.6611,  ...,  0.4295,  0.6516,  0.8896],\n",
            "          [-0.1134, -0.2231, -0.1053,  ...,  0.0695,  0.0045, -0.1662]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0980,  1.0575,  0.8925,  ...,  1.4622,  1.6957,  1.7144],\n",
            "          [-0.3598, -0.3793, -0.3793,  ..., -0.2428, -0.4719, -0.8181]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5212,  1.2582,  1.0686,  ...,  0.8332,  0.7659,  0.4937],\n",
            "          [-0.8040, -0.8896, -0.6272,  ..., -0.9638, -1.1977, -1.2319]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2393,  0.2510,  0.3249,  ..., -0.0528,  0.0056,  0.0563],\n",
            "          [-0.3451, -0.2688, -0.2765,  ...,  0.6994,  0.7375,  0.6308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0137,  0.0168, -0.0747,  ...,  0.3610,  0.5135,  0.5397],\n",
            "          [ 0.7270,  0.7179,  1.0480,  ...,  0.1218, -0.1992, -0.4468]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2784,  0.1513,  0.0485,  ..., -0.5237, -0.5824, -0.5188],\n",
            "          [ 0.0183,  0.1257,  0.2791,  ...,  0.2484,  0.2714,  0.2638]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4020, -0.1929, -0.0572,  ..., -0.1342, -0.1452, -0.2846],\n",
            "          [-0.0631, -0.0826, -0.1868,  ..., -0.8769, -0.9680, -0.9420]]],\n",
            "\n",
            "\n",
            "        [[[-0.6068, -0.7475, -0.7313,  ...,  0.8333,  0.5897,  0.3569],\n",
            "          [-0.9580, -0.8323, -0.7401,  ...,  0.7515,  0.9024,  0.8018]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1473,  0.2371,  0.0832,  ...,  0.7373,  0.5492,  0.5962],\n",
            "          [ 0.7149,  0.6166,  0.5592,  ..., -0.4735, -0.2932, -0.1211]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2086,  0.3114,  0.3114,  ...,  0.6255,  0.5341,  0.3057],\n",
            "          [-0.2901, -0.2400, -0.2651,  ...,  0.4789,  0.5227,  0.7477]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2904,  0.1437, -0.1883,  ..., -0.7288, -0.8523, -1.0338],\n",
            "          [ 0.7240,  0.8203,  1.1026,  ...,  0.8780,  0.8203,  0.6791]]],\n",
            "\n",
            "\n",
            "        [[[-1.1426, -0.8371, -0.9192,  ..., -2.1227, -2.0224, -2.1410],\n",
            "          [ 0.9162,  0.5915,  0.4292,  ...,  0.2925,  0.3438,  0.3181]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.0030, -2.0649, -2.1190,  ..., -0.6116, -0.6502, -0.5343],\n",
            "          [ 0.3165,  0.3002,  0.0806,  ...,  0.7151,  0.8290,  0.6744]]],\n",
            "\n",
            "\n",
            "        [[[-0.7133, -0.6527, -0.6931,  ...,  0.1951,  0.4625,  0.6795],\n",
            "          [ 1.1539,  1.2614,  1.3474,  ...,  0.3259,  0.2184,  0.1753]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9565,  1.0515,  1.1583,  ...,  0.5884,  0.5469,  0.9506],\n",
            "          [-0.0401, -0.0092, -0.1945,  ..., -0.3798, -0.0772, -0.2563]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1741,  1.1820,  1.2497,  ..., -0.3066, -0.4578, -0.6688],\n",
            "          [-0.4619, -0.8129, -1.0247,  ..., -0.4075, -0.2381, -0.0142]]],\n",
            "\n",
            "\n",
            "        [[[-0.5274, -0.4065, -0.2919,  ...,  1.5981,  1.6012,  1.4680],\n",
            "          [ 0.0510, -0.1445, -0.2940,  ...,  1.6612,  1.3909,  1.1897]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7079,  1.8513,  1.9494,  ...,  1.0626,  0.9116,  0.7456],\n",
            "          [ 0.8807,  0.8748,  0.8925,  ..., -0.7667, -0.6899, -0.7076]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 6.5785e-01,  5.3861e-01,  4.1566e-01,  ...,  6.5412e-01,\n",
            "            7.4355e-01,  8.1061e-01],\n",
            "          [-7.2937e-01, -7.3891e-01, -7.1030e-01,  ...,  2.8773e-04,\n",
            "            3.3671e-02, -5.6941e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5611e-01,  8.8937e-01,  6.7344e-01,  ..., -1.6671e-01,\n",
            "           -2.3345e-01, -2.6093e-01],\n",
            "          [-7.5118e-02, -1.6234e-02,  2.5142e-01,  ..., -3.2136e-01,\n",
            "           -4.6054e-01, -3.1066e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.3909e-01, -6.1257e-01, -6.2617e-01,  ..., -9.6293e-01,\n",
            "           -9.2551e-01, -9.0510e-01],\n",
            "          [-2.5012e-01, -2.7635e-01, -2.7635e-01,  ...,  5.2920e-01,\n",
            "            5.5917e-01,  5.7790e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-9.6532e-01, -1.0709e+00, -1.0840e+00,  ..., -3.1231e-01,\n",
            "           -1.1443e-01, -4.1876e-02],\n",
            "          [-7.3612e-01, -7.5941e-01, -7.8269e-01,  ..., -6.0945e-02,\n",
            "           -1.5407e-01, -1.4381e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.2604e-01, -4.8710e-01, -6.4144e-01,  ...,  5.7319e-01,\n",
            "            4.1885e-01,  1.9068e-01],\n",
            "          [ 3.9227e-01,  8.1098e-01,  6.1860e-01,  ..., -5.0172e-01,\n",
            "           -6.1488e-01, -6.8278e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3722e-02, -2.7160e-01, -1.8919e-01,  ...,  7.3113e-01,\n",
            "            7.4487e-01,  5.3883e-01],\n",
            "          [-5.3165e-01, -2.6982e-01, -4.8405e-01,  ..., -9.1250e-01,\n",
            "           -8.1729e-01, -8.1729e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.7983,  1.1794,  0.8539,  ...,  2.5767,  2.4338,  1.9733],\n",
            "          [-0.7154, -0.6420, -0.4323,  ..., -0.4847, -0.4218, -0.3064]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3491,  1.1051,  1.3275,  ...,  0.3660,  0.3230,  0.3875],\n",
            "          [ 0.0925,  0.3944,  0.4168,  ..., -0.2095, -0.2207, -0.6456]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4184,  0.3477,  0.7190,  ..., -2.1278, -2.3635, -2.6936],\n",
            "          [-0.9805, -0.9696, -0.8388,  ...,  1.8203,  1.8530,  1.7113]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0132, -1.1618, -1.0981,  ...,  0.0621,  0.1258, -0.1077],\n",
            "          [-0.4386,  0.0799, -0.0559,  ..., -0.4633, -0.2287,  0.0923]]],\n",
            "\n",
            "\n",
            "        [[[-0.0105,  0.4775,  0.3043,  ...,  1.0363,  1.0678,  0.9969],\n",
            "          [-0.0460, -0.6120, -0.4524,  ..., -2.8033, -2.9048, -2.7597]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2673,  1.9579,  1.7926,  ...,  1.6953,  1.2673,  0.8004],\n",
            "          [-2.2671, -2.6548, -2.5942,  ...,  0.8461,  1.1368,  1.2943]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1646,  0.1158,  0.6810,  ...,  0.9113,  0.9950,  0.9741],\n",
            "          [ 1.9201,  2.4048,  1.6920,  ...,  0.4234,  0.6800,  0.4234]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1593,  0.9017,  0.6139,  ..., -0.4089, -0.2119, -0.2195],\n",
            "          [ 0.3857,  0.4480,  0.3235,  ...,  0.3235, -0.4612, -0.3615]]],\n",
            "\n",
            "\n",
            "        [[[-0.1535, -0.2851, -0.4167,  ..., -0.6229, -0.6887, -0.5658],\n",
            "          [ 0.1041,  0.4940,  0.7308,  ...,  0.8561,  1.4410,  1.3574]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.6100,  0.7116,  0.8610,  ..., -0.5675, -0.6870, -0.3344],\n",
            "          [ 0.5847, -0.0220, -0.4467,  ...,  0.4027,  0.1752, -0.2798]]],\n",
            "\n",
            "\n",
            "        [[[-0.7308, -0.8019, -0.6385,  ..., -1.0364, -1.0435, -0.8019],\n",
            "          [-0.4903,  0.1881, -0.3611,  ..., -0.9104, -1.3950, -1.3304]]],\n",
            "\n",
            "\n",
            "        [[[-1.2431, -0.5603, -0.6772,  ..., -2.0709, -1.9212, -2.1598],\n",
            "          [-1.5641, -1.6685, -2.3124,  ...,  1.0809,  1.0113,  0.7503]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.5570, -2.4672, -2.6861,  ..., -0.4250, -0.4306, -0.2062],\n",
            "          [ 0.5778,  0.0580, -0.4978,  ..., -0.1213, -0.3544, -0.8025]]],\n",
            "\n",
            "\n",
            "        [[[-0.4333, -0.3993, -0.3312,  ...,  0.5635,  0.4906,  0.4322],\n",
            "          [-1.0276, -1.1513, -0.7625,  ...,  0.1390, -0.0555, -0.0555]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5115,  0.2097,  0.2258,  ...,  1.6060,  1.1352,  1.5979],\n",
            "          [ 0.1482,  0.4284, -0.2565,  ..., -0.1320, -1.0971,  0.0392]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.5398, -0.2473, -0.3152,  ...,  2.0818,  2.0609,  1.9512],\n",
            "          [ 2.8557,  2.3030,  2.0819,  ...,  0.6171,  0.5342,  0.9488]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6715,  2.5913,  2.5975,  ...,  0.0321,  0.3775,  0.5131],\n",
            "          [ 0.9676,  0.9821,  0.9676,  ...,  0.9385,  1.1272,  1.1998]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4947,  0.5208,  0.2750,  ...,  0.8137,  0.6777,  0.8033],\n",
            "          [ 1.0596,  0.5292,  0.7665,  ..., -1.4525, -1.0617, -0.7965]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.4391e+00,  9.6574e-01,  7.8712e-01,  ...,  4.2988e-01,\n",
            "            7.0674e-01,  1.1354e+00],\n",
            "          [-1.3707e+00, -7.8107e-01, -2.8974e-01,  ...,  1.1024e+00,\n",
            "            7.0930e-01,  5.4552e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1627e-01,  1.5280e-01,  4.1714e-01,  ..., -4.9154e-01,\n",
            "           -4.3372e-01, -6.8980e-01],\n",
            "          [ 6.7459e-01, -1.1825e-01,  2.5287e-01,  ...,  2.4796e+00,\n",
            "            1.6530e+00,  1.4674e+00]]],\n",
            "\n",
            "\n",
            "        [[[-9.0082e-01, -7.0549e-01, -7.7060e-01,  ...,  5.5019e-01,\n",
            "            9.5945e-01,  1.0339e+00],\n",
            "          [ 1.3414e+00,  1.4773e+00,  1.2599e+00,  ...,  1.7219e+00,\n",
            "            1.1648e+00,  1.4094e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5358e-01,  2.9474e-04,  2.9474e-04,  ..., -3.1829e-01,\n",
            "           -2.1378e-02, -1.5575e-01],\n",
            "          [ 7.9478e-01,  3.5778e-02,  2.5164e-01,  ..., -1.6633e+00,\n",
            "           -9.6526e-02, -6.6752e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.3495e-02, -8.7007e-02, -1.7709e-01,  ...,  9.2417e-01,\n",
            "            6.6293e-01,  7.4851e-01],\n",
            "          [-5.1849e-01, -4.0157e-01, -1.2023e-01,  ...,  8.9184e-01,\n",
            "            6.9819e-01,  8.2607e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2732e-01,  5.8385e-01,  5.7997e-01,  ...,  7.0599e-01,\n",
            "            1.0666e+00,  5.1212e-01],\n",
            "          [ 7.5261e-01,  6.9684e-01,  6.7059e-01,  ...,  1.2930e-01,\n",
            "            1.1946e-01, -6.2850e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.7138,  1.1062,  0.9875,  ...,  0.9100,  1.3266,  1.5518],\n",
            "          [-0.1415,  0.1085, -0.3985,  ..., -0.1027,  0.2212,  0.2283]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4805,  1.1478,  1.5740,  ..., -1.1017, -1.6168, -1.5712],\n",
            "          [ 1.0406, -0.4601, -0.1938,  ...,  2.3282,  0.5468,  1.2390]]],\n",
            "\n",
            "\n",
            "        [[[-0.4522, -0.7128, -0.2142,  ..., -0.7468,  0.6356,  0.3863],\n",
            "          [ 0.4082,  0.2753,  0.5410,  ..., -0.0834, -0.9071, -1.5182]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2789, -0.4083, -0.6382,  ..., -0.7197, -0.4418, -0.1017],\n",
            "          [-1.6255, -1.4911, -1.1456,  ...,  1.5322,  1.4938,  1.4842]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0546,  0.1971,  0.3142,  ...,  0.3193,  0.4058,  0.3600],\n",
            "          [ 1.1925,  0.9356,  0.7533,  ...,  1.6068,  1.4162,  1.2008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0310, -0.1879, -0.3366,  ..., -0.6837, -0.8406, -0.8902],\n",
            "          [ 1.1761,  1.2396,  1.0968,  ..., -0.2518, -0.0931, -0.2835]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.1883, -1.4415, -1.6517,  ..., -2.0808, -2.0636, -2.1752],\n",
            "          [-0.2648, -0.0304,  0.0633,  ...,  0.1961,  0.2351,  0.3133]]],\n",
            "\n",
            "\n",
            "        [[[-1.8808, -1.8697, -1.8215,  ..., -0.4747, -0.6565, -0.5971],\n",
            "          [ 0.1690,  0.2703,  0.4188,  ..., -0.0065,  0.0610, -0.2293]]],\n",
            "\n",
            "\n",
            "        [[[-0.7972, -0.7642, -0.7477,  ...,  0.8613,  0.6179,  0.3662],\n",
            "          [-0.0169,  0.2668,  0.5650,  ..., -0.4898, -0.3734, -0.4752]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8708,  1.0072,  1.0186,  ..., -0.6679, -0.6679, -0.7020],\n",
            "          [-0.2480, -0.3292, -0.5457,  ..., -0.3238, -0.1831, -0.1506]]],\n",
            "\n",
            "\n",
            "        [[[-0.6707, -0.5801, -0.4941,  ...,  0.6557,  0.8956,  1.1174],\n",
            "          [ 0.0341,  0.0388,  0.2594,  ...,  1.1415,  1.2118,  1.2306]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0969,  1.2171,  1.3519,  ...,  1.4284,  1.2572,  1.1369],\n",
            "          [ 1.2359,  1.3518,  1.3003,  ..., -0.9913, -0.7896, -0.7810]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.0636,  0.8725,  0.4697,  ..., -0.9257, -1.0046, -1.1915],\n",
            "          [-0.9461, -0.9118, -1.1344,  ...,  2.5980,  2.4895,  2.2099]]],\n",
            "\n",
            "\n",
            "        [[[-1.4209, -1.4298, -1.3494,  ..., -0.4161, -0.5411, -0.7912],\n",
            "          [ 2.2762,  2.1357,  2.0527,  ...,  1.7398,  1.6568,  1.5738]]],\n",
            "\n",
            "\n",
            "        [[[-0.6588, -0.4890, -0.3048,  ...,  1.2918,  1.0570,  0.8728],\n",
            "          [ 1.8136,  1.6127,  1.4341,  ...,  0.4816,  0.9132,  1.0769]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3179,  0.0075,  0.2829,  ..., -0.2679, -0.5182, -0.5332],\n",
            "          [-0.1605,  0.1406,  0.0883,  ..., -0.3307, -0.2521, -0.5794]]],\n",
            "\n",
            "\n",
            "        [[[-0.6358, -0.4467, -0.3521,  ..., -0.7602, -0.7204, -0.4367],\n",
            "          [-0.3907, -0.5876, -0.3791,  ...,  0.8252,  0.9063,  0.8368]]],\n",
            "\n",
            "\n",
            "        [[[-0.5950, -0.5228, -0.3224,  ..., -0.8194, -0.7232, -0.6270],\n",
            "          [ 0.8364,  0.8494,  0.7198,  ...,  1.4581,  1.5617,  1.5746]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.5701, -0.3722,  0.0944,  ...,  0.7660,  0.4408,  0.2004],\n",
            "          [ 1.6116,  1.6879,  1.7751,  ..., -3.4257, -3.3167, -3.3821]]],\n",
            "\n",
            "\n",
            "        [[[-0.1827, -0.8838, -1.2996,  ..., -0.8466, -0.5984, -0.5053],\n",
            "          [-3.9016, -3.4998, -2.9943,  ..., -0.5315, -0.7519, -0.7648]]],\n",
            "\n",
            "\n",
            "        [[[-0.0935,  0.4112,  0.2043,  ...,  0.1381,  0.3698,  0.3615],\n",
            "          [-0.2858, -1.1047, -0.5091,  ..., -0.3478,  0.0616, -0.0253]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.5647, -0.6511, -1.0272,  ..., -0.7070, -0.6816, -0.9103],\n",
            "          [-0.0073,  0.1992,  0.6417,  ..., -0.2335, -0.1843, -0.0860]]],\n",
            "\n",
            "\n",
            "        [[[-0.7863, -0.7863, -0.7695,  ...,  1.7795,  1.2200,  0.9088],\n",
            "          [-0.0385, -0.2169, -0.4009,  ..., -2.3584, -2.0851, -2.1855]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5548,  0.1900, -0.0502,  ..., -0.1837, -0.3127, -0.1348],\n",
            "          [-2.9651, -2.9031, -2.7482,  ..., -0.0071,  0.1710,  0.0548]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.2296,  0.4448,  0.6199,  ..., -0.9865, -1.0916, -1.0215],\n",
            "          [-0.1506, -0.3623, -0.5371,  ...,  0.0610,  0.0979, -0.1782]]],\n",
            "\n",
            "\n",
            "        [[[-0.8081, -0.8384, -0.8645,  ...,  0.6898,  0.5899,  0.4770],\n",
            "          [-0.5187, -0.6554, -0.2356,  ..., -0.4406, -1.1923, -1.8269]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4598,  0.4402,  0.2521,  ...,  0.2011,  0.3226,  0.3579],\n",
            "          [-1.4666, -1.3949, -1.2227,  ..., -0.9287, -0.8856, -0.8426]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2090,  0.3479,  0.4494,  ..., -0.5761, -0.2606,  0.1376],\n",
            "          [-0.5740, -0.9493, -1.2186,  ...,  2.5754,  2.5346,  2.2490]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4091,  0.6275,  0.6006,  ..., -0.6099, -0.5908, -0.5142],\n",
            "          [ 1.6904,  1.3472,  1.2377,  ...,  0.4929,  0.2520,  0.0111]]],\n",
            "\n",
            "\n",
            "        [[[-0.4198, -0.4896, -0.5740,  ..., -0.2987, -0.1078,  0.0317],\n",
            "          [-0.2220, -0.2329, -0.3257,  ...,  1.1532,  0.9895,  0.9131]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1204,  0.1992,  0.1650,  ...,  3.8246,  3.5710,  3.2489],\n",
            "          [ 0.9681,  0.9824,  1.0541,  ..., -2.4169, -2.1946, -2.0297]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6322,  2.1957,  1.6351,  ...,  0.5583,  0.5073,  0.5137],\n",
            "          [-1.4676, -1.3587, -1.1898,  ...,  1.0755,  1.1299,  1.2770]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5070,  0.5790,  0.6394,  ..., -0.0568, -0.0770, -0.1173],\n",
            "          [ 1.5069,  1.4808,  1.3830,  ...,  1.3503,  1.3895,  1.2721]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2532,  0.0586, -0.1933,  ...,  0.3219,  0.3104,  0.3905],\n",
            "          [-0.1672,  0.2543,  1.0974,  ...,  0.2192, -0.0970,  0.1138]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2235,  0.2004,  0.6245,  ...,  0.1464, -0.0927, -0.1466],\n",
            "          [-0.0247,  0.4204,  0.0674,  ..., -1.4521, -1.4214, -1.4828]]],\n",
            "\n",
            "\n",
            "        [[[-0.1025,  0.0432,  0.3156,  ...,  0.2143,  0.3093,  0.3663],\n",
            "          [-0.9710, -1.0545, -1.0426,  ...,  0.9026,  0.4849,  0.2343]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.3907,  0.5742,  0.7985,  ..., -0.2888, -0.1597,  0.2684],\n",
            "          [-0.1878, -0.0570, -0.2531,  ...,  0.0192,  0.2916,  0.4441]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6058,  0.8691,  0.9745,  ...,  1.0647,  0.4553, -0.2219],\n",
            "          [ 0.4186,  0.3551, -0.0131,  ..., -1.7904, -2.0316, -2.5141]]],\n",
            "\n",
            "\n",
            "        [[[-0.4408, -0.6872, -0.9206,  ..., -0.4149, -0.2334,  0.0844],\n",
            "          [-2.6994, -2.9905, -2.7788,  ..., -0.9259, -1.1509, -0.9656]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4994, -1.7763, -1.9879,  ...,  0.7478,  0.8048,  0.6012],\n",
            "          [-1.1427, -0.9262, -0.5551,  ..., -1.0808, -1.1891, -0.7871]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6277,  0.6382,  0.6068,  ...,  0.3241,  0.1984,  0.6905],\n",
            "          [-0.8381, -0.1182, -0.1561,  ..., -0.4213, -0.3835, -0.3835]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7517,  0.9185,  0.5585,  ..., -0.6356, -0.4600, -0.4688],\n",
            "          [-0.4353, -0.6980, -0.9054,  ..., -0.6289, -1.2649, -1.4723]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4578, -0.6927, -0.7685,  ...,  2.9595,  3.0959,  2.5049],\n",
            "          [-1.8442, -2.2614, -2.0312,  ...,  0.0261,  0.1268,  0.3858]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9835,  1.5761,  1.9141,  ...,  1.6628,  1.8361,  1.6541],\n",
            "          [ 0.8808,  0.8073,  0.7926,  ..., -0.2369, -0.4428, -0.3840]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8424,  0.7043,  0.4628,  ...,  0.3420,  0.3938,  0.4513],\n",
            "          [-0.2822,  0.1405,  0.4223,  ..., -0.9163, -1.0290, -0.8176]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.5193,  0.5476, -0.0468,  ..., -0.3393, -0.2449, -0.4713],\n",
            "          [-0.8780, -1.2862, -1.3445,  ...,  0.2299, -0.3727, -1.2862]]],\n",
            "\n",
            "\n",
            "        [[[-0.2511, -0.5530, -0.6858,  ..., -1.0903, -1.0602, -1.2473],\n",
            "          [-0.6817, -0.8726,  0.1115,  ...,  0.5227,  0.3905,  0.3905]]],\n",
            "\n",
            "\n",
            "        [[[-1.3291, -1.2556, -0.9436,  ...,  0.1089,  0.0905,  0.0660],\n",
            "          [ 0.4504,  0.2357,  0.2013,  ...,  0.2786,  0.3216,  0.4933]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.4141,  0.4925,  0.3413,  ..., -0.6333, -0.8909, -0.9357],\n",
            "          [ 0.5828,  0.4311,  0.3098,  ...,  0.2391,  0.3604,  0.3806]]],\n",
            "\n",
            "\n",
            "        [[[-1.9597, -1.7292, -1.4886,  ..., -0.4359, -0.2755,  0.1556],\n",
            "          [ 0.9281,  0.8083,  0.5238,  ...,  1.9016,  1.8717,  2.0514]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0559,  0.2437,  0.0037,  ...,  0.8801,  0.6871,  0.6558],\n",
            "          [ 1.0485,  0.7796,  0.6720,  ...,  0.8782,  0.9140,  0.8513]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0885,  0.1401,  0.0534,  ...,  2.1025,  1.9685,  1.9764],\n",
            "          [ 0.8184,  0.6999,  0.5023,  ..., -0.6831, -1.0650, -1.3285]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9197,  0.7090,  0.5533,  ...,  0.4433,  0.3563,  0.3563],\n",
            "          [-0.5778, -0.3220,  0.0983,  ..., -0.3951, -0.1484, -0.4682]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4121,  0.1967,  0.0860,  ..., -0.4248, -0.6709, -0.6032],\n",
            "          [-0.3089, -0.2997, -0.0880,  ..., -0.6862, -0.5942, -0.4930]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.2201, -0.3453, -0.2147,  ...,  0.4823,  0.6838,  0.7600],\n",
            "          [-0.4598, -0.3877, -0.2723,  ..., -0.3084, -0.6544, -0.5607]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5505,  0.3114,  0.1130,  ..., -1.0366, -1.0162, -1.4028],\n",
            "          [-0.2444, -0.1029, -0.1104,  ...,  1.1181,  0.9543,  1.1553]]],\n",
            "\n",
            "\n",
            "        [[[-2.1936, -2.2981, -2.3952,  ...,  0.9128,  0.3303, -0.5060],\n",
            "          [ 1.6560,  1.6872,  1.7184,  ...,  0.9900,  0.8443,  0.8651]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.9096,  0.6841,  0.4392,  ...,  0.3398,  0.3640,  0.4319],\n",
            "          [ 1.2683,  1.3251,  1.5158,  ..., -0.4885, -0.4236, -0.4236]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4803,  0.4830,  0.5945,  ...,  1.5977,  1.6277,  1.5977],\n",
            "          [-0.4970, -0.5397, -0.6678,  ..., -0.0221,  0.0473,  0.2394]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8272,  1.8393,  1.8728,  ...,  0.4047,  0.3955,  0.4503],\n",
            "          [ 0.1692,  0.1381,  0.0812,  ..., -0.4518, -0.5191, -0.5605]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.3428,  0.2772,  0.2608,  ...,  0.5558,  0.6350,  0.6733],\n",
            "          [-0.6541, -0.8179, -0.8288,  ..., -0.1135, -0.1190, -0.2009]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6366,  0.6284,  0.6474,  ..., -0.3509, -0.2938, -0.1197],\n",
            "          [-0.1735,  0.0086, -0.0058,  ..., -0.5090, -0.6048, -0.7917]]],\n",
            "\n",
            "\n",
            "        [[[-0.0314,  0.2054,  0.4276,  ..., -0.0096, -0.0314, -0.0338],\n",
            "          [-0.8003, -0.8102, -0.8494,  ...,  0.4664,  0.4910,  0.5106]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3016, -0.0372,  0.0778,  ..., -2.0949, -1.7213, -1.3304],\n",
            "          [ 1.3173,  1.4106,  1.2345,  ...,  1.1101,  0.8615,  0.3228]]],\n",
            "\n",
            "\n",
            "        [[[-1.1149, -1.1513, -1.2294,  ...,  0.4831,  0.4987,  0.5247],\n",
            "          [ 0.1904,  0.1607, -0.1364,  ...,  0.5767,  0.7649,  0.9234]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5366,  0.3482,  0.4449,  ...,  0.5009,  0.4959,  0.6028],\n",
            "          [ 0.7840,  0.9754,  1.2385,  ...,  0.3135,  0.4491,  0.2737]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.7684,  0.8071,  0.8362,  ..., -0.1036, -0.2877, -0.5250],\n",
            "          [ 0.1969, -0.1123, -0.4134,  ..., -0.0391, -0.0716, -0.2995]]],\n",
            "\n",
            "\n",
            "        [[[-0.9224, -1.0025, -0.9507,  ...,  1.0504,  1.1116,  1.2105],\n",
            "          [-0.0258,  0.1879,  0.3395,  ...,  0.2844, -0.0258, -0.1775]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5585,  1.5257,  1.5585,  ...,  0.7647,  0.4636,  0.5402],\n",
            "          [-0.5787, -0.5691, -0.5980,  ..., -0.2609, -0.1934, -0.0778]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0897,  0.4486,  0.3284,  ...,  1.4102,  1.3201,  0.8794],\n",
            "          [-1.7819, -1.2735, -0.7845,  ..., -1.9384, -2.0166, -1.9188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5289,  0.3270,  0.0651,  ..., -0.1149, -0.1422, -0.0822],\n",
            "          [-1.0892, -1.0170, -0.9990,  ..., -0.0427, -0.0157,  0.0204]]],\n",
            "\n",
            "\n",
            "        [[[-0.0496, -0.2680,  0.0291,  ..., -1.4300, -1.1242, -0.7310],\n",
            "          [ 0.1086,  0.4713,  0.5922,  ..., -0.1734, -0.5092, -0.7644]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.3847,  0.1702,  0.3182,  ...,  0.3034,  0.1258, -0.1332],\n",
            "          [-0.8943, -0.7292, -0.7174,  ...,  0.6510,  0.9813,  1.2172]]],\n",
            "\n",
            "\n",
            "        [[[-0.1264, -0.4717, -0.6986,  ..., -0.6887, -0.6492, -0.3631],\n",
            "          [ 1.8752,  1.6612,  1.1839,  ...,  0.2621,  0.2950,  0.7065]]],\n",
            "\n",
            "\n",
            "        [[[-0.1781,  0.0645, -0.1312,  ..., -0.3503, -0.6243, -0.4599],\n",
            "          [ 0.7091,  0.7509,  0.4996,  ...,  0.7370,  0.1923, -0.2266]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0286,  0.6364,  0.3996,  ...,  0.5544,  0.7548,  0.9370],\n",
            "          [-0.4362, -0.8908, -0.7817,  ..., -0.3635, -0.5271, -0.5635]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0623,  1.0921,  1.4894,  ...,  0.7743,  1.2609,  1.3503],\n",
            "          [-1.1047, -1.1800, -1.3494,  ...,  0.2504, -0.1449, -0.9353]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9162,  0.7951,  0.3994,  ..., -1.5143, -1.6354, -1.6031],\n",
            "          [-0.5712, -0.7969, -0.4395,  ...,  0.4822,  0.6703,  0.4069]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.2625, -0.8454, -0.8120,  ...,  0.8317,  0.3728,  0.2059],\n",
            "          [ 0.3591, -0.4104, -0.9166,  ..., -0.2484, -0.0662,  0.4198]]],\n",
            "\n",
            "\n",
            "        [[[-0.4478, -0.3741, -0.3952,  ..., -0.3005, -0.0689, -0.5320],\n",
            "          [ 0.6826,  0.6826,  0.4208,  ..., -0.9630, -0.8134, -0.4768]]],\n",
            "\n",
            "\n",
            "        [[[-0.4166, -0.7295,  0.1435,  ...,  0.3988,  0.6130,  0.8765],\n",
            "          [-0.1404, -0.2202, -0.0207,  ..., -0.5994, -0.8588, -1.2580]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1125, -0.2428, -0.5111,  ..., -0.2888, -0.4115, -0.3425],\n",
            "          [ 0.5608,  0.2877,  0.1871,  ...,  0.2302,  0.0721,  0.3596]]],\n",
            "\n",
            "\n",
            "        [[[-0.2789, -0.0177, -0.0786,  ..., -0.0960, -0.2963, -0.4878],\n",
            "          [ 0.1250,  0.4838,  0.7489,  ...,  0.2342,  0.1718,  0.0938]]],\n",
            "\n",
            "\n",
            "        [[[-0.7247, -0.7950, -0.7872,  ...,  0.8772,  0.7287,  0.6428],\n",
            "          [ 0.0544,  0.1161, -0.2048,  ..., -1.0193, -1.1180, -1.0317]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.2842,  0.2520, -0.0461,  ..., -0.5134, -0.2878, -0.1509],\n",
            "          [-1.0734, -0.8361, -0.6779,  ...,  0.2978,  0.1132, -0.0714]]],\n",
            "\n",
            "\n",
            "        [[[-0.2507, -0.0952, -0.3130,  ..., -0.3052, -0.1730,  0.1226],\n",
            "          [ 0.1533,  0.0326,  0.2438,  ...,  0.6561,  0.6460,  0.9075]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3031,  0.1815,  0.3465,  ...,  0.0861, -0.2438, -0.4521],\n",
            "          [ 1.0535,  0.8203,  0.8203,  ...,  0.3400,  0.3812,  0.5321]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1603,  0.0439,  0.3427,  ..., -0.8377, -0.2849, -0.1902],\n",
            "          [ 0.4344,  0.7324,  0.4615,  ...,  0.3124,  0.3124,  0.0551]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031, -0.3073,  0.2265,  ..., -0.5245, -0.7541, -0.4004],\n",
            "          [-0.0469, -0.1885, -0.3725,  ...,  1.1278,  0.8023,  0.3635]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1066,  0.1845,  2.8859,  ..., -1.3351, -1.6987, -1.5039],\n",
            "          [ 0.4527,  0.5187,  0.1059,  ...,  0.5352,  0.5352,  0.5022]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.1711, -1.5833, -1.4419,  ..., -0.0876, -0.3853,  0.0463],\n",
            "          [ 0.5179,  0.6734, -0.0598,  ...,  0.2735, -0.5931, -0.9486]]],\n",
            "\n",
            "\n",
            "        [[[-0.3936, -0.3936, -0.3936,  ...,  0.4122, -0.4197, -0.2209],\n",
            "          [-0.5498, -1.4919, -0.7539,  ..., -0.9424, -1.0052, -0.4085]]],\n",
            "\n",
            "\n",
            "        [[[-0.3747, -0.0411, -0.0166,  ...,  0.2090,  0.8123,  0.4493],\n",
            "          [-0.1239, -0.9692, -2.0257,  ...,  1.0251,  0.9195,  1.0515]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2496, -1.0911, -1.2425,  ...,  1.3499,  1.3570,  1.4697],\n",
            "          [ 1.0538,  0.9450,  0.7789,  ..., -2.4106, -2.3418, -2.2388]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2741,  0.9157,  0.4163,  ..., -1.5738, -1.6462, -1.5319],\n",
            "          [-1.8601, -1.2844, -0.7647,  ..., -0.4964, -0.2673,  0.0959]]],\n",
            "\n",
            "\n",
            "        [[[-1.0309, -0.7559, -0.3893,  ..., -2.6403, -2.6586, -2.8713],\n",
            "          [-0.0879, -0.1363, -0.4374,  ...,  3.1063,  2.9396,  2.9181]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.4043, -2.2803, -2.2555,  ...,  0.3228,  0.4685,  0.6358],\n",
            "          [ 2.7501,  2.6538,  2.2954,  ..., -1.0855, -1.1764, -1.1871]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6870,  0.7363,  0.4972,  ..., -0.2391, -0.1177, -0.1860],\n",
            "          [-1.3231, -1.1601, -1.1994,  ..., -0.2834, -0.5532, -0.4857]]],\n",
            "\n",
            "\n",
            "        [[[-0.1499, -0.2024, -0.0675,  ...,  0.0224,  0.0524,  0.0149],\n",
            "          [-0.5546, -0.1155, -0.3681,  ..., -0.6809, -0.7230, -1.0297]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.4513,  2.0387,  1.5760,  ..., -0.2685,  0.2442,  0.9445],\n",
            "          [-1.6680, -1.5070, -1.6143,  ...,  0.9079,  0.3176,  0.3176]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9984,  0.7245, -0.0494,  ...,  1.2901,  1.3973,  0.8614],\n",
            "          [-0.3703, -0.5065, -0.9568,  ...,  0.0171,  0.0695,  0.1951]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3825,  0.5145,  0.3453,  ..., -0.0608, -0.1420,  0.1761],\n",
            "          [ 0.0540, -0.1193, -0.2161,  ...,  0.1814,  0.1458,  0.4057]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 5.7727e-01,  7.5050e-01,  1.1170e-01,  ...,  4.3651e-01,\n",
            "            1.3877e-01,  6.8395e-02],\n",
            "          [ 1.2705e+00,  7.8830e-01,  9.3984e-01,  ...,  1.3807e+00,\n",
            "            1.0776e+00,  8.7096e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3679e-01,  3.1918e-01,  4.6747e-01,  ..., -1.4296e+00,\n",
            "           -1.5472e+00, -1.6802e+00],\n",
            "          [ 2.2031e-01,  6.0180e-01,  6.8794e-01,  ...,  1.2187e-01,\n",
            "            4.0490e-01, -2.3501e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.6878e+00, -2.7934e+00, -2.8386e+00,  ..., -7.3461e-01,\n",
            "           -7.3461e-01, -8.1756e-01],\n",
            "          [ 8.2062e-01,  8.6917e-01,  1.6137e+00,  ...,  3.3504e-01,\n",
            "            8.8536e-01,  1.2738e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3185e-01,  2.4314e-01,  3.1929e-01,  ...,  4.7744e-01,\n",
            "           -1.6102e-01,  2.6419e-02],\n",
            "          [ 1.1775e+00,  1.1668e+00,  6.9613e-01,  ...,  9.7112e-02,\n",
            "            8.4148e-04, -5.0191e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.6923e-02, -2.0281e-01, -4.2312e-01,  ..., -4.6443e-01,\n",
            "           -1.9592e-01, -1.6150e-01],\n",
            "          [-5.6750e-01, -1.0212e+00, -7.8174e-01,  ...,  1.1086e+00,\n",
            "            9.3216e-01,  5.6670e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.3965e-01, -3.0006e-01, -2.7366e-01,  ..., -8.1482e-01,\n",
            "           -7.0923e-01, -3.3965e-01],\n",
            "          [ 9.3286e-01,  1.0073e+00,  9.6478e-01,  ...,  8.7967e-01,\n",
            "            1.2946e+00,  1.4968e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.0995,  0.5329,  0.7256,  ..., -0.3889, -0.3683,  0.4710],\n",
            "          [ 1.8783,  1.3296,  1.1676,  ...,  1.0803,  1.8408,  1.3920]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5186,  1.8961,  1.8144,  ...,  0.0715, -0.9981, -1.3882],\n",
            "          [ 0.4987, -0.1903, -0.0101,  ..., -0.6567, -1.3245, -0.4235]]],\n",
            "\n",
            "\n",
            "        [[[-1.6698, -1.3882, -1.0672,  ..., -0.2505, -0.1097, -0.3969],\n",
            "          [-0.0501,  0.7605,  0.2780,  ...,  0.0850,  0.5868,  0.4227]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.8969, -0.7807, -0.5700,  ...,  0.1493,  0.1856,  0.0694],\n",
            "          [ 0.3545,  0.8184,  0.3469,  ...,  1.0694,  1.4345,  0.5066]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0115,  0.0786, -0.2217,  ..., -0.3419, -0.3949, -0.3914],\n",
            "          [ 1.0850,  0.1540,  0.8988,  ..., -0.5908, -1.2347, -0.8080]]],\n",
            "\n",
            "\n",
            "        [[[-1.0815, -1.0448, -1.2098,  ..., -1.0815, -0.5593, -0.8983],\n",
            "          [-1.9589, -0.4876, -1.4645,  ...,  0.3952,  1.1250,  1.0308]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.3910, -0.3984, -0.4058,  ..., -0.6411, -0.8175, -0.6925],\n",
            "          [ 1.8401,  1.5571,  2.2904,  ...,  1.4671,  2.1746,  1.1326]]],\n",
            "\n",
            "\n",
            "        [[[-1.0296, -0.9237, -0.6061,  ..., -0.4767, -1.7707, -1.8060],\n",
            "          [ 2.0057,  1.4911,  2.1527,  ...,  0.9324,  1.0647,  0.5354]]],\n",
            "\n",
            "\n",
            "        [[[-1.0466, -1.3503, -1.3672,  ..., -0.0933, -0.5911, -0.5405],\n",
            "          [ 0.8040,  0.5465,  0.9802,  ..., -0.2395,  0.1399,  0.0180]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.6500, -1.2721, -0.8360,  ..., -0.3563, -0.6543, -0.8578],\n",
            "          [ 0.6056,  1.1199,  0.7845,  ..., -1.2168, -1.0827, -1.5187]]],\n",
            "\n",
            "\n",
            "        [[[-0.7451, -0.9053, -0.6857,  ...,  0.8987,  1.6820,  1.4684],\n",
            "          [-0.5518, -0.9071,  0.0996,  ..., -1.6276, -1.0453, -1.7065]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5828,  1.3414,  1.1630,  ...,  0.4756,  0.1082,  0.1607],\n",
            "          [-0.9162, -1.3230, -0.1647,  ...,  0.2067,  0.5073,  0.6134]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.0951,  0.1423, -0.2363,  ..., -0.0758, -0.0823,  0.0782],\n",
            "          [ 0.6454,  1.1527,  0.8077,  ...,  1.1831,  0.7468,  0.4323]]],\n",
            "\n",
            "\n",
            "        [[[-0.4612, -0.6338, -1.2759,  ...,  0.9956,  0.7609,  0.1533],\n",
            "          [-0.0562, -0.0795,  0.7382,  ...,  1.0186,  0.3410,  1.0420]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2300,  0.0271, -0.4663,  ..., -0.5948, -0.3987, -0.5340],\n",
            "          [ 0.5984,  1.0653,  0.5529,  ...,  0.2796,  0.1999, -0.1759]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0605, -0.0401, -0.2666,  ...,  0.0102,  0.0773, -0.2079],\n",
            "          [ 1.8698,  2.3241,  2.0212,  ...,  0.6416,  0.5406, -0.2670]]],\n",
            "\n",
            "\n",
            "        [[[-0.5084, -0.1410,  0.0149,  ..., -1.4103, -1.6775, -0.7534],\n",
            "          [-0.1348, -0.6240, -0.1854,  ...,  1.0293,  1.8728,  1.1474]]],\n",
            "\n",
            "\n",
            "        [[[-0.5722, -0.7454, -0.5361,  ...,  0.4816,  0.3805,  0.2939],\n",
            "          [ 0.5440,  1.0007,  1.5001,  ..., -0.1552,  0.0731, -0.4977]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.7135, -0.9240, -1.3173,  ..., -0.4757, -0.6130, -0.6038],\n",
            "          [-0.1529, -0.5284,  0.2055,  ..., -0.4090, -0.6479, -0.6309]]],\n",
            "\n",
            "\n",
            "        [[[-0.3175, -0.2258, -0.0654,  ...,  1.0118,  0.9277,  1.5312],\n",
            "          [-0.5065, -0.7905, -0.0380,  ...,  0.4163,  1.0409,  0.2317]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8290,  1.0625,  1.4678,  ...,  1.3533,  1.0537,  0.5075],\n",
            "          [-0.4547, -0.8767, -0.2074,  ..., -0.9640, -0.7312, -0.9203]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0168,  0.4082,  0.2308,  ...,  1.1909,  0.6222,  0.5366],\n",
            "          [-0.1305, -0.5705, -0.2981,  ..., -0.7486, -0.7800, -0.5181]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6255,  0.4484,  0.6034,  ...,  0.2768,  0.4816,  0.4262],\n",
            "          [-0.4123,  0.0182, -0.3461,  ..., -0.4454, -0.5006, -0.3350]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6221, -0.0169,  0.3134,  ...,  1.2325, -0.3256, -0.5841],\n",
            "          [-0.5535, -0.0128, -1.3292,  ..., -0.0833,  0.7864,  1.2565]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.5751, -0.0373,  0.8677,  ..., -0.7454, -0.3621, -0.3195],\n",
            "          [ 1.3468,  0.3420, -0.2377,  ...,  0.6512,  0.0812,  0.4870]]],\n",
            "\n",
            "\n",
            "        [[[-1.0180, -1.0365, -0.8023,  ...,  0.6829,  0.9047,  0.7014],\n",
            "          [ 0.0242,  0.6698,  0.0353,  ..., -0.0537, -0.5435, -0.6660]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9238,  0.6530,  0.8805,  ...,  0.9454,  0.4201, -0.4247],\n",
            "          [-1.2475, -1.2970, -1.4210,  ..., -0.6895, -0.1067, -0.5035]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.8855, -0.6869, -0.5140,  ...,  2.0484,  1.9139,  1.3565],\n",
            "          [ 1.2073,  0.3799,  1.1279,  ...,  0.8786,  0.2212,  1.0486]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5199,  1.4791,  1.4383,  ...,  0.5207,  0.5750,  0.6974],\n",
            "          [ 0.0247,  0.0137, -0.8394,  ..., -0.3187, -1.0388, -0.7175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7952,  0.4748,  0.3833,  ...,  0.8802,  0.8344,  1.1025],\n",
            "          [-1.2721, -0.8097, -1.0891,  ..., -0.3954, -0.4532, -0.9060]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.9115,  1.4979,  1.4574,  ...,  0.2173,  0.1027,  0.0623],\n",
            "          [-0.9944, -0.9279, -0.8059,  ...,  1.3232,  1.2012,  0.5248]]],\n",
            "\n",
            "\n",
            "        [[[-0.0585, -0.1823, -0.2260,  ..., -0.7648, -0.1968,  1.0410],\n",
            "          [ 0.6613,  0.7924,  1.2360,  ...,  0.5403,  0.1975,  0.5000]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1138,  2.0474,  1.5164,  ...,  0.4175,  0.5429,  0.3512],\n",
            "          [-1.0070, -0.6606, -1.4876,  ..., -0.1130,  0.4458,  0.1440]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.2471,  1.4241,  1.7075,  ..., -2.4597, -1.8459, -2.1056],\n",
            "          [-0.3660, -1.2144, -0.6760,  ...,  0.3356,  1.3144, -0.2028]]],\n",
            "\n",
            "\n",
            "        [[[-1.5301, -0.9203, -0.6094,  ..., -1.2551, -0.6692,  0.1080],\n",
            "          [ 0.3109, -0.7859,  0.0653,  ..., -0.3767,  1.6368, -0.3930]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0782,  0.0668, -0.2468,  ..., -0.1856,  0.1356, -0.0594],\n",
            "          [ 0.6733, -0.5193,  0.3281,  ..., -0.1349,  0.8695, -0.0721]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.8805, -1.2637, -0.6095,  ...,  0.3111, -0.6580, -1.1910],\n",
            "          [ 1.9655, -0.3705,  1.5550,  ..., -0.8519,  0.9179, -0.5687]]],\n",
            "\n",
            "\n",
            "        [[[-0.9872, -1.5814, -1.6433,  ...,  0.8823,  0.7585,  0.5975],\n",
            "          [ 1.2417, -0.5014,  1.2922,  ...,  1.0522, -0.5014,  0.1680]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4954,  0.2557,  0.9095,  ...,  0.6589,  0.4082,  0.2339],\n",
            "          [-1.4440,  0.1079, -1.4966,  ...,  0.4235,  1.9754,  0.4761]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2683,  0.0190, -0.1072,  ...,  0.1171, -0.1282,  0.2362],\n",
            "          [ 1.6712,  0.1123,  1.2780,  ..., -1.0674,  0.0140, -0.8146]]],\n",
            "\n",
            "\n",
            "        [[[-0.0426, -0.1705, -0.2650,  ...,  0.0742, -0.2595, -0.1205],\n",
            "          [-0.2721, -1.5708, -0.9665,  ...,  0.4223,  1.3868,  1.0653]]],\n",
            "\n",
            "\n",
            "        [[[-0.1771, -0.3493, -0.3598,  ...,  0.7000,  1.4308,  0.5120],\n",
            "          [ 1.6081, -0.1931,  0.8794,  ..., -0.2618, -0.4131, -1.0318]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.4760,  0.1132,  1.3376,  ...,  2.2212,  1.1672,  0.8159],\n",
            "          [-0.0267, -0.7694, -0.0712,  ..., -0.1752, -1.6013,  0.2853]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2530,  0.1935,  0.0828,  ...,  0.7976,  0.6189,  0.5168],\n",
            "          [-0.3696,  0.4134, -0.9177,  ..., -0.7350,  0.1133, -0.2913]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5046,  0.3842,  0.5286,  ..., -0.8015, -1.1265, -0.7774],\n",
            "          [ 0.2570, -0.0130,  0.7113,  ...,  1.0669,  0.4150,  1.1723]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7027, -0.4842, -0.1720,  ...,  0.0278,  0.3837, -0.5841],\n",
            "          [-1.4490, -0.1329, -1.7974,  ...,  0.5562, -0.8839,  0.5794]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2166,  0.2482, -0.1305,  ...,  0.2355,  0.1472,  0.3302],\n",
            "          [-1.1494,  0.0600, -1.9529,  ...,  0.1785, -0.6251,  0.7451]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1756, -0.1737, -0.1055,  ..., -1.2639, -0.7614, -1.6131],\n",
            "          [ 0.1536,  1.4375, -0.3822,  ...,  1.3769, -0.4429,  1.8217]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.1811, -1.4008, -1.4133,  ...,  1.4050,  1.2104,  1.1916],\n",
            "          [ 0.0474,  1.5827,  0.2551,  ...,  0.1587,  1.1673, -0.1528]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5512,  1.3535,  0.5218,  ...,  0.2832,  0.0787, -0.2145],\n",
            "          [ 0.8539, -1.1749,  0.4498,  ...,  1.0475, -0.2320,  1.2159]]],\n",
            "\n",
            "\n",
            "        [[[-0.3508, -0.5633, -0.2702,  ...,  0.1036,  0.1695, -0.2336],\n",
            "          [-0.6451,  0.9867, -1.0130,  ...,  0.8452, -0.9659,  0.9867]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8870,  0.8985,  0.7981,  ...,  1.0762,  1.0608,  1.2616],\n",
            "          [ 0.2459, -0.0522,  0.1427,  ...,  0.4751,  0.1350, -0.6598]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8312,  0.9136,  0.9165,  ...,  0.4164,  0.2752,  0.3782],\n",
            "          [ 0.0318,  0.2769, -0.1329,  ...,  0.7543, -0.0696,  0.0741]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3818,  0.3752,  0.2406,  ..., -0.2159, -0.1338, -0.1896],\n",
            "          [ 2.1972,  0.4060,  0.7479,  ...,  0.0386,  0.2121, -1.3290]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.1474, -0.2739, -0.3332,  ..., -0.2581, -0.2700, -0.0328],\n",
            "          [-0.5164,  0.1004,  0.1559,  ..., -0.5164, -1.4382, -1.7085]]],\n",
            "\n",
            "\n",
            "        [[[-0.1783, -0.4246, -0.4298,  ...,  1.0269,  0.9457,  0.9693],\n",
            "          [-0.3597, -0.3277, -0.3104,  ...,  1.8710,  1.2393,  1.6982]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1514,  1.3868,  1.4332,  ..., -0.1950, -0.0590, -0.0291],\n",
            "          [ 3.0282,  4.1315,  4.7996,  ..., -0.2205, -0.0182, -1.4035]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0460, -0.2182, -0.4245,  ...,  0.8001,  0.4714,  0.3876],\n",
            "          [ 1.4203,  1.4534,  1.6608,  ...,  0.4413,  0.5823,  0.5657]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2905,  0.3172,  0.2238,  ...,  0.6285,  0.6108,  0.7175],\n",
            "          [ 0.4535,  0.3347,  0.4103,  ..., -0.2108, -0.3026, -0.5726]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1315,  1.1068,  0.9894,  ...,  0.2848,  0.1427,  0.2354],\n",
            "          [-0.9372, -0.8577, -0.7783,  ..., -1.1834, -1.1040, -1.2708]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.2239,  0.3215,  0.4707,  ...,  0.9529,  1.0907,  1.2973],\n",
            "          [-0.9705, -0.7513, -0.5850,  ...,  0.5562,  0.6243,  0.2917]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4156,  1.1857,  0.6193,  ...,  0.4286,  0.3108,  0.2323],\n",
            "          [ 0.3356,  0.5982,  1.3102,  ..., -1.0262, -0.9017, -0.9017]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0834,  0.0364,  0.0717,  ..., -0.7505, -0.6389, -0.4862],\n",
            "          [-0.9787, -0.8825, -0.9787,  ...,  0.7529,  0.5364,  0.3280]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7701, -0.5328, -0.3429,  ...,  1.3662,  1.2119,  1.1110],\n",
            "          [ 0.8593,  0.3205,  0.0252,  ...,  0.4090,  0.3426,  0.3278]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3665,  1.3740,  1.3815,  ...,  0.0049,  0.3041,  0.3041],\n",
            "          [ 0.3110,  0.0075, -0.0550,  ...,  1.0431,  0.8913,  0.4985]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1854, -0.0160, -0.0577,  ..., -0.3564, -0.4119, -0.3147],\n",
            "          [ 0.7991,  1.1635,  1.5956,  ..., -0.3956, -0.4804, -0.4719]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.3446, -0.4046, -0.3961,  ...,  0.5648,  0.5562,  0.5048],\n",
            "          [-0.6842, -0.3529, -0.0517,  ...,  0.4002,  0.3199,  0.4303]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3550,  0.2730,  0.1091,  ..., -2.3339, -2.1617, -1.9486],\n",
            "          [ 0.7611,  0.8539,  0.8230,  ...,  2.5258,  2.1749,  1.9273]]],\n",
            "\n",
            "\n",
            "        [[[-1.6635, -1.6276, -1.7137,  ...,  1.7235,  1.1997,  0.9270],\n",
            "          [ 1.4560,  1.3706,  1.5699,  ..., -0.8127, -0.5944, -0.4710]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1313,  0.8960,  0.6788,  ...,  0.3228,  0.0995, -0.0513],\n",
            "          [-1.2005, -0.9672, -0.1214,  ...,  0.0536, -0.0047,  0.5057]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0352, -0.0986, -0.1458,  ..., -0.5865, -0.4134, -0.5314],\n",
            "          [-0.0549,  0.0349,  0.2819,  ..., -2.5923, -2.5137, -1.8064]]],\n",
            "\n",
            "\n",
            "        [[[-0.3513, -0.3231, -0.1891,  ...,  1.2561,  0.8825,  0.7062],\n",
            "          [-1.6417, -2.7427, -3.4996,  ...,  0.5831,  0.6634,  1.2368]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.5978,  0.6865,  0.9008,  ..., -0.9614, -0.7397, -0.6658],\n",
            "          [ 1.9031,  1.6348,  0.7599,  ..., -0.3249,  0.1417,  0.0367]]],\n",
            "\n",
            "\n",
            "        [[[-0.2714, -0.6848, -0.5258,  ..., -0.8438, -0.6466, -0.5894],\n",
            "          [-0.0285,  0.1754,  0.4229,  ...,  1.9955,  2.2139,  1.7189]]],\n",
            "\n",
            "\n",
            "        [[[-0.6163, -0.1395,  0.5551,  ..., -0.2076, -0.1804,  0.6640],\n",
            "          [ 1.2082,  0.2766,  0.1321,  ...,  0.3087,  0.1160, -0.4140]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.6423,  0.4688,  0.6149,  ..., -1.3577, -1.0016, -0.4353],\n",
            "          [-0.8250, -0.1064, -0.6743,  ...,  2.3507,  1.2149,  0.6702]]],\n",
            "\n",
            "\n",
            "        [[[-0.1273, -0.0291, -0.6181,  ..., -1.3142, -1.2339, -1.1089],\n",
            "          [-0.4068, -0.8576, -1.0115,  ...,  0.7804,  0.5825,  0.6375]]],\n",
            "\n",
            "\n",
            "        [[[-1.4254, -1.3679, -1.3335,  ...,  2.7584,  2.1492,  1.5171],\n",
            "          [ 0.7974,  1.3648,  1.1327,  ..., -0.3633, -0.0409,  0.2944]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.5492,  0.3317,  0.3713,  ...,  1.5772,  1.1720,  0.8260],\n",
            "          [ 0.6008,  0.6370, -0.1226,  ..., -0.4481, -0.4240, -0.1105]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2873,  0.6518,  0.7585,  ..., -0.3795, -0.7262, -0.5217],\n",
            "          [-0.1519, -0.3450, -0.4201,  ..., -0.7956, -0.8063, -1.1175]]],\n",
            "\n",
            "\n",
            "        [[[-0.5289, -0.4100, -0.4649,  ...,  0.1387,  0.0746,  0.5319],\n",
            "          [-0.9848, -1.0693, -0.5622,  ..., -0.1608, -0.5305, -1.0165]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1903, -0.0187, -0.0229,  ..., -0.3536, -0.3578, -0.3368],\n",
            "          [-1.5417, -0.9131,  1.4533,  ...,  0.2146,  0.0112, -0.3770]]],\n",
            "\n",
            "\n",
            "        [[[-0.2613, -0.4388, -0.5074,  ..., -0.0111,  0.0696,  0.0817],\n",
            "          [-0.0973, -0.2219,  0.0687,  ..., -0.3298, -0.6786, -0.5540]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1382,  0.0975,  0.1464,  ..., -0.3185, -0.4408, -0.3348],\n",
            "          [-0.8137, -0.7271, -0.5416,  ..., -0.1583, -0.2325, -0.2820]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.5890e-01,  5.6492e-01,  6.4534e-01,  ...,  1.2258e-01,\n",
            "           -5.1668e-02, -9.1880e-02],\n",
            "          [ 1.6606e-01,  1.1801e+00,  1.0273e+00,  ...,  1.8191e+00,\n",
            "            1.6524e+00,  1.0690e+00]]],\n",
            "\n",
            "\n",
            "        [[[-9.0426e-04,  1.0618e-01,  1.8649e-01,  ...,  2.8465e-01,\n",
            "           -8.1217e-02, -8.8434e-01],\n",
            "          [ 1.2015e+00,  1.0042e+00,  9.5865e-01,  ..., -4.3185e-02,\n",
            "            4.5773e-01,  8.6757e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.5122e-01, -9.8199e-01, -9.9983e-01,  ..., -3.6855e-02,\n",
            "            1.6525e-01,  2.6630e-01],\n",
            "          [ 8.3523e-01,  1.1903e+00,  1.0212e+00,  ...,  5.6473e-01,\n",
            "            2.7733e-01,  3.1114e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.9572e-01,  5.8622e-01,  4.8453e-01,  ..., -7.2003e-01,\n",
            "           -1.2441e+00, -1.2832e+00],\n",
            "          [ 4.0291e-01,  5.2940e-01,  1.5518e+00,  ..., -1.3466e-01,\n",
            "            2.3453e-02,  6.1372e-01]]],\n",
            "\n",
            "\n",
            "        [[[-9.0671e-01, -4.3371e-01,  2.5774e-02,  ...,  5.7986e-01,\n",
            "            6.5419e-01,  6.4067e-01],\n",
            "          [-1.8671e-01, -3.6877e-01, -7.9661e-01,  ...,  4.5050e-01,\n",
            "            8.4193e-01,  3.6858e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0739e+00,  6.5455e-01,  9.0331e-01,  ...,  4.4843e-01,\n",
            "            7.3273e-01,  7.0430e-01],\n",
            "          [ 5.8978e-01, -1.4415e-01,  1.4942e-01,  ...,  6.8764e-01,\n",
            "            7.7571e-01, -3.2029e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.1830,  1.3842,  1.8129,  ..., -0.6452, -0.1466,  0.1246],\n",
            "          [-0.6435, -1.2660, -1.3473,  ..., -0.3728, -1.1848, -0.6615]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0229, -0.0904, -0.0832,  ...,  0.7926,  0.7566,  0.7566],\n",
            "          [-0.3807,  0.9047,  0.6725,  ..., -0.5548, -2.0226, -1.7573]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7025,  0.6958,  0.6958,  ..., -0.1914, -0.2549, -0.2014],\n",
            "          [-0.3817,  0.0206, -1.9853,  ...,  0.5666,  0.6011,  0.6644]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0584,  0.5520,  0.6722,  ...,  4.7320,  4.5100,  3.9089],\n",
            "          [-0.3764, -0.1141, -0.7381,  ..., -3.3064, -3.4782, -3.7224]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8923,  1.6657,  1.5398,  ...,  0.2745,  0.3437,  0.4256],\n",
            "          [-3.3623, -3.2209, -3.1556,  ..., -0.2291, -1.1212, -0.4249]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3885,  0.2331,  0.2696,  ..., -0.7039, -0.6353, -0.6673],\n",
            "          [-1.2283, -0.5056, -0.8563,  ...,  0.1428, -0.3036,  0.4510]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.8160, -0.9759, -0.7118,  ...,  0.6716,  0.4700,  0.1572],\n",
            "          [-0.7619,  0.1019, -0.5800,  ..., -0.8755, -0.6596, -0.1367]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1622,  0.1476,  0.2024,  ...,  0.1732,  0.0635,  0.1147],\n",
            "          [-0.7207, -0.4771, -1.3175,  ..., -0.0387,  1.1061,  0.6920]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2553,  0.5712,  0.6277,  ...,  0.5938,  0.6277,  0.7969],\n",
            "          [ 1.3010,  0.2814,  0.7296,  ..., -1.1304, -0.1108, -0.8391]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.9754,  1.0581,  0.5804,  ..., -2.4602, -1.7988, -1.9825],\n",
            "          [ 0.6881,  0.7626,  1.3400,  ...,  1.0420,  0.3528, -0.6902]]],\n",
            "\n",
            "\n",
            "        [[[-2.2968, -1.4743, -2.0489,  ...,  1.4436,  1.4887,  0.3959],\n",
            "          [-0.6347, -0.9697, -1.5869,  ..., -0.2467,  0.4057, -0.1233]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5223,  1.7939,  2.0918,  ..., -0.0505, -0.3827, -0.3140],\n",
            "          [-0.4848, -0.3515, -0.5610,  ...,  0.4868,  1.1917,  1.3822]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.9374, -1.5237, -0.5147,  ..., -0.4465,  0.5489,  0.3989],\n",
            "          [ 1.4964,  1.4774,  0.5050,  ..., -0.1814,  0.8100,  1.3058]]],\n",
            "\n",
            "\n",
            "        [[[-0.0524,  0.0040,  0.2071,  ..., -0.1314,  0.0266,  0.7149],\n",
            "          [ 1.1877, -0.1684, -1.2055,  ..., -0.4676,  0.3700,  1.1079]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1795, -1.1413, -0.6478,  ...,  0.5278,  0.7600, -0.5607],\n",
            "          [ 0.9877, -0.2716,  0.3580,  ...,  0.4883,  0.4883,  0.5317]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2819, -1.6639, -1.3689,  ..., -0.8128, -0.7451, -0.0149],\n",
            "          [-1.9916, -1.2840, -0.7336,  ..., -1.5199, -0.4388, -0.3208]]],\n",
            "\n",
            "\n",
            "        [[[-0.8763, -1.0544, -1.1959,  ..., -0.0592,  0.1347,  0.1189],\n",
            "          [-1.0828, -0.7388, -0.8043,  ..., -0.2475,  0.7188,  0.7024]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5964,  0.3568,  0.1359,  ..., -0.8884, -0.2447, -0.2118],\n",
            "          [-0.2854, -0.4916, -0.3541,  ..., -0.9212, -0.2167,  0.0411]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1571, -0.1312, -0.5485,  ...,  0.4417,  0.8931,  1.3560],\n",
            "          [-0.1293, -0.3853, -0.8333,  ...,  0.2227,  0.1907,  0.1107]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6984,  3.0470,  3.0905,  ..., -0.5371, -0.3029, -0.7332],\n",
            "          [ 0.4093,  1.0445,  1.0445,  ...,  0.4689, -0.5236, -1.3772]]],\n",
            "\n",
            "\n",
            "        [[[-0.5865, -0.4041, -0.3230,  ..., -0.1963, -0.2065, -0.4193],\n",
            "          [ 0.3768, -0.0306, -0.9982,  ..., -0.2852,  0.3428,  0.6993]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7080, -0.3161,  0.1369,  ...,  0.1960,  0.2058,  0.2354],\n",
            "          [-0.8339, -0.8174, -0.2314,  ..., -0.2396,  0.0162,  0.6682]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5830,  0.0992,  0.0262,  ...,  0.5191,  0.7154,  0.4461],\n",
            "          [-1.1906,  1.3736,  0.6843,  ...,  0.7119,  0.4178, -0.6943]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0603,  0.3824,  0.2234,  ...,  0.4744, -0.3077, -0.0401],\n",
            "          [-0.3624, -0.1722, -0.4489,  ..., -0.7169, -0.8985, -0.2154]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4123, -0.3761,  0.3597,  ..., -0.4726, -0.6596, -0.6958],\n",
            "          [-0.6189, -1.9447, -1.4973,  ..., -0.2874,  1.4528, -0.0885]]],\n",
            "\n",
            "\n",
            "        [[[-0.5616, -0.4913, -0.1954,  ..., -0.1769,  0.0340, -0.0992],\n",
            "          [ 0.2527,  0.5462, -0.1582,  ...,  0.5462,  0.9102,  0.4640]]],\n",
            "\n",
            "\n",
            "        [[[-0.3616, -0.2399,  0.1203,  ..., -0.8240,  0.2419, -1.6028],\n",
            "          [ 0.5307,  0.4786,  0.3222,  ...,  1.3023,  0.4578,  0.8956]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5503,  1.8614,  1.8433,  ..., -0.5426, -0.5094, -0.7631],\n",
            "          [ 0.1164,  0.2387, -0.1950,  ...,  0.3165,  0.2276, -0.7065]]],\n",
            "\n",
            "\n",
            "        [[[-0.4506, -0.6933, -0.4986,  ..., -1.1698, -0.9510, -0.9900],\n",
            "          [-0.0892, -0.1308, -0.0580,  ..., -0.6713, -0.4946, -0.0372]]],\n",
            "\n",
            "\n",
            "        [[[-1.1227, -0.7881, -0.6004,  ...,  1.8549,  1.7986,  1.3764],\n",
            "          [ 0.2475,  0.1944, -0.0395,  ..., -1.6235,  0.2900,  0.1625]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 2.2638,  2.6291,  2.2796,  ..., -0.6112, -0.3991, -0.2773],\n",
            "          [ 0.1788, -0.7038,  0.1228,  ..., -0.8439, -0.9280, -0.6057]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0523, -0.0224,  0.0709,  ...,  0.3445,  0.1921,  0.1984],\n",
            "          [-0.3315, -0.4305, -0.1211,  ..., -1.3585, -1.4822, -0.6656]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7629, -0.4594, -1.4992,  ..., -2.9676, -2.9716, -3.0430],\n",
            "          [-0.4919, -0.6704, -1.3589,  ..., -0.5556,  0.2094,  0.4134]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3123,  0.0460,  0.2010,  ...,  0.0847,  0.4431,  0.0751],\n",
            "          [-0.0120,  0.1807,  0.0431,  ...,  0.0156,  1.3730, -0.2229]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5159,  0.1987,  0.1410,  ...,  0.2564,  0.0430, -0.6146],\n",
            "          [-0.1719,  0.3773,  0.0932,  ..., -0.0867,  0.3016, -1.0716]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0206,  0.0736,  0.3575,  ...,  0.0849, -0.9446, -1.0317],\n",
            "          [-0.5332, -0.1227, -0.9702,  ..., -1.2086, -0.3346, -0.1889]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.1758e+00, -9.2907e-01, -1.0442e+00,  ...,  1.4825e+00,\n",
            "            1.6010e+00,  1.4924e+00],\n",
            "          [-6.6949e-01, -6.0466e-01, -6.0101e-02,  ...,  6.6598e-01,\n",
            "            4.5853e-01,  4.5853e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6734e+00,  1.4511e+00,  1.4086e+00,  ...,  6.6328e-01,\n",
            "            4.5408e-01, -3.3044e-01],\n",
            "          [ 5.8152e-01,  4.9310e-01,  4.7703e-01,  ...,  2.0605e+00,\n",
            "           -9.5373e-01,  1.3934e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3419e+00, -2.1986e-01, -4.1031e-01,  ..., -1.7687e-02,\n",
            "           -6.1637e-02, -1.8470e-01],\n",
            "          [ 1.0901e+00, -2.7803e+00, -8.9541e-01,  ..., -6.0950e-01,\n",
            "            6.8214e-02, -2.8123e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1366e-01, -3.2661e-01, -5.7183e-01,  ...,  4.8003e-01,\n",
            "            3.9614e-01, -1.6860e-02],\n",
            "          [ 5.1559e-01,  2.7733e-01,  6.0825e-01,  ..., -6.8894e-01,\n",
            "           -7.0218e-01, -3.5803e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1439e-03, -1.6438e-01, -1.4783e-01,  ..., -1.6438e-01,\n",
            "           -2.2507e-01, -5.4508e-01],\n",
            "          [ 6.9194e-02,  4.2141e-01,  6.5286e-01,  ..., -8.0630e-01,\n",
            "           -7.7611e-01, -5.5472e-01]]],\n",
            "\n",
            "\n",
            "        [[[-6.9075e-01, -6.1405e-01, -9.8110e-01,  ...,  8.3221e-01,\n",
            "            1.1554e+00,  1.4184e+00],\n",
            "          [-4.8102e-01, -3.0041e-01,  1.0656e-02,  ..., -7.6198e-01,\n",
            "           -1.0831e+00, -1.3038e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.3033,  1.2035,  1.2718,  ...,  0.2841,  0.2999,  0.3366],\n",
            "          [-1.0086, -0.7008, -0.5550,  ...,  0.5709,  0.7167,  0.7815]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5179,  0.5306,  0.6194,  ..., -2.0574, -1.9813, -1.5563],\n",
            "          [ 1.1730,  1.2632,  0.8122,  ...,  2.3355,  2.2554,  1.8344]]],\n",
            "\n",
            "\n",
            "        [[[-1.3165, -1.2391, -0.8521,  ...,  1.4955,  1.4310,  1.3988],\n",
            "          [ 1.8363,  1.5575,  1.3029,  ..., -0.1882,  0.1027,  0.1027]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2171, -0.6472, -0.5354,  ..., -0.7247, -0.0536, -0.7935],\n",
            "          [-1.2890, -0.7036, -0.6827,  ...,  1.1780,  1.5752,  0.9899]]],\n",
            "\n",
            "\n",
            "        [[[-1.0535, -1.3980, -1.2175,  ..., -0.2906, -0.7089, -0.9550],\n",
            "          [ 1.3057,  0.2669,  0.0591,  ...,  0.2291, -0.1675, -1.3386]]],\n",
            "\n",
            "\n",
            "        [[[-0.2674,  0.6334,  0.7027,  ..., -0.8563,  0.3043,  0.0791],\n",
            "          [-2.6037, -1.5666, -0.2989,  ...,  0.0180, -0.3854, -1.5090]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.6192, -0.3870, -0.2638,  ...,  0.2291,  0.7923, -0.4926],\n",
            "          [-0.8576, -1.2955, -1.7060,  ...,  0.1825,  0.6478,  0.2920]]],\n",
            "\n",
            "\n",
            "        [[[-0.5537, -1.0643, -0.9508,  ..., -0.9225, -0.0430, -0.4118],\n",
            "          [ 0.6855,  0.6855,  0.0590,  ...,  0.6631,  0.6855,  0.8868]]],\n",
            "\n",
            "\n",
            "        [[[-0.3043, -0.6562, -0.9968,  ..., -1.0423, -1.0536, -1.4624],\n",
            "          [ 0.6590,  0.4250, -0.0856,  ...,  1.2972,  1.1271,  0.7867]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0658,  0.1122,  0.1763,  ..., -0.1014, -0.8420, -1.4330],\n",
            "          [-0.6364, -0.5361, -0.8744,  ..., -2.3403, -2.2401, -2.1524]]],\n",
            "\n",
            "\n",
            "        [[[-1.4930, -1.5359, -1.6033,  ...,  0.8345,  0.8713,  0.7672],\n",
            "          [-1.8921, -1.6969, -1.7579,  ...,  0.2182, -0.0624, -0.3307]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8408,  0.8777,  0.6413,  ..., -1.4861, -1.4344, -1.2350],\n",
            "          [-0.4799, -0.5521, -0.3932,  ...,  1.2824,  1.1668,  1.3257]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.3437, -0.4466,  0.6001,  ..., -0.3438,  0.0581, -0.5026],\n",
            "          [ 1.0861,  0.4180, -0.5471,  ...,  0.1025, -0.0274, -0.0089]]],\n",
            "\n",
            "\n",
            "        [[[-0.8009, -0.7662, -1.1949,  ...,  0.8792, -0.2563,  1.0415],\n",
            "          [-0.1879,  0.0924,  0.2649,  ...,  1.5588,  1.8823,  1.4510]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6964,  1.6023,  1.4142,  ..., -0.7900, -0.6690, -0.3196],\n",
            "          [ 0.9172,  1.4599,  1.4127,  ...,  1.3419,  0.8936,  0.2564]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2640, -0.1771, -0.1133,  ...,  0.1360,  0.4317,  0.3390],\n",
            "          [-0.9100, -1.0800, -1.2501,  ...,  0.5783,  0.2275, -0.1977]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2962,  0.1945, -0.1340,  ..., -1.5417, -1.3696, -1.4635],\n",
            "          [-0.7121, -0.7772, -0.6210,  ...,  0.7194,  0.9276,  0.9407]]],\n",
            "\n",
            "\n",
            "        [[[-0.9198, -1.1763, -1.3595,  ...,  0.4097,  0.4306,  0.1585],\n",
            "          [ 0.5173,  0.7863,  0.9078,  ..., -0.5154, -0.5848, -0.4720]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.3890,  0.3820,  0.5717,  ...,  0.9791,  0.4804, -0.1448],\n",
            "          [-0.5688, -0.7278, -0.8981,  ..., -0.2508, -0.3190, -0.1259]]],\n",
            "\n",
            "\n",
            "        [[[-0.6357, -0.7407, -0.8195,  ..., -0.8720, -0.9771, -0.7197],\n",
            "          [ 0.2062,  0.6197,  0.7045,  ...,  0.2168,  0.2274,  0.4501]]],\n",
            "\n",
            "\n",
            "        [[[-0.5272, -0.3875, -0.3688,  ...,  0.1017, -0.2104, -0.2244],\n",
            "          [ 0.2837,  0.3966,  0.2924,  ...,  0.6833,  0.7441,  0.7702]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.4643, -2.3056, -1.9315,  ..., -0.1514, -0.4348, -0.4915],\n",
            "          [ 0.3863,  0.3863,  0.6098,  ..., -0.7091, -1.0221, -0.6867]]],\n",
            "\n",
            "\n",
            "        [[[-0.8341, -0.9377, -0.7046,  ..., -0.0443, -0.2256,  0.1240],\n",
            "          [-0.6968, -1.1446, -0.9325,  ..., -1.1210, -0.9325, -1.0974]]],\n",
            "\n",
            "\n",
            "        [[[-0.3504,  0.0666, -0.7269,  ..., -0.3773, -0.1352, -0.8345],\n",
            "          [-1.0591, -1.5008, -1.1754,  ..., -0.0130,  0.3125,  0.2892]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.1593e+00,  9.2581e-01, -4.1879e-02,  ..., -6.9852e-01,\n",
            "           -3.2988e-01, -9.0589e-01],\n",
            "          [ 2.8096e-01,  5.0981e-01,  4.9710e-01,  ...,  9.4208e-01,\n",
            "            6.7509e-01,  2.1739e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.3934e+00, -1.7307e+00, -1.3091e+00,  ..., -9.0168e-01,\n",
            "           -1.1546e+00, -1.0703e+00],\n",
            "          [ 8.5349e-02,  1.0095e+00,  1.1599e+00,  ...,  4.9368e-01,\n",
            "            3.0026e-01,  1.0684e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1996e+00, -2.2073e+00, -2.2073e+00,  ...,  5.9586e-01,\n",
            "           -1.0035e-01,  3.2104e-01],\n",
            "          [-2.5628e-01, -4.8434e-01, -2.1827e-01,  ...,  6.9397e-01,\n",
            "            5.9895e-01,  4.7804e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1947e+00, -2.9756e-01,  1.3632e-01,  ...,  2.8340e-01,\n",
            "            4.2312e-01,  1.5838e-01],\n",
            "          [-1.5202e-01, -2.9370e-01, -4.1358e-01,  ...,  5.5946e-04,\n",
            "            2.9482e-01,  4.2560e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.4640e-01,  2.7609e-02,  3.8570e-02,  ..., -2.0220e+00,\n",
            "           -4.3273e-01, -6.8482e-01],\n",
            "          [ 6.6839e-01,  4.8465e-01,  4.6795e-01,  ..., -6.3446e-01,\n",
            "           -1.5007e-01, -1.6677e-01]]],\n",
            "\n",
            "\n",
            "        [[[-9.4979e-01, -1.1560e+00, -1.7746e+00,  ...,  6.8737e-01,\n",
            "            1.8621e+00, -7.2484e-01],\n",
            "          [-2.0306e-01, -2.0306e-01, -6.3428e-01,  ..., -1.3280e+00,\n",
            "            2.3754e-01, -3.4320e-02]]]], dtype=torch.float64)\n",
            "tensor([[[[-1.1086e+00,  1.9785e+00,  1.2729e+00,  ..., -8.7342e-01,\n",
            "           -4.1770e-01, -1.0057e+00],\n",
            "          [-1.3422e+00, -5.2493e-01,  3.3085e+00,  ...,  1.2069e+00,\n",
            "            9.1504e-01,  1.5614e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.6577e-01, -6.4526e-01, -5.8848e-01,  ...,  5.8809e-02,\n",
            "           -3.6136e-01, -5.3170e-01],\n",
            "          [-1.6612e-03, -1.6612e-03, -2.6200e-01,  ...,  5.5621e-01,\n",
            "            1.0025e+00,  6.3059e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.0810e-01, -5.6066e-01, -2.0469e-01,  ..., -2.8097e-01,\n",
            "           -3.0639e-01, -2.1316e-01],\n",
            "          [ 2.2614e-01,  4.2175e-02,  1.6954e-01,  ...,  1.6413e+00,\n",
            "            1.0894e+00,  1.0469e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.0228e-01,  4.4397e-01,  6.2848e-01,  ..., -7.3688e-01,\n",
            "           -5.2470e-01, -1.6491e-01],\n",
            "          [ 2.2619e-01,  3.1534e-01,  2.9305e-01,  ..., -2.6418e-01,\n",
            "           -6.8768e-01, -9.1057e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.7283e-02, -6.5006e-02, -1.7817e-01,  ..., -1.3102e-01,\n",
            "            7.7433e-01,  6.6116e-01],\n",
            "          [-7.3473e-01, -6.8923e-01, -1.2807e+00,  ...,  9.4878e-01,\n",
            "           -1.2048e-01, -1.2580e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4783e-01,  4.1415e-01,  4.3644e-02,  ..., -1.0881e+00,\n",
            "           -1.1555e+00, -1.2565e+00],\n",
            "          [-3.0747e-01,  8.9646e-01,  8.3079e-01,  ...,  4.2765e-02,\n",
            "           -3.0747e-01, -3.2936e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-2.4651e+00, -2.0245e+00, -2.2392e+00,  ..., -7.7037e-01,\n",
            "           -2.2804e-01,  9.9619e-02],\n",
            "          [ 1.1347e-01,  3.3667e-01,  2.9203e-01,  ...,  9.1149e-02,\n",
            "            1.8675e-03, -8.4631e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.5835e-01,  7.6059e-02,  8.4256e-02,  ..., -9.6064e-02,\n",
            "            3.6293e-01, -1.6163e-01],\n",
            "          [-5.2968e-01,  3.9798e-01,  4.2007e-01,  ..., -1.1481e+00,\n",
            "           -4.1924e-01,  4.4587e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6396e-01, -1.4920e+00, -1.1132e+00,  ..., -1.0862e+00,\n",
            "           -1.2485e+00, -4.6396e-01],\n",
            "          [ 3.2272e-01,  1.4430e-01,  5.2097e-01,  ...,  8.4823e-02,\n",
            "            4.0202e-01,  2.5349e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.9187e+00, -1.5400e-01,  8.8985e-01,  ...,  4.5804e-01,\n",
            "           -6.0128e-02, -1.3142e+00],\n",
            "          [-1.7445e+00, -1.4654e+00, -2.1477e+00,  ..., -6.9742e-02,\n",
            "           -1.3177e-01, -7.7123e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7612e+00, -1.4378e+00,  5.5577e-01,  ..., -2.2170e-01,\n",
            "           -3.7862e-01, -3.1086e-01],\n",
            "          [-7.8451e-02, -1.4661e-02, -1.4661e-02,  ...,  3.6808e-01,\n",
            "            1.1292e-01,  4.9129e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9910e-01,  2.0824e-01,  8.3503e-01,  ..., -5.9375e-02,\n",
            "           -3.1291e-01, -6.8264e-01],\n",
            "          [-2.6033e+00, -1.9436e-01, -3.5676e-01,  ..., -2.1161e+00,\n",
            "           -2.0890e+00, -2.1702e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.1213, -0.2282,  0.4570,  ...,  0.0585,  0.2918,  0.4521],\n",
            "          [-1.5358, -1.5176, -1.6630,  ...,  0.3544,  0.4090,  0.2272]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7133,  0.9074,  0.8378,  ...,  1.6616,  1.7385,  1.9435],\n",
            "          [ 0.3161,  0.1399, -0.0866,  ...,  0.4168,  0.6181,  0.5426]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1989,  1.2750,  0.7438,  ...,  0.1219, -0.4506, -0.2550],\n",
            "          [ 0.2300,  0.2717,  0.3133,  ..., -0.3254, -0.4226, -0.4365]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3488, -0.3040, -0.3178,  ..., -0.1177, -0.2281, -0.4143],\n",
            "          [-0.4319, -0.3481, -0.3900,  ..., -0.0969, -0.2225, -0.2644]]],\n",
            "\n",
            "\n",
            "        [[[-0.2261, -0.1163, -0.1037,  ...,  0.5807,  0.6089,  1.0673],\n",
            "          [-0.3067, -0.3067, -0.5809,  ...,  0.0067, -0.0324, -0.2283]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1759,  1.5296,  1.5577,  ..., -1.1591, -0.9994, -1.1434],\n",
            "          [-0.3587, -0.6472, -0.7193,  ...,  1.1558,  0.9034,  1.0477]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.7858, -0.7232, -0.3853,  ...,  0.7003,  0.4719,  0.5501],\n",
            "          [ 0.9089,  0.6143,  0.4670,  ..., -1.0429, -1.1534, -1.1902]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4300,  0.2897,  0.1062,  ...,  0.2357,  0.2249,  0.2870],\n",
            "          [-0.9485, -0.9829, -0.8798,  ...,  0.3923,  0.1860,  0.2548]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2133,  0.1557,  0.1617,  ..., -0.0506,  0.0829, -0.0810],\n",
            "          [ 0.2241, -0.0489,  0.2241,  ...,  0.6531,  0.6141,  0.5361]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7217,  0.9359,  1.0073,  ..., -1.7137, -1.6026, -2.3007],\n",
            "          [-1.6665, -1.1888, -1.0296,  ...,  1.1600,  0.2444,  1.4387]]],\n",
            "\n",
            "\n",
            "        [[[-1.1860, -1.6955, -1.6880,  ..., -1.9727, -1.5831, -0.3169],\n",
            "          [ 0.4941,  0.3801,  0.7223,  ..., -0.0762, -0.4564,  0.5702]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2161,  0.3399, -0.0938,  ..., -1.7223, -1.5896, -1.1559],\n",
            "          [-0.0061, -0.0061,  0.4366,  ...,  1.0404,  0.0744,  0.8794]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.0917e+00, -7.9927e-01, -4.5487e-01,  ...,  3.8339e-01,\n",
            "            4.0289e-01,  1.1242e+00],\n",
            "          [-7.0719e-02,  1.1921e+00,  1.0755e-02,  ...,  1.0755e-02,\n",
            "           -1.1299e+00, -2.9982e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8924e-01, -4.1441e-01, -1.1082e+00,  ...,  1.9863e-02,\n",
            "           -2.8462e-01, -4.0941e-01],\n",
            "          [-1.0258e+00, -2.1811e-01, -1.2828e+00,  ...,  7.5593e-02,\n",
            "            6.6301e-01, -3.6497e-01]]],\n",
            "\n",
            "\n",
            "        [[[-6.8956e-01, -1.9853e-01,  8.4440e-02,  ...,  1.2605e-01,\n",
            "           -1.8188e-01,  1.8431e-01],\n",
            "          [ 1.3157e-01, -1.2934e-01, -6.5118e-01,  ..., -9.9907e-01,\n",
            "            1.1161e-03, -6.5118e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.3180e-01,  6.5230e-01,  9.0273e-01,  ...,  5.6882e-01,\n",
            "            3.6609e-01,  7.2385e-01],\n",
            "          [-8.3755e-01, -9.6274e-01, -1.0045e+00,  ..., -1.2811e-01,\n",
            "           -1.6985e-01, -5.0370e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4718e-01,  7.0955e-01,  4.0520e-01,  ...,  3.6322e-01,\n",
            "           -1.5453e-01, -7.6030e-03],\n",
            "          [-5.3660e-01, -5.3660e-01, -6.6447e-01,  ..., -4.9397e-01,\n",
            "           -3.6610e-01, -5.3660e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.7594e-01, -5.2299e-01, -5.5459e-01,  ...,  4.5946e-01,\n",
            "            5.6862e-01,  4.2212e-01],\n",
            "          [-5.1428e-01, -3.7416e-01, -4.7925e-01,  ..., -2.2657e+00,\n",
            "           -7.9451e-01, -7.5948e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.5923,  0.0549,  0.4393,  ..., -0.0608, -0.0402, -0.3171],\n",
            "          [-0.8415, -0.9274, -1.0132,  ..., -0.6699, -0.4124, -0.4124]]],\n",
            "\n",
            "\n",
            "        [[[-0.3352, -0.3315, -0.2541,  ...,  0.1072,  0.3727,  0.0962],\n",
            "          [-0.5576, -0.6005, -0.7293,  ...,  0.8152,  0.9010,  1.0726]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0932, -0.1328, -0.0307,  ...,  1.4308,  1.5548,  1.3251],\n",
            "          [ 0.9003,  0.9950,  0.9950,  ..., -0.8035, -0.6615, -0.6615]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.5991,  0.1983,  0.3576,  ..., -0.6239, -0.3978, -0.5982],\n",
            "          [-0.6747, -0.5896, -0.4195,  ..., -0.5471, -0.5471, -0.7598]]],\n",
            "\n",
            "\n",
            "        [[[-0.2165, -0.6143, -0.4552,  ..., -1.0428, -0.9755, -1.7222],\n",
            "          [-0.8061, -0.7133, -0.8061,  ...,  0.5387,  0.6314,  0.5851]]],\n",
            "\n",
            "\n",
            "        [[[-1.2049, -1.1746, -1.2250,  ..., -0.3824, -0.2008, -0.5943],\n",
            "          [ 0.4909,  0.3663,  0.1585,  ..., -0.3817, -2.6672, -0.6310]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.1298e+00, -1.8482e+00, -1.6213e+00,  ...,  7.6483e-02,\n",
            "           -4.0859e-01,  1.5472e-01],\n",
            "          [-9.3763e-01, -3.1144e-01, -5.5228e-01,  ..., -1.1877e-01,\n",
            "           -5.0411e-01, -7.4495e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.9914e-01, -7.2905e-01, -7.3547e-01,  ...,  3.4893e-01,\n",
            "            2.9118e-01,  1.3076e-01],\n",
            "          [-7.2742e-01, -3.9787e-01, -1.5070e-01,  ...,  1.7885e-01,\n",
            "            9.6463e-02, -1.9190e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0565e-01,  1.9460e-01,  2.2591e-01,  ...,  3.0140e-01,\n",
            "           -2.6390e-01,  1.0437e-01],\n",
            "          [ 8.2183e-03,  8.2183e-03, -6.7016e-01,  ..., -5.0057e-01,\n",
            "           -5.2177e-01, -6.0657e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.8730e-01,  5.1991e-02, -1.0181e+00,  ..., -5.4237e+00,\n",
            "           -5.9587e+00, -2.1091e+00],\n",
            "          [ 9.7923e-02,  6.3219e-02, -6.1889e-03,  ...,  4.2971e+00,\n",
            "            4.0542e+00,  3.8460e+00]]],\n",
            "\n",
            "\n",
            "        [[[-5.5792e+00, -6.3193e+00, -2.6400e+00,  ..., -1.8002e-02,\n",
            "           -5.1844e-01, -2.2946e-01],\n",
            "          [ 3.7242e+00,  3.6899e+00,  3.5530e+00,  ..., -4.5303e-01,\n",
            "           -4.8727e-01, -5.2151e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.3060e+00, -5.8745e-01, -1.2772e+00,  ..., -3.0004e-01,\n",
            "            6.9632e-01,  8.0170e-01],\n",
            "          [-9.4874e-01, -1.0843e+00, -1.0391e+00,  ...,  2.1088e-04,\n",
            "           -4.1571e+00,  1.3577e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.2890e-01, -3.1246e-01, -2.5612e-01,  ..., -1.2234e+00,\n",
            "           -1.1764e+00, -2.0916e-01],\n",
            "          [-4.4928e-02, -4.4928e-02, -3.2505e-01,  ...,  1.7585e-03,\n",
            "           -9.1616e-02, -4.1842e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2730e-02, -5.5796e-01, -2.3306e-01,  ..., -6.1053e-02,\n",
            "            1.8406e+00,  1.1430e+00],\n",
            "          [-4.3092e-01, -4.7497e-01, -6.5113e-01,  ..., -9.1537e-01,\n",
            "           -6.0709e-01, -7.3921e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3016e+00,  5.6654e-01,  1.8593e+00,  ..., -9.1905e-01,\n",
            "            3.8509e-01,  4.4882e-02],\n",
            "          [-7.1461e-01, -4.7993e-01, -7.6155e-01,  ...,  4.1187e-01,\n",
            "           -5.7498e-02, -5.7498e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2024e+00, -1.8583e+00, -2.1982e+00,  ...,  2.5968e-01,\n",
            "           -6.9659e-01, -1.6708e-01],\n",
            "          [-8.9224e-01, -5.4725e-01, -1.1387e+00,  ..., -3.5011e-01,\n",
            "           -3.0082e-01, -3.5011e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.7800e-01,  6.2339e-01, -5.9381e-01,  ..., -8.3883e-01,\n",
            "           -1.5107e+00, -3.5669e-01],\n",
            "          [-2.0902e-01, -5.0646e-01, -3.0817e-01,  ..., -1.2996e+00,\n",
            "           -9.5262e-01, -1.0518e+00]]],\n",
            "\n",
            "\n",
            "        [[[-8.1642e-01,  3.6037e-01, -1.3313e-01,  ..., -6.6458e-01,\n",
            "           -9.5877e-01, -4.7477e-01],\n",
            "          [-5.4027e-01, -1.0323e+00, -9.8309e-01,  ...,  9.5124e-04,\n",
            "           -2.9426e-01, -4.4187e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.7894, -0.6507, -0.9851,  ..., -0.9525, -0.7323, -0.6834],\n",
            "          [-0.5083, -0.7399, -0.3693,  ...,  0.1865,  0.1401,  0.4644]]],\n",
            "\n",
            "\n",
            "        [[[-0.2734, -0.5079,  0.3104,  ..., -0.0284,  0.2218,  0.0550],\n",
            "          [ 0.0927,  0.0036,  0.1818,  ..., -0.8430, -0.7984, -1.1994]]],\n",
            "\n",
            "\n",
            "        [[[-0.2447, -1.0909, -1.1819,  ..., -1.7733, -1.7824, -0.6905],\n",
            "          [-0.8516, -1.4269, -1.0729,  ...,  0.8300,  0.5644,  0.6087]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2526, -0.4907, -1.1556,  ...,  0.4719, -0.1335, -0.2228],\n",
            "          [-0.4719, -0.3699, -0.6248,  ..., -0.3190, -0.6757, -0.7267]]],\n",
            "\n",
            "\n",
            "        [[[-1.2880,  0.2810, -1.2037,  ..., -0.3718, -0.5508, -1.3722],\n",
            "          [-0.6986, -0.9540, -1.3115,  ..., -0.7497, -0.8007, -1.3115]]],\n",
            "\n",
            "\n",
            "        [[[-0.2029, -1.0640, -0.6949,  ...,  0.2780, -0.1581,  0.5352],\n",
            "          [-1.7628, -1.2426, -1.6588,  ...,  0.0059,  0.1100,  0.0059]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.2585,  1.3816,  0.9192,  ..., -1.4970, -0.8363, -0.2040],\n",
            "          [-0.1643, -0.1141,  0.1368,  ...,  1.0399,  1.2407,  0.7891]]],\n",
            "\n",
            "\n",
            "        [[[-0.1179,  0.7173,  1.3317,  ..., -0.7707, -0.5115, -0.3867],\n",
            "          [ 0.6978,  0.8468,  0.8965,  ...,  0.2506, -0.0972, -0.2463]]],\n",
            "\n",
            "\n",
            "        [[[-0.0401, -0.7885, -0.1796,  ...,  0.9875,  1.1397,  0.1502],\n",
            "          [-0.1953, -0.4565, -0.4565,  ..., -0.2998, -0.3520, -2.7549]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3132,  0.7742,  2.7193,  ..., -0.0353, -0.3951, -0.7099],\n",
            "          [-0.6087, -0.6599, -0.6087,  ..., -0.3522, -0.3522, -0.6599]]],\n",
            "\n",
            "\n",
            "        [[[-0.1828, -0.1510,  0.1844,  ...,  0.2639,  0.1844,  0.3310],\n",
            "          [-0.1973, -0.3139, -0.3806,  ...,  0.3692,  0.3526,  0.5026]]],\n",
            "\n",
            "\n",
            "        [[[-0.1165,  0.0588, -0.6268,  ...,  0.5647,  0.4426,  0.4116],\n",
            "          [ 0.4830,  0.5109,  0.5109,  ...,  1.5152,  1.6547,  1.4315]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.5569,  0.5330,  0.4853,  ...,  2.5265,  2.3197,  2.0493],\n",
            "          [ 1.1322,  0.9345,  0.9098,  ...,  0.0448, -0.2764, -0.1776]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5578,  2.3840,  2.0275,  ..., -0.8641, -0.3547, -0.4806],\n",
            "          [-0.2340, -0.3376, -0.4931,  ..., -1.4515, -1.5551, -1.6587]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1936, -0.4044, -0.0419,  ..., -0.1032, -0.3207,  0.0781],\n",
            "          [-1.4511, -1.2690, -1.4511,  ..., -0.3128, -0.4950, -0.5860]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.2302, -2.3406, -2.3681,  ..., -0.9270, -0.8235, -0.9201],\n",
            "          [ 2.1800,  1.9804,  1.8982,  ...,  1.0174,  0.8530,  0.5711]]],\n",
            "\n",
            "\n",
            "        [[[-0.8479, -0.7649, -0.5989,  ...,  0.4799,  0.6987,  0.7213],\n",
            "          [-0.2208, -0.8736, -1.0186,  ...,  0.0331, -0.1724, -0.2570]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7149,  0.3199,  0.0981,  ...,  1.4079,  1.2347,  1.4842],\n",
            "          [-0.4937, -0.2133,  0.2675,  ...,  0.3343,  0.8017,  0.8151]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.3855,  1.5321,  1.5703,  ..., -1.0227, -1.0864, -1.0291],\n",
            "          [ 0.5750,  0.6621,  0.3523,  ..., -0.0447, -0.0737,  0.3136]]],\n",
            "\n",
            "\n",
            "        [[[-0.7129, -0.5557, -0.2086,  ...,  0.0272, -0.0317,  0.2892],\n",
            "          [ 0.5925,  1.0123,  0.5289,  ..., -0.4631, -0.3359, -0.2342]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4089,  0.6598,  0.9610,  ..., -1.4481, -1.4337, -1.6775],\n",
            "          [-0.3402, -0.4428, -0.6593,  ...,  1.4263,  1.8707,  2.1784]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2093, -1.0743, -0.6334,  ..., -0.8112, -0.5837, -0.7827],\n",
            "          [ 0.9888,  0.8496,  0.2497,  ...,  2.2956,  2.1457,  2.2849]]],\n",
            "\n",
            "\n",
            "        [[[-0.6639, -0.6224, -0.5186,  ..., -0.2437, -0.3786, -0.3423],\n",
            "          [ 1.8799,  1.7669,  1.4018,  ...,  0.9324,  1.0541,  1.0193]]],\n",
            "\n",
            "\n",
            "        [[[-0.2440, -0.4625, -0.5864,  ..., -1.9444, -1.4780, -1.0529],\n",
            "          [ 0.7486,  0.6501,  0.7486,  ...,  1.1775,  0.6572,  0.5306]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-6.8049e-01, -7.0382e-01, -7.4114e-01,  ..., -1.4410e+00,\n",
            "           -1.2917e+00, -9.8843e-01],\n",
            "          [ 2.0408e-01,  1.7517e-01,  5.9545e-02,  ...,  1.6566e+00,\n",
            "            1.3170e+00,  9.4119e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.0475e-01, -7.7239e-01, -6.2905e-01,  ...,  2.5870e-01,\n",
            "            1.6160e-01,  1.3386e-01],\n",
            "          [ 6.3586e-01,  6.4484e-01,  2.5846e-01,  ..., -1.0097e-01,\n",
            "           -1.4589e-01,  3.3819e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1811e-01,  5.8915e-01,  5.2399e-01,  ...,  2.0633e+00,\n",
            "            1.8516e+00,  1.3710e+00],\n",
            "          [ 2.8808e-01,  3.2271e-01,  2.4189e-01,  ..., -3.0834e+00,\n",
            "           -2.8409e+00, -2.1482e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 8.9212e-01,  7.1867e-01,  9.8232e-01,  ..., -1.4252e+00,\n",
            "           -1.0852e+00, -1.4252e+00],\n",
            "          [ 3.5907e-01,  7.4358e-01,  7.5837e-01,  ...,  1.2020e+00,\n",
            "            8.0274e-01,  2.9991e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5043e+00, -1.3338e+00, -3.6046e-01,  ...,  1.2878e+00,\n",
            "            1.0392e+00,  1.1528e+00],\n",
            "          [ 2.7912e-01,  6.3399e-01, -1.8187e-03,  ...,  5.4527e-01,\n",
            "            4.4177e-01,  1.1647e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 8.0221e-01,  9.0566e-01,  8.0830e-01,  ..., -8.9550e-01,\n",
            "           -1.3762e+00, -1.4797e+00],\n",
            "          [-6.9168e-01, -1.0137e+00, -1.0723e+00,  ...,  4.0267e-02,\n",
            "            1.0211e+00,  1.4456e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[-1.2541, -1.0998, -1.0998,  ...,  1.1398,  0.9990,  0.8381],\n",
            "          [ 0.5302,  0.1984, -0.0180,  ..., -0.2488, -0.2343, -0.3642]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0905,  1.0528,  0.9773,  ...,  0.9094,  1.0830,  1.0754],\n",
            "          [-0.8267, -0.9983, -0.5692,  ...,  0.5178, -0.3547, -1.0698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9718,  0.7237,  0.8300,  ..., -0.3468, -0.5169, -0.1979],\n",
            "          [-1.6016, -1.4755, -1.0831,  ...,  0.5705,  0.8928,  0.8648]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5601, -1.1528, -0.8050,  ...,  0.9342,  0.9681,  0.9512],\n",
            "          [-0.8109, -1.6069, -1.8951,  ..., -0.0560, -0.2893, -0.0560]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7525,  0.9720,  0.8338,  ...,  1.4516,  1.6548,  1.0533],\n",
            "          [ 0.1237,  0.3263,  0.4501,  ..., -0.8894, -0.6755, -0.3378]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1013,  0.5273,  0.4433,  ...,  2.5851,  2.2071,  2.0111],\n",
            "          [-0.2162, -0.1722,  0.1355,  ...,  0.2015,  0.9159,  1.2016]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.5406,  1.6999,  1.3746,  ..., -0.2718, -0.1324, -0.1125],\n",
            "          [ 1.1110,  0.7992,  0.5424,  ...,  0.4599,  0.2673, -0.0629]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4444,  0.8784,  1.0829,  ...,  0.1531,  0.6614,  0.4692],\n",
            "          [-0.7578, -1.1724, -1.3363,  ..., -0.6325, -0.9410, -0.7289]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5406,  0.0230, -0.0588,  ..., -0.5056, -0.5165, -0.7017],\n",
            "          [-0.6459, -0.5635, -0.3492,  ..., -0.3410, -0.2998, -0.0279]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.7455, -0.4405, -0.7794,  ..., -0.2457, -0.1271,  0.0847],\n",
            "          [ 0.4530, -0.0304, -0.0431,  ...,  0.4911,  0.4021,  0.1731]]],\n",
            "\n",
            "\n",
            "        [[[-0.1239, -0.1742, -0.4327,  ..., -0.7055, -1.0143, -0.4327],\n",
            "          [ 0.3006,  0.3433,  0.2721,  ..., -0.9089, -0.4109, -0.8093]]],\n",
            "\n",
            "\n",
            "        [[[-0.7006, -0.4561, -0.5583,  ..., -0.2518, -0.5765, -0.3576],\n",
            "          [-0.3180, -0.6723, -0.6977,  ..., -1.6469, -0.8748, -1.1533]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-8.5324e-01, -4.6167e-01, -8.7026e-01,  ..., -3.6060e-02,\n",
            "           -4.1735e-02, -3.6060e-02],\n",
            "          [-3.2304e-01, -4.9484e-01, -4.7922e-01,  ..., -5.7539e-02,\n",
            "            7.5213e-02, -1.2782e-01]]],\n",
            "\n",
            "\n",
            "        [[[-9.1781e-02, -1.3655e-01, -6.4918e-02,  ..., -9.6933e-01,\n",
            "           -7.7233e-01, -1.0589e+00],\n",
            "          [-2.1928e-01, -2.4901e-01, -4.0882e-02,  ...,  3.1591e-01,\n",
            "            5.0917e-01,  1.1038e+00]]],\n",
            "\n",
            "\n",
            "        [[[-9.6872e-01, -1.3083e+00, -9.9626e-01,  ..., -9.7790e-01,\n",
            "           -4.1806e-01, -7.0257e-01],\n",
            "          [ 1.0328e+00,  1.1309e+00,  4.7683e-01,  ...,  2.0302e+00,\n",
            "            1.3925e+00,  1.4252e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.3089e-01, -1.3065e-01, -3.2576e-02,  ...,  4.0589e-01,\n",
            "            5.9734e-02,  3.0782e-01],\n",
            "          [-5.5831e-01, -1.7269e-01, -1.0033e+00,  ..., -2.4685e-01,\n",
            "           -3.9210e-02, -1.1337e-01]]],\n",
            "\n",
            "\n",
            "        [[[-5.6956e-02,  1.8039e-01, -8.1136e-01,  ...,  7.8667e-02,\n",
            "           -5.6555e-01,  7.5679e-01],\n",
            "          [ 1.0940e+00,  7.6950e-01,  1.5268e+00,  ..., -1.2801e-03,\n",
            "            3.7735e-01, -4.3400e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8375e-01,  1.7440e+00,  1.5285e+00,  ..., -5.8478e-01,\n",
            "           -1.3306e+00, -7.9196e-01],\n",
            "          [-7.6291e-01, -1.6166e+00, -1.5399e+00,  ...,  1.1523e+00,\n",
            "            1.4587e+00,  1.2070e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.8674, -0.4297, -0.9497,  ..., -0.1350, -0.5293, -0.1913],\n",
            "          [ 0.9711,  0.9472,  0.6836,  ..., -0.4664,  0.1805, -0.0831]]],\n",
            "\n",
            "\n",
            "        [[[-1.1066, -0.4320, -0.8910,  ...,  0.1105, -0.0495, -0.4737],\n",
            "          [ 1.0860,  0.6203,  1.4694,  ...,  1.5927,  1.3599,  2.2912]]],\n",
            "\n",
            "\n",
            "        [[[-0.1334, -0.0406,  0.3614,  ...,  0.3305, -0.4220,  0.1037],\n",
            "          [ 1.3433,  1.3433,  0.3168,  ..., -0.0849,  0.4507, -0.1146]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0482, -0.8533, -1.0698,  ..., -0.3338, -0.3049, -0.1317],\n",
            "          [ 0.2422,  0.1280,  0.7247,  ..., -1.6621, -1.6748, -1.7890]]],\n",
            "\n",
            "\n",
            "        [[[-0.1656, -0.1043, -0.2168,  ...,  0.9594,  1.5219,  0.2742],\n",
            "          [-2.1742, -1.9130, -1.6058,  ...,  0.4683,  0.9907,  1.7281]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8865,  0.3748,  1.0626,  ..., -0.5898, -0.0530, -0.3046],\n",
            "          [ 1.3345,  1.4060,  1.5695,  ...,  1.0383,  0.6808,  0.6297]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1593, -0.2361,  0.0131,  ..., -3.3724, -3.2965, -3.8653],\n",
            "          [ 0.3168,  0.2314, -0.0247,  ...,  1.1550,  1.5663,  0.8989]]],\n",
            "\n",
            "\n",
            "        [[[-2.9132, -2.2867, -3.4100,  ..., -0.3815, -0.1611, -0.2259],\n",
            "          [ 0.9157,  0.4253,  1.2284,  ...,  0.1091,  0.0309, -0.0544]]],\n",
            "\n",
            "\n",
            "        [[[-0.2180, -0.3758, -0.0952,  ...,  0.9044,  1.0798,  1.0447],\n",
            "          [-0.6206, -1.1158, -1.2958,  ...,  0.2496,  0.0095,  0.2496]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7974,  0.7850,  0.2160,  ..., -0.5324, -0.7921, -1.2313],\n",
            "          [ 0.0966,  0.4882,  1.0671,  ...,  0.7266,  0.1477,  0.9820]]],\n",
            "\n",
            "\n",
            "        [[[-0.6242, -0.2736, -0.4639,  ...,  0.1420,  0.0318, -0.2436],\n",
            "          [ 1.1585,  0.9810,  1.0750,  ...,  0.7305,  0.7618,  0.8453]]],\n",
            "\n",
            "\n",
            "        [[[-0.1774, -0.1849, -0.1699,  ...,  0.6303,  0.7200,  0.4882],\n",
            "          [ 1.4619,  1.3824,  0.9529,  ..., -0.0969, -0.7808,  0.0304]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.3819,  0.6200,  0.8991,  ..., -0.9892, -1.4161, -1.9415],\n",
            "          [-0.1444, -0.3368, -0.4997,  ...,  0.4479,  0.4923,  1.0993]]],\n",
            "\n",
            "\n",
            "        [[[-2.2868, -2.3060, -1.9602,  ..., -0.1158,  0.0379, -0.5481],\n",
            "          [ 1.4502,  1.7380,  1.6319,  ..., -0.3071, -0.3526, -0.0799]]],\n",
            "\n",
            "\n",
            "        [[[-0.1241, -0.5849, -0.4772,  ..., -0.1540,  0.1093,  0.0734],\n",
            "          [-0.5267, -0.5800, -0.2070,  ...,  0.1660, -0.0471, -0.5693]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0969,  0.2510,  0.4897,  ...,  1.8778,  1.4446,  1.6629],\n",
            "          [-0.1998, -0.1327,  1.6133,  ...,  1.3335,  0.7403, -1.7108]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5663,  1.9958,  1.3914,  ..., -0.3863, -0.8079, -0.3982],\n",
            "          [-0.4706,  1.3384,  1.7415,  ..., -0.0364, -1.0494,  0.3047]]],\n",
            "\n",
            "\n",
            "        [[[-0.5786, -0.6862, -0.6911,  ...,  0.1697,  0.3996,  0.0915],\n",
            "          [ 0.5417,  0.1845,  0.4443,  ...,  0.4660,  1.0505, -0.9196]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.0466,  0.2608,  0.4681,  ..., -0.3714, -0.1150, -0.0974],\n",
            "          [ 0.6074,  0.3336, -1.4811,  ...,  1.4488, -0.1023,  0.0700]]],\n",
            "\n",
            "\n",
            "        [[[-0.1988, -0.0616, -0.2582,  ...,  0.7069,  0.6841,  0.6109],\n",
            "          [ 0.4434,  1.2502,  1.4071,  ..., -1.1143,  0.9028, -0.3859]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6283,  0.4909,  0.5672,  ..., -0.8225, -0.5285, -0.9561],\n",
            "          [-0.3425, -0.3233,  1.2331,  ..., -2.5425, -0.4866, -1.2551]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.4451,  0.4661,  0.7115,  ..., -0.9198, -0.9257, -0.8150],\n",
            "          [ 0.1042, -0.1081, -0.2189,  ..., -0.7081,  0.0949,  0.2426]]],\n",
            "\n",
            "\n",
            "        [[[-0.6847, -1.2820, -1.2024,  ..., -0.1406, -0.2302, -0.5023],\n",
            "          [-0.0849,  0.4827,  0.3257,  ...,  2.1249, -0.2660, -0.4592]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3870, -2.9093, -1.9009,  ...,  0.8588,  0.3576,  0.3811],\n",
            "          [-0.8399,  1.2976,  1.7309,  ...,  1.4998,  0.1278,  0.3444]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.3824,  0.5792,  0.4874,  ...,  1.5041,  1.3237,  1.4057],\n",
            "          [-0.8596, -1.1026, -0.8900,  ...,  2.5275,  1.4339,  2.3300]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3399,  1.3649,  1.2686,  ..., -2.6190, -2.6155, -2.5585],\n",
            "          [ 1.8408,  1.4840,  1.6327,  ..., -1.8464, -0.9544, -1.9208]]],\n",
            "\n",
            "\n",
            "        [[[-2.4231, -1.9916, -1.5636,  ...,  0.1485,  0.1380,  0.2250],\n",
            "          [-0.7588, -0.8136, -1.7180,  ...,  0.4608, -0.2243, -0.1147]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3926,  1.3615,  1.5006,  ...,  0.4406,  0.5395,  0.5651],\n",
            "          [ 0.3244,  0.7567,  0.4060,  ...,  0.2265, -0.7849, -0.1568]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3385,  0.4480,  0.3969,  ...,  0.7510,  0.8295,  0.8933],\n",
            "          [-0.9891, -1.0912, -1.0598,  ..., -0.3605, -1.3976, -0.8712]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7501,  0.9760,  0.9526,  ...,  0.3840,  0.5735,  0.5294],\n",
            "          [ 1.4971, -1.1135, -0.6691,  ..., -0.4099,  0.8583, -0.6414]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.4389,  0.6525,  0.5959,  ...,  0.4847,  0.5435,  0.7855],\n",
            "          [ 0.2652,  0.5846,  0.2714,  ...,  0.1775,  0.3215,  0.4781]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2282,  0.1937,  0.2945,  ..., -0.0663, -0.4270, -0.9973],\n",
            "          [ 2.6774, -0.4780, -0.9975,  ..., -0.7217, -0.1638, -0.5806]]],\n",
            "\n",
            "\n",
            "        [[[-0.3763, -0.1571, -0.1700,  ...,  0.4230,  0.3736,  0.3908],\n",
            "          [-0.4226, -0.2496, -0.4803,  ...,  0.8412,  0.6629,  0.5056]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4134, -1.4344, -1.1554,  ..., -0.5092, -0.0699, -0.2093],\n",
            "          [-1.7712, -0.8199, -1.2307,  ...,  0.0666, -0.2469,  0.0774]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0386,  0.1430, -0.0353,  ...,  0.1099,  0.4080,  0.4182],\n",
            "          [-0.0316, -0.2656, -0.7973,  ..., -0.7441, -0.2443, -1.0313]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2383,  0.1547,  0.0680,  ...,  0.4463,  0.4006,  0.3723],\n",
            "          [ 0.1651, -0.2501, -0.0106,  ...,  0.1810,  0.3567, -0.0185]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.4617,  0.4528,  0.5636,  ..., -0.5768, -0.3051, -0.2622],\n",
            "          [ 0.4372,  0.9148,  0.3349,  ...,  0.3434,  0.2325, -0.0233]]],\n",
            "\n",
            "\n",
            "        [[[-0.2217, -0.1313, -0.2072,  ..., -0.0716, -0.1602, -0.0319],\n",
            "          [-0.8366, -0.9878, -0.7121,  ..., -0.3564, -0.5609, -0.5076]]],\n",
            "\n",
            "\n",
            "        [[[-0.0780,  0.0641, -0.0235,  ...,  1.0472,  1.0705,  1.0919],\n",
            "          [ 0.4256, -0.5273, -0.9486,  ...,  0.8670,  1.2080,  0.7466]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7136,  0.5687,  0.5636,  ..., -0.2117, -0.1736, -0.1329],\n",
            "          [-0.4027, -0.0704,  1.5750,  ..., -0.5609, -0.5767, -0.4027]]],\n",
            "\n",
            "\n",
            "        [[[-0.0591, -0.1978, -0.2355,  ...,  0.0955, -0.0809,  0.0658],\n",
            "          [-0.4099, -0.1694, -0.3738,  ...,  0.5763,  0.5522,  0.0952]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1057, -0.0890, -0.6502,  ...,  1.4400,  1.5373,  1.5459],\n",
            "          [-0.7092, -1.4932, -1.8400,  ...,  0.1200,  0.1050, -0.0157]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.1815,  1.1711,  1.0429,  ...,  1.0011,  0.8703,  0.6454],\n",
            "          [ 0.1882,  0.5581,  0.5581,  ...,  0.5964,  0.5326,  0.9026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7973,  0.5383,  0.1902,  ...,  0.6497,  0.5494,  0.7054],\n",
            "          [ 1.2099,  1.0398,  0.3749,  ...,  1.0243,  1.3800,  1.3181]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5344,  0.5410,  0.7622,  ...,  0.2472,  0.1481,  0.0689],\n",
            "          [ 1.2490,  1.4649,  1.4649,  ..., -1.2839, -1.2263, -0.9529]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.9022,  0.3947,  0.0563,  ..., -0.0550, -0.0327,  0.0741],\n",
            "          [ 0.8629,  1.1499,  1.5954,  ..., -0.2397, -0.5493, -1.0327]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0774,  0.2734,  0.1874,  ...,  1.7692,  1.5446,  1.4824],\n",
            "          [-1.1980, -1.3597, -1.3386,  ..., -0.9240, -1.0224, -0.9380]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1918,  1.2306,  0.9501,  ...,  0.8293,  0.6006,  0.1994],\n",
            "          [-0.6647, -0.6320, -0.3896,  ..., -1.0120, -0.8547, -0.6058]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.0482, -0.2528, -0.6431,  ..., -1.7777, -2.1518, -2.3877],\n",
            "          [-0.3577, -0.0288,  0.2659,  ...,  2.0751,  2.3561,  2.5685]]],\n",
            "\n",
            "\n",
            "        [[[-2.7020, -2.7108, -2.7108,  ...,  1.7375,  1.9309,  2.0452],\n",
            "          [ 2.6069,  2.5609,  2.5806,  ..., -1.1101, -1.0182, -0.8409]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5074,  1.2831,  0.8570,  ..., -0.0065, -0.0700, -0.1186],\n",
            "          [-0.7898, -0.8466, -1.0966,  ...,  0.5739,  0.5910,  0.6989]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.6428, -0.8110, -0.3904,  ...,  1.6594,  1.4988,  1.4376],\n",
            "          [ 0.8087,  0.9264,  0.9002,  ..., -0.5783, -0.7745, -0.2119]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2798,  1.1247,  0.7283,  ...,  0.4181,  0.6594,  0.3751],\n",
            "          [-0.1756,  0.1599,  0.5492,  ..., -0.3501, -0.8199, -1.0749]]],\n",
            "\n",
            "\n",
            "        [[[-0.2311, -0.7162, -0.9131,  ..., -0.1397,  0.0994,  0.3174],\n",
            "          [-0.9180, -0.0219,  0.6405,  ...,  0.7315,  0.7315,  0.5886]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.4973,  0.6660,  0.6880,  ...,  0.2627,  0.3214,  0.2627],\n",
            "          [ 0.3919,  0.1917,  0.2793,  ...,  2.1445,  2.3698,  2.2821]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4924,  0.8542,  1.2160,  ...,  0.8400,  0.7975,  0.3789],\n",
            "          [ 1.8027,  1.9017,  1.7807,  ...,  0.6031,  0.7462,  0.6031]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4065,  0.3997,  0.5007,  ..., -1.1085, -0.7112, -0.4082],\n",
            "          [ 0.5889,  0.7445,  0.7223,  ...,  0.7334,  0.5444,  0.4777]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4904,  1.0891,  1.3834,  ...,  2.3288,  2.2217,  2.0612],\n",
            "          [ 0.2137, -0.8108, -0.6623,  ..., -0.3208, -0.8405, -0.7663]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1866,  1.3074,  1.2435,  ..., -0.2420, -0.1070,  0.0707],\n",
            "          [-0.8463, -0.1771, -0.2690,  ...,  0.2034,  0.3608,  0.2165]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2396, -0.0707,  0.1025,  ..., -1.3551, -1.0881, -1.3984],\n",
            "          [ 0.0392, -0.2412, -0.0500,  ...,  1.6964,  1.3140,  1.6072]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.7687, -0.7232, -0.7142,  ...,  0.2669,  0.5667,  0.5167],\n",
            "          [ 1.7277,  1.6746,  1.4302,  ..., -0.5457, -0.4819, -0.5882]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5917,  0.4692,  0.6563,  ...,  1.0111,  1.0369,  1.3467],\n",
            "          [-1.1210, -0.7762, -0.8232,  ...,  1.4803,  1.5273,  0.7908]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7285,  2.2440,  1.7936,  ...,  0.2466,  0.1106,  0.0511],\n",
            "          [ 1.4312,  1.5936,  1.3012,  ...,  0.5215,  1.0576,  1.3175]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9885, -2.7218, -2.8996,  ...,  2.1838,  2.1515,  2.2323],\n",
            "          [-0.3805, -0.4192, -0.3418,  ...,  1.5143,  1.8237,  1.4950]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7539,  3.8671,  3.8042,  ...,  0.0534,  0.2800,  0.3051],\n",
            "          [ 1.4012,  0.6239,  0.6794,  ...,  0.7905,  0.7165,  1.4752]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5220,  0.4953,  0.2755,  ..., -0.2375, -0.9437, -0.9037],\n",
            "          [ 0.8606,  0.2633, -0.4004,  ...,  0.0144,  0.0144, -0.1847]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.7879, -0.2922, -0.2345,  ...,  0.1593,  0.3664,  0.5566],\n",
            "          [-0.1471, -0.1338, -0.2798,  ...,  0.3041, -0.2134, -0.4921]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2850,  1.1348,  0.8276,  ...,  0.3114,  0.1024,  0.4552],\n",
            "          [-0.2999, -0.1893,  0.0042,  ...,  0.5295,  1.1101,  1.4695]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1895,  0.5808,  0.4091,  ..., -0.3089, -0.4182, -0.3401],\n",
            "          [ 2.1849,  1.9308,  1.9112,  ...,  2.4976,  1.8721,  1.5203]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2656,  0.5326,  0.4945,  ...,  0.4436,  0.3673,  0.2338],\n",
            "          [-1.2772, -1.1766, -0.8289,  ..., -0.2617, -0.4538, -0.4355]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1156,  0.2302,  0.4198,  ..., -0.6737, -0.5591, -0.5017],\n",
            "          [-0.1997, -0.3518, -0.4559,  ...,  0.7533,  0.6972,  0.5531]]],\n",
            "\n",
            "\n",
            "        [[[-0.4653, -0.3606, -0.4335,  ...,  0.1995,  0.0765,  0.0993],\n",
            "          [ 0.4927,  0.4851,  0.7194,  ...,  0.7270,  0.6363,  0.6212]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.0900,  0.1124,  0.0990,  ...,  0.9280,  1.0893,  1.0938],\n",
            "          [ 0.5639,  0.7689,  0.5211,  ...,  0.3588,  0.2990,  0.4015]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9243,  2.1643,  2.5570,  ...,  0.0916,  0.3898,  0.8625],\n",
            "          [ 1.4489,  1.3316,  1.6574,  ...,  0.1328,  0.1849,  0.0155]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6018,  1.6018,  1.7003,  ...,  0.5624,  0.1861,  0.4011],\n",
            "          [-0.2025, -0.5572, -0.3470,  ...,  0.4410,  0.0995,  0.3359]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.1265, -3.0728, -2.8706,  ...,  0.5097,  0.7243,  0.8976],\n",
            "          [-0.1556,  0.9299,  1.1501,  ...,  0.3006, -0.3287, -0.9108]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9305,  1.4557,  1.4815,  ...,  0.6456,  0.5837,  0.6508],\n",
            "          [-1.1851, -1.7465, -1.2871,  ...,  1.1457,  0.6183,  0.4822]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4600,  0.5527,  0.4545,  ...,  0.5963,  0.3836,  0.5254],\n",
            "          [ 0.0145,  0.1369, -0.0204,  ..., -0.1428, -0.4225, -0.4400]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 5.3360e-01,  3.4284e-01,  4.4639e-01,  ..., -6.3818e-01,\n",
            "           -5.2918e-01, -3.2752e-01],\n",
            "          [-6.2725e-01, -3.6137e-01,  4.2097e-03,  ...,  8.0185e-01,\n",
            "            4.6950e-01,  3.1994e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1340e-01,  6.7901e-02,  1.1999e-01,  ..., -3.0716e-01,\n",
            "           -4.5302e-01, -4.5823e-01],\n",
            "          [-1.1738e-01, -5.2144e-01, -9.2550e-01,  ...,  8.4614e-01,\n",
            "            5.5605e-01,  6.3893e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.5153e-01, -1.1842e-01,  5.5937e-01,  ..., -7.6922e-02,\n",
            "            4.6254e-01,  5.1787e-01],\n",
            "          [ 2.1242e+00,  5.6963e-01, -2.8129e-01,  ...,  1.6005e+00,\n",
            "            1.0442e+00,  6.8417e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.6915e-01,  6.6061e-02,  1.3021e-01,  ..., -2.6181e-01,\n",
            "           -1.1926e-01,  1.1595e-01],\n",
            "          [-5.4048e-01, -1.0871e+00, -1.0871e+00,  ...,  2.1291e+00,\n",
            "            2.1800e+00,  2.1927e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7123e-01,  5.1927e-01,  6.0974e-01,  ...,  3.3833e-01,\n",
            "            2.0673e-01,  5.8684e-02],\n",
            "          [ 2.0676e+00,  1.7398e+00,  1.7398e+00,  ..., -3.3601e-01,\n",
            "           -8.0034e-01, -1.0052e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6869e-01, -8.4206e-02,  9.4518e-05,  ...,  9.8870e-01,\n",
            "            5.7487e-01,  7.5880e-01],\n",
            "          [-1.0342e+00, -1.2088e+00, -7.9246e-01,  ..., -9.4000e-02,\n",
            "            2.9552e-01,  4.4327e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.0564,  0.7482,  0.2315,  ..., -0.4755, -0.1492, -0.3577],\n",
            "          [ 0.0055, -0.6389, -1.0378,  ..., -0.5162, -0.8691, -1.7283]]],\n",
            "\n",
            "\n",
            "        [[[-0.2458, -0.5390, -0.5239,  ..., -0.4187, -0.4638, -0.5465],\n",
            "          [-1.2481, -1.2716, -1.0954,  ...,  1.5370,  1.7485,  1.5605]]],\n",
            "\n",
            "\n",
            "        [[[-0.6701, -0.5068, -0.1473,  ..., -1.0051, -0.8008, -0.8580],\n",
            "          [ 1.8280,  1.6363,  1.3296,  ...,  0.2177,  0.4605,  0.5883]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.4293,  1.1203,  1.3303,  ...,  0.2261,  0.2667,  0.4361],\n",
            "          [-0.9492, -0.2316,  0.2157,  ...,  1.6507,  1.6170,  1.5326]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1589, -0.5078, -0.6320,  ...,  1.4008,  1.1655,  0.9367],\n",
            "          [ 1.9735,  1.6708,  1.5296,  ...,  0.2181,  0.0768,  0.6014]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0672,  1.0802,  1.2623,  ..., -0.9040, -0.5397, -1.0341],\n",
            "          [ 0.7107,  0.9606,  0.8572,  ...,  2.0374,  2.3562,  2.6232]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.1564, -2.5422, -2.6918,  ...,  0.1350, -0.0382,  0.2846],\n",
            "          [ 2.7441,  2.6221,  2.2354,  ..., -0.4913, -0.4710, -0.5625]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0756,  0.3406,  0.4034,  ...,  0.7172,  1.1984,  1.7005],\n",
            "          [-0.6234, -0.8642, -1.1318,  ...,  1.2143,  1.1964,  1.4640]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8641,  1.8325,  2.0911,  ...,  0.7858,  0.5147,  0.4957],\n",
            "          [ 1.4709,  1.5311,  1.4537,  ...,  1.7719,  1.5053,  1.1182]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2255,  0.5041,  0.6712,  ...,  0.1962,  0.4836,  0.6859],\n",
            "          [ 0.3507,  0.0184, -0.0503,  ...,  0.0662,  0.9255,  0.8262]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5418,  0.1878,  1.3191,  ..., -1.0129, -0.1939, -0.3397],\n",
            "          [ 2.0721,  0.9108,  5.3853,  ..., -0.2505, -0.3052, -0.0524]]],\n",
            "\n",
            "\n",
            "        [[[-0.1465,  0.2352,  0.3680,  ...,  1.6571,  2.1108,  2.4206],\n",
            "          [-0.0637, -0.1646, -0.0368,  ..., -0.8435, -0.4671, -0.5208]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 2.3629,  1.9247,  2.2131,  ...,  0.6657,  0.8210,  0.3385],\n",
            "          [-0.6486, -1.0058, -0.0916,  ...,  1.4797,  1.4083,  0.9798]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7845,  0.6709,  0.6276,  ...,  2.0396,  0.9793,  1.9477],\n",
            "          [ 0.4949,  0.6857,  0.6416,  ...,  0.5022,  0.3041, -0.0040]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9411,  1.6168,  0.5176,  ...,  0.2068,  0.2068,  0.2384],\n",
            "          [ 0.0697,  0.1508,  0.1127,  ..., -0.1021,  0.0888,  0.0363]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.3980, -1.4653, -1.1289,  ...,  0.1648, -0.0629, -0.1302],\n",
            "          [-1.5566, -1.5634, -1.6584,  ...,  0.6627,  0.7035,  0.8188]]],\n",
            "\n",
            "\n",
            "        [[[-0.2873, -0.3699, -0.4525,  ..., -0.6856, -0.5739, -0.4573],\n",
            "          [ 0.9982,  1.0638,  1.1049,  ...,  0.1444,  0.0869,  0.2183]]],\n",
            "\n",
            "\n",
            "        [[[-0.2763, -0.6006, -0.9629,  ...,  0.2166,  0.0734,  0.2924],\n",
            "          [ 0.4320,  0.4766,  0.2728,  ...,  0.5403,  0.5721,  0.5721]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.4217,  0.2480,  0.1635,  ..., -0.0055,  0.0086,  0.0508],\n",
            "          [ 0.6202,  0.5617,  0.3132,  ...,  0.7663,  0.8029,  0.8029]]],\n",
            "\n",
            "\n",
            "        [[[-0.3165, -0.5154, -0.7779,  ...,  0.5090,  0.6487,  0.7884],\n",
            "          [ 0.8244,  0.4058,  0.1341,  ..., -0.3725, -0.3505, -0.2624]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8600,  0.9449,  0.9308,  ...,  0.5107,  0.2180,  0.1047],\n",
            "          [-0.3376, -0.4344, -0.3673,  ...,  0.8167,  0.8837,  0.9210]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.9559,  0.5256,  0.0236,  ..., -2.0253, -1.3491, -1.1545],\n",
            "          [ 1.4099,  0.8537,  0.5025,  ..., -1.1073, -0.9024, -0.2439]]],\n",
            "\n",
            "\n",
            "        [[[-1.0754, -0.9459, -1.2998,  ...,  0.8837,  0.8233,  0.6507],\n",
            "          [ 0.1095,  0.0217,  0.0656,  ...,  0.7097,  0.9585,  0.2413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3858,  0.8013,  0.7667,  ..., -3.1897, -2.6357, -2.3933],\n",
            "          [ 0.0623, -0.2346,  0.0218,  ..., -1.3414, -0.5316, -0.4911]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.6454e+00, -1.0803e+00, -3.9272e-01,  ..., -9.2960e-01,\n",
            "           -6.8471e-01, -8.5425e-01],\n",
            "          [-8.3798e-01, -2.5598e-01,  4.3854e-03,  ...,  6.5648e-02,\n",
            "            1.4223e-01,  4.0260e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.1895e-01, -4.3708e-01, -2.9827e-01,  ..., -2.4870e-01,\n",
            "            1.9003e-02,  2.1730e-01],\n",
            "          [ 2.9036e-01,  2.2104e-01, -8.0418e-04,  ..., -6.9406e-01,\n",
            "           -8.6045e-01, -7.3566e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.7552e-01,  3.6815e-01, -9.0235e-02,  ...,  1.6687e+00,\n",
            "            1.5514e+00,  1.3702e+00],\n",
            "          [-5.1722e-01, -4.1735e-01, -3.6048e-03,  ...,  4.6720e-01,\n",
            "            4.3867e-01,  5.3854e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.2364e+00,  9.0864e-01,  6.8130e-01,  ...,  9.5623e-01,\n",
            "            8.3462e-01,  6.2843e-01],\n",
            "          [ 9.9335e-01,  9.4908e-01,  7.9730e-01,  ...,  9.4908e-01,\n",
            "            1.0629e+00,  1.0692e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 4.2252e-01,  4.3627e-01,  5.0960e-01,  ..., -9.1111e-01,\n",
            "           -8.8820e-01, -8.1029e-01],\n",
            "          [ 1.3432e+00,  1.3503e+00,  1.4842e+00,  ...,  2.4365e-01,\n",
            "            7.4484e-02,  8.8582e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.3156e-01, -6.3662e-01, -5.1669e-01,  ...,  8.3249e-01,\n",
            "            1.0074e+00,  9.5241e-01],\n",
            "          [-1.9224e-02, -1.8716e-01, -7.0625e-01,  ...,  4.7696e-01,\n",
            "            4.9986e-01,  6.0673e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.1731,  1.2002,  1.4822,  ..., -1.1696, -1.7715, -1.7878],\n",
            "          [ 0.6356,  0.6932,  0.8003,  ...,  0.6191, -0.0148, -0.2453]]],\n",
            "\n",
            "\n",
            "        [[[-1.5468, -1.6844, -1.7827,  ...,  0.1389,  0.2814,  0.3453],\n",
            "          [-0.2439, -0.3023, -0.4060,  ...,  1.0265,  0.7996,  0.7478]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3290,  0.2649,  0.3044,  ..., -0.1050, -0.2876, -0.4849],\n",
            "          [ 1.2695,  1.0588,  1.2533,  ..., -2.1345, -1.8265, -1.8671]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2427,  0.3718,  0.3799,  ...,  0.9530,  1.1064,  1.2759],\n",
            "          [-0.5689, -0.5575, -0.1215,  ..., -0.4542, -0.2248, -0.1904]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2968,  1.4637,  1.5699,  ...,  0.2500,  0.1439,  0.1514],\n",
            "          [-0.0825, -0.1840, -0.1388,  ...,  0.8424,  0.7070,  0.5604]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0059, -0.3071, -0.1897,  ..., -1.6917, -1.8091, -1.6995],\n",
            "          [ 0.7043,  1.0120,  1.2057,  ..., -1.8257, -1.7915, -1.4952]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.5581, -1.5490, -1.1294,  ..., -0.0165,  0.1294,  0.4305],\n",
            "          [-1.3587, -0.9955, -0.9845,  ..., -0.5662, -0.9514, -0.9294]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6602,  0.3748,  0.3907,  ..., -1.3451, -1.5987, -1.7572],\n",
            "          [-0.6600, -0.1868, -0.0944,  ..., -0.8908, -0.9716, -0.9023]]],\n",
            "\n",
            "\n",
            "        [[[-1.1772, -1.2167, -1.1851,  ...,  0.1911,  0.2623, -0.4891],\n",
            "          [-0.8976, -0.5011, -0.5245,  ...,  0.5601,  0.3385,  0.6767]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.3974, -1.3325, -1.2191,  ..., -0.5949, -0.9191, -1.0650],\n",
            "          [-2.1424, -2.1176, -1.8939,  ..., -1.3472, -1.2602, -1.3845]]],\n",
            "\n",
            "\n",
            "        [[[-0.7834, -0.6002, -0.3764,  ...,  0.0102, -0.0610, -0.1424],\n",
            "          [-1.1258, -0.8667, -0.3113,  ..., -0.2496,  0.0960,  0.4046]]],\n",
            "\n",
            "\n",
            "        [[[-0.1505, -0.4474, -0.9308,  ...,  0.8333,  0.5534,  0.2566],\n",
            "          [ 0.4469,  0.2049,  0.0521,  ...,  1.2620,  1.1474,  0.5106]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.0425, -0.0484, -0.4271,  ..., -0.6165, -0.5559, -0.7074],\n",
            "          [ 0.2154, -0.2384, -0.3048,  ...,  0.5143,  0.2486,  0.2486]]],\n",
            "\n",
            "\n",
            "        [[[-1.0720, -1.1486, -1.1103,  ...,  0.2578,  0.3056,  0.3056],\n",
            "          [ 0.7333,  0.5538,  0.3893,  ...,  1.7355,  1.0474,  0.7034]]],\n",
            "\n",
            "\n",
            "        [[[-0.0497,  0.1545, -0.1631,  ...,  0.2453,  0.0335,  0.0713],\n",
            "          [ 0.3192,  0.7523,  0.6470,  ...,  1.0099,  0.9279,  0.7523]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1459,  0.1442,  0.3600,  ..., -2.3069, -2.8536, -3.4116],\n",
            "          [-0.5877, -0.2308, -0.6861,  ..., -0.6492, -0.6123, -0.1447]]],\n",
            "\n",
            "\n",
            "        [[[-3.4995, -3.1723, -2.0292,  ..., -0.4210, -0.3383, -0.6773],\n",
            "          [-1.1222, -1.1222, -0.7758,  ..., -0.6273, -0.0829, -0.0582]]],\n",
            "\n",
            "\n",
            "        [[[-0.0658, -0.0897, -0.2686,  ..., -0.1523,  0.1161,  0.1400],\n",
            "          [-0.1730, -0.1785, -0.4369,  ...,  0.0358, -0.2170, -0.4479]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.0982,  0.3907, -0.2656,  ..., -1.1131, -1.1769, -0.9444],\n",
            "          [-0.1832, -1.7989,  0.5480,  ...,  0.6777, -0.5724, -0.2422]]],\n",
            "\n",
            "\n",
            "        [[[-1.0913, -1.3280, -0.8650,  ...,  0.3457,  0.0885,  0.6853],\n",
            "          [-1.0046,  0.1606,  0.1751,  ...,  0.2836,  0.1027, -0.2085]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7280,  0.6291,  0.5771,  ...,  1.9355,  1.9147,  1.9303],\n",
            "          [-2.8862, -0.7975, -0.4342,  ..., -0.6158,  0.6815, -0.6677]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3791, -0.4499, -0.3352,  ..., -0.1462,  0.1676, -0.4094],\n",
            "          [ 0.1505, -0.9753, -0.3267,  ..., -0.0820, -0.0208,  0.0404]]],\n",
            "\n",
            "\n",
            "        [[[-0.2447, -0.1249, -0.0538,  ..., -0.4206, -0.7388, -0.8323],\n",
            "          [ 0.5340, -0.1264,  0.4993,  ...,  2.2720, -2.0265, -0.8795]]],\n",
            "\n",
            "\n",
            "        [[[-0.4022, -0.5084, -0.2147,  ..., -1.9579, -2.5546, -2.6389],\n",
            "          [-0.3269, -0.3476, -0.0276,  ...,  1.0872,  1.4072,  0.3027]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-3.4973e+00, -3.5263e+00, -3.5511e+00,  ..., -1.8158e-01,\n",
            "            1.0025e-01, -4.0665e-02],\n",
            "          [-8.4563e-01, -6.2044e-01, -2.7684e+00,  ..., -5.5056e-03,\n",
            "            3.2362e-01,  4.6461e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6390e-01,  6.6635e-01,  2.7985e-01,  ..., -7.8024e-01,\n",
            "           -9.0908e-01, -9.6429e-01],\n",
            "          [-2.1684e-01, -1.6270e-01, -8.5751e-01,  ..., -2.7976e+00,\n",
            "           -1.9403e+00, -1.7869e+00]]],\n",
            "\n",
            "\n",
            "        [[[-7.9410e-01, -3.7516e-01, -1.2996e+00,  ..., -5.9829e-01,\n",
            "           -3.7516e-01, -4.8445e-01],\n",
            "          [-1.5634e+00, -3.1757e+00, -2.1513e+00,  ..., -1.6485e-01,\n",
            "           -4.9044e-02,  2.0928e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.8915e-01,  2.3108e-01,  6.5625e-01,  ..., -3.9578e-01,\n",
            "           -1.4214e-02, -1.9409e-01],\n",
            "          [-8.5402e-01, -1.4070e+00, -1.1817e+00,  ...,  1.4957e-01,\n",
            "            2.6681e-02, -2.3958e-01]]],\n",
            "\n",
            "\n",
            "        [[[-7.4515e-02, -4.8197e-01, -2.1210e-01,  ...,  5.4461e-01,\n",
            "            5.2484e-02,  1.7419e-01],\n",
            "          [ 7.9500e-01,  1.1124e-01,  2.9533e-01,  ..., -3.6213e-01,\n",
            "            1.9014e-01,  1.3754e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6865e-01,  1.1657e-01, -2.8408e-01,  ...,  1.8468e-01,\n",
            "            2.5279e-01,  3.4093e-01],\n",
            "          [-1.5063e-01, -1.1893e-03,  6.7128e-01,  ..., -4.1214e-01,\n",
            "           -1.0472e+00, -8.9781e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.1398,  0.4412,  0.1994,  ..., -0.1710,  0.0201, -0.0774],\n",
            "          [-1.1414, -1.2913, -1.7838,  ...,  0.5287, -0.3920,  0.5287]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5743, -0.4191, -0.4844,  ..., -0.2632, -0.1762, -0.2523],\n",
            "          [ 0.4823,  0.0115,  0.7008,  ..., -0.6947, -0.5938, -0.1062]]],\n",
            "\n",
            "\n",
            "        [[[-0.4489, -0.2964, -0.4751,  ..., -0.2528, -0.0173, -0.2702],\n",
            "          [-0.9493, -0.0768, -0.3803,  ..., -0.3613, -0.8355, -1.0441]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.5430, -0.3281, -0.8024,  ...,  0.3833,  0.3314, -0.0539],\n",
            "          [ 0.0269, -0.2269, -0.1576,  ..., -1.5879, -0.6421, -0.8036]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6103, -0.1112,  1.2596,  ...,  1.0721,  0.6103,  0.0187],\n",
            "          [-1.2641, -1.6108, -1.8585,  ...,  0.2715, -0.0257,  0.0734]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1676,  0.5643,  0.1676,  ...,  1.0202, -0.4318,  1.1299],\n",
            "          [-0.1172, -0.0614, -0.1533,  ...,  1.6917,  1.9576,  2.4172]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.0578e-01,  6.9499e-01,  5.1300e-01,  ...,  3.3556e-01,\n",
            "            5.0845e-01,  2.4456e-01],\n",
            "          [ 6.9547e+00,  5.7935e+00,  4.7576e+00,  ...,  2.4940e-01,\n",
            "           -6.9364e-02,  1.0140e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.0189e-01,  2.6852e-01,  2.9322e-01,  ..., -7.4393e-01,\n",
            "           -1.2658e-01,  9.2376e-03],\n",
            "          [ 4.1043e-02, -2.9832e-01,  1.0093e-01,  ...,  7.3973e-01,\n",
            "            2.6063e-01,  3.2052e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.8577e-01,  4.5418e-02, -1.0238e-02,  ..., -1.0238e-02,\n",
            "            1.2248e-01, -3.2277e-01],\n",
            "          [ 6.8997e-02, -2.3662e-02, -1.4412e-01,  ..., -3.9430e-01,\n",
            "           -3.1091e-01, -2.8311e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9339e-01, -4.0672e-01, -2.7450e-01,  ..., -5.0116e-01,\n",
            "           -6.9004e-01, -2.8950e-02],\n",
            "          [-2.2061e-01,  2.5688e-01, -6.7817e-02,  ...,  1.2501e+00,\n",
            "            1.4602e+00,  9.0627e-01]]],\n",
            "\n",
            "\n",
            "        [[[-6.6073e-01, -1.0788e+00, -1.8684e+00,  ...,  1.2747e+00,\n",
            "            7.4826e-01,  1.3986e+00],\n",
            "          [ 1.2949e+00,  9.5847e-01,  1.0636e+00,  ...,  6.4310e-01,\n",
            "            1.2369e-02,  1.5954e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2651e+00,  4.6915e-01,  1.3086e+00,  ..., -1.0650e+00,\n",
            "            1.3628e-01,  6.0254e-03],\n",
            "          [-6.9658e-02, -4.6556e-01, -1.3217e-01,  ...,  1.6598e+00,\n",
            "            1.5348e+00,  4.5126e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.3565, -0.7691, -0.9256,  ..., -0.3139, -1.3381, -0.9682],\n",
            "          [ 0.4922,  0.0815, -0.0792,  ..., -2.1328, -1.1328,  0.0458]]],\n",
            "\n",
            "\n",
            "        [[[-1.1981, -2.4397, -1.8026,  ...,  0.7133,  1.0400,  0.2885],\n",
            "          [-0.9934, -1.0881,  0.2615,  ...,  1.2560,  0.4983,  0.6404]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8082,  0.7820,  0.4551,  ...,  0.2066, -0.6303,  0.2589],\n",
            "          [ 0.7976,  0.0843,  0.2270,  ..., -1.2199, -0.6289, -0.3028]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.8035, -0.2632,  0.0069,  ..., -0.0408,  0.3088, -0.0884],\n",
            "          [ 0.4851, -0.0217, -0.6267,  ..., -0.8066, -1.1009, -0.5940]]],\n",
            "\n",
            "\n",
            "        [[[-0.5258,  0.0177,  0.4369,  ...,  0.3127,  0.9183,  0.5767],\n",
            "          [-0.4109, -0.6824, -0.8453,  ...,  2.4129,  2.1414,  1.4173]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5310,  0.8374,  0.5576,  ...,  0.1048,  0.3445,  0.3845],\n",
            "          [ 1.2193,  1.1057,  0.7078,  ...,  1.3709,  1.0867,  1.2762]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.2979,  0.4315,  0.1035,  ...,  0.7109,  0.8080,  0.4679],\n",
            "          [ 1.6655,  1.3933,  0.9171,  ...,  1.3480,  1.2346,  1.3933]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1254,  0.2682,  0.3942,  ..., -0.4709, -0.3533, -0.3617],\n",
            "          [ 0.4396,  0.4684,  0.3173,  ...,  0.1519, -0.0279, -0.2868]]],\n",
            "\n",
            "\n",
            "        [[[-0.0668, -0.6443, -0.7213,  ...,  1.2230,  1.4155,  1.4347],\n",
            "          [-1.7660, -2.0355, -1.1912,  ..., -0.1135, -0.2213, -0.2752]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.4478, -0.1239,  0.3109,  ..., -2.0846, -1.2747, -0.7718],\n",
            "          [ 1.0239,  1.1817,  1.0889,  ...,  0.1232, -0.1739, -0.2389]]],\n",
            "\n",
            "\n",
            "        [[[-0.4711, -0.6071, -1.4147,  ...,  0.7956,  1.3227,  1.3822],\n",
            "          [-0.1346, -0.0809,  0.1450,  ...,  1.6401,  1.5003,  1.5863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8667, -0.1326, -1.4295,  ..., -1.0175, -1.0023, -0.8650],\n",
            "          [ 1.3450,  1.1989,  1.6374,  ...,  0.0293,  0.0415, -0.2753]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-9.1904e-01, -8.4851e-01, -5.7422e-01,  ...,  4.1320e-01,\n",
            "            2.2512e-01, -2.6075e-01],\n",
            "          [-3.4432e-01, -3.6828e-01, -6.7978e-01,  ...,  8.6984e-02,\n",
            "           -4.0423e-01, -2.0842e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.2535e-01, -6.5633e-01, -5.9084e-01,  ..., -2.1364e+00,\n",
            "           -2.3656e+00, -2.5490e+00],\n",
            "          [ 6.9550e-01,  8.9336e-01,  8.1642e-01,  ..., -1.3380e+00,\n",
            "           -1.5579e+00, -1.6018e+00]]],\n",
            "\n",
            "\n",
            "        [[[-3.3535e+00, -3.5449e+00, -3.5449e+00,  ...,  1.1831e+00,\n",
            "            1.0316e+00,  9.0402e-01],\n",
            "          [-2.0126e+00, -2.0960e+00, -2.4296e+00,  ..., -3.4482e-01,\n",
            "           -1.3634e-01, -2.5156e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.4438e-01,  5.8609e-01,  9.8547e-01,  ..., -6.6357e-01,\n",
            "           -1.2948e+00, -1.2691e+00],\n",
            "          [-9.2864e-01, -6.6268e-01, -1.0117e+00,  ...,  1.0194e-01,\n",
            "            2.2052e-03,  5.2072e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.6414e-01, -7.2030e-01, -3.5203e-01,  ..., -5.8001e-01,\n",
            "           -3.6080e-01, -3.9587e-01],\n",
            "          [ 3.8062e-02,  1.7638e-01,  4.7283e-02,  ..., -7.2591e-02,\n",
            "           -1.6480e-01, -1.6480e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4882e-01, -1.2525e-01, -3.8455e-01,  ..., -1.2174e+00,\n",
            "           -1.0053e+00, -1.0760e+00],\n",
            "          [-1.1480e-01, -1.0600e-01, -1.4119e-01,  ...,  6.1530e-01,\n",
            "            4.3057e-01,  3.7780e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-1.1139, -1.4858, -1.7834,  ...,  0.2559, -0.5313, -0.9218],\n",
            "          [ 0.5046,  0.6106,  0.5699,  ...,  0.9043,  0.9695,  1.3447]]],\n",
            "\n",
            "\n",
            "        [[[-0.7784, -0.5416, -0.5609,  ...,  1.2127,  0.7294,  1.4834],\n",
            "          [ 0.4112,  0.3681,  0.1555,  ..., -0.8140, -0.9229, -0.9305]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4615,  1.9443,  2.2551,  ..., -0.6148, -0.4594, -0.3954],\n",
            "          [-2.0135, -2.0589, -1.9340,  ...,  0.1548,  0.0981, -0.0154]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.6579, -0.3394,  0.0370,  ...,  0.4424,  0.1818,  0.2493],\n",
            "          [ 0.5110,  0.4790,  0.4502,  ..., -0.2652, -0.3292, -0.4053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1808,  0.6674,  0.6418,  ...,  0.9747,  0.7314,  0.4881],\n",
            "          [-1.3902, -1.6533, -0.4702,  ..., -0.1280, -0.1418, -0.1039]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4001,  0.0346,  0.0346,  ...,  0.8977,  1.0703,  0.8774],\n",
            "          [-0.1310, -0.0741, -0.0878,  ..., -1.8453, -1.7677, -1.8148]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.8548,  0.8043,  0.6781,  ...,  0.4257,  0.2616,  0.1985],\n",
            "          [-1.5261, -1.5279, -1.5019,  ...,  1.1810,  1.2631,  1.2613]]],\n",
            "\n",
            "\n",
            "        [[[-0.1770, -0.4810, -0.6735,  ..., -1.2714, -1.3525, -1.3322],\n",
            "          [ 1.1752,  1.1801,  1.2245,  ...,  0.4974,  0.4780,  0.5394]]],\n",
            "\n",
            "\n",
            "        [[[-1.0069, -1.3015, -1.4611,  ...,  1.5712,  1.2029,  1.0188],\n",
            "          [ 0.5470,  0.5661,  0.5728,  ...,  0.7983,  0.7741,  0.7525]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1816,  0.8470,  0.6209,  ..., -0.0211, -0.2110, -0.2200],\n",
            "          [-0.9016, -0.9434, -0.7480,  ..., -0.0219,  0.3271,  0.3969]]],\n",
            "\n",
            "\n",
            "        [[[-0.2267,  0.3578,  0.7633,  ...,  1.0377,  1.2882,  1.4194],\n",
            "          [ 0.2608,  0.1215, -0.0179,  ...,  0.9052,  0.1737, -0.3488]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8420,  0.6065,  0.5172,  ...,  0.9151,  0.9476,  0.9719],\n",
            "          [-0.6662, -0.8696, -0.7243,  ..., -0.3756, -0.2303, -0.0705]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.3882,  1.4741,  1.5792,  ..., -0.2266, -0.2553, -0.4464],\n",
            "          [ 0.1256,  0.0488, -0.0152,  ...,  0.5865,  0.7785,  0.9449]]],\n",
            "\n",
            "\n",
            "        [[[-0.7368, -0.9074, -1.0353,  ...,  0.1073,  0.5678,  0.6275],\n",
            "          [ 1.2892,  0.9674,  1.0373,  ...,  0.6456,  0.2958, -0.4456]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6718,  0.4653,  0.3745,  ..., -1.6823, -1.9879, -2.0705],\n",
            "          [-0.8350, -0.8209, -0.8209,  ...,  0.4558,  0.3856, -0.3159]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.9402, -2.0745, -2.2871,  ..., -0.5194, -0.3292,  0.1295],\n",
            "          [-0.1553, -0.1553, -0.0940,  ...,  0.0440,  0.3660,  0.0747]]],\n",
            "\n",
            "\n",
            "        [[[-0.0330,  0.8605,  0.9598,  ...,  0.4138,  0.2317, -0.0661],\n",
            "          [-0.0491,  0.2150,  0.2150,  ..., -0.5441, -1.1051, -1.2536]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4109,  0.4643,  0.2908,  ..., -0.5235, -0.3900, -0.3500],\n",
            "          [-1.2339, -1.5622, -1.8904,  ...,  0.5605, -0.1398, -0.1179]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.6873, -0.7520, -0.5795,  ..., -0.6873, -0.9030, -1.0108],\n",
            "          [-0.3853, -0.4274, -0.5959,  ...,  1.1944,  1.2365,  0.8153]]],\n",
            "\n",
            "\n",
            "        [[[-1.0515, -1.4670, -0.9685,  ...,  0.8595,  0.2225, -0.0268],\n",
            "          [ 0.5049,  0.4482,  0.3726,  ..., -0.7987, -0.4020, -0.2508]]],\n",
            "\n",
            "\n",
            "        [[[-0.0873, -0.1781,  0.1072,  ...,  0.9112,  0.8983,  0.7427],\n",
            "          [-0.0807,  0.2762, -0.0212,  ..., -1.5679, -2.2620, -2.3016]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0600,  1.2681,  0.9675,  ...,  2.2511,  1.9735,  1.4532],\n",
            "          [ 0.2748,  0.6936,  0.5159,  ..., -1.8571, -1.6160, -1.2480]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7534,  0.4275,  0.4275,  ...,  0.1609, -0.1575, -0.0982],\n",
            "          [-1.0469, -0.8971, -1.0239,  ...,  1.9257,  1.8911,  1.7759]]],\n",
            "\n",
            "\n",
            "        [[[-0.4057, -0.5135, -0.6311,  ..., -3.7083, -3.6691, -3.8553],\n",
            "          [ 1.7252,  1.6396,  1.4441,  ...,  1.6274,  1.3830,  1.5175]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-3.1407, -2.9290, -2.7766,  ...,  1.2365,  1.2704,  0.8047],\n",
            "          [ 1.5993,  1.5476,  1.3149,  ..., -0.0554, -0.1071, -0.0554]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5479,  0.2686,  0.0618,  ...,  0.6926,  0.5892,  0.2893],\n",
            "          [ 0.1918,  0.2144,  0.2595,  ..., -0.9021, -0.6991, -0.8909]]],\n",
            "\n",
            "\n",
            "        [[[-0.2496, -0.7642, -0.8414,  ..., -0.8328, -0.9700, -1.4932],\n",
            "          [-1.1367, -0.7360, -0.3220,  ..., -0.7093, -0.1350,  0.5596]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0257, -0.2167, -0.4395,  ..., -0.3758,  0.1653,  0.1414],\n",
            "          [ 0.5447, -0.3602, -0.5917,  ...,  0.7972, -0.0235, -0.4864]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2063, -0.0193,  0.2063,  ..., -1.7611, -0.5331, -0.7837],\n",
            "          [-0.2475, -0.2475, -0.6123,  ...,  0.5466,  0.7826,  1.1689]]],\n",
            "\n",
            "\n",
            "        [[[-0.0743, -0.1371, -0.0086,  ..., -0.1428, -0.2199, -0.1828],\n",
            "          [ 1.0671,  0.7683,  0.1180,  ..., -0.5324,  0.0301,  0.0301]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.5253, -0.0361,  0.5609,  ..., -0.5685, -0.6835, -0.0505],\n",
            "          [-0.3342, -0.4245, -0.6594,  ...,  0.2620,  0.6776,  0.2801]]],\n",
            "\n",
            "\n",
            "        [[[-0.2332,  0.8327,  0.7550,  ...,  0.6662,  0.5884,  1.4101],\n",
            "          [-0.2212, -0.3054, -0.3054,  ..., -0.5583, -0.4881, -1.0360]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5502,  0.6511, -0.1437,  ...,  1.0681,  1.2114,  0.2863],\n",
            "          [-1.9800, -1.5891,  0.2586,  ..., -0.0079, -0.3987, -0.0434]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0712,  1.5694,  0.4764,  ..., -2.3316, -2.4965, -2.0630],\n",
            "          [ 1.3165,  0.0562, -0.1565,  ...,  0.3476,  0.6470, -0.3140]]],\n",
            "\n",
            "\n",
            "        [[[-1.6484, -1.6116, -1.9120,  ...,  1.9750,  2.3981,  2.1130],\n",
            "          [ 0.4136,  0.3271,  1.0320,  ...,  0.3072, -0.2447,  0.4535]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8627,  3.0819,  3.9736,  ...,  1.0165,  0.0185,  0.7300],\n",
            "          [-0.0474,  0.6477, -0.0551,  ...,  0.0067,  0.5860,  0.1534]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4774,  0.1233, -0.7195,  ..., -1.8422, -1.1189, -0.9994],\n",
            "          [ 0.4446, -0.3000, -0.1628,  ...,  0.4903,  0.4315,  0.4642]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4558,  0.6253,  1.0952,  ...,  0.4096, -0.0988,  0.7909],\n",
            "          [ 0.4694,  0.4487,  0.3868,  ..., -0.1159,  0.4350,  0.3523]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5376,  1.3866,  0.6069,  ...,  0.3808,  0.1224,  1.5297],\n",
            "          [ 0.2827, -0.2365, -0.5286,  ...,  2.1163,  2.2867,  1.3456]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5083,  0.1942, -0.1358,  ...,  0.3499,  2.5733,  0.9354],\n",
            "          [-1.2963, -1.4098, -0.7904,  ...,  1.7082,  1.1507,  1.8321]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1458, -0.8438,  0.5508,  ...,  1.2420, -0.3809,  1.6868],\n",
            "          [ 1.0845,  1.5641,  0.3444,  ..., -1.0525, -0.4375, -1.5634]]],\n",
            "\n",
            "\n",
            "        [[[-0.3744,  1.2872,  0.1066,  ...,  0.6422, -0.3197,  0.6258],\n",
            "          [-1.3701, -1.4076, -0.3079,  ..., -0.2829,  0.5418, -0.7453]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.4968,  0.4472, -0.6243,  ...,  0.5748,  0.4472, -1.1729],\n",
            "          [ 0.0769, -0.9518,  0.3143,  ...,  0.6308,  0.5065,  1.8969]]],\n",
            "\n",
            "\n",
            "        [[[-0.5335, -0.6657,  0.5097,  ..., -0.1440, -1.5211,  0.4541],\n",
            "          [ 1.4041,  2.1900,  1.7409,  ..., -0.2576,  0.4946, -0.6506]]],\n",
            "\n",
            "\n",
            "        [[[-0.6544,  0.5790, -0.9969,  ...,  0.2569,  0.4556, -0.5584],\n",
            "          [ 0.2135, -0.8072,  0.5621,  ...,  0.5123,  0.3878,  1.3463]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.4389,  0.8794, -0.6702,  ...,  0.3613, -1.1188,  0.2457],\n",
            "          [-0.6580, -1.6157, -0.5475,  ..., -1.2842, -0.4278, -1.2105]]],\n",
            "\n",
            "\n",
            "        [[[-0.8434, -0.0738, -1.0001,  ..., -0.2815, -0.0738, -0.4007],\n",
            "          [-0.1614, -0.8731,  0.0705,  ...,  0.9740,  1.2059,  1.2539]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2659, -0.0628,  0.5150,  ...,  3.0156,  1.6756,  2.5125],\n",
            "          [ 1.9031,  1.8844,  1.6880,  ..., -0.6689, -0.3977, -1.0991]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.6342,  1.2364,  0.3108,  ...,  0.5785,  0.0739,  0.8015],\n",
            "          [-0.3390, -0.8383, -0.2454,  ...,  0.7157,  0.9840,  0.1602]]],\n",
            "\n",
            "\n",
            "        [[[-0.4710,  0.0987, -1.1450,  ...,  1.1418, -0.0458,  0.8529],\n",
            "          [ 0.9667,  0.4047,  1.1071,  ...,  0.0498, -0.0611, -0.5787]]],\n",
            "\n",
            "\n",
            "        [[[-0.1881,  0.6880, -0.3804,  ..., -0.5076, -0.2911, -0.6175],\n",
            "          [-0.4739, -1.5372, -0.6498,  ...,  1.1410,  0.9572,  0.5894]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8924, -0.7320,  0.3964,  ...,  0.9578,  0.3582,  1.2249],\n",
            "          [-0.9355, -0.2442, -0.5544,  ..., -1.3432, -1.0684, -2.8409]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2980,  0.9877,  0.4239,  ..., -0.2456,  0.5195, -0.1550],\n",
            "          [-1.1993, -2.0201, -1.0718,  ...,  2.0123,  0.5938,  1.1038]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5028,  0.5320,  0.5847,  ..., -2.2756, -1.6966, -2.2698],\n",
            "          [-0.4262,  0.1368, -0.9803,  ...,  2.1386,  1.2807,  2.0940]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-8.6087e-01, -1.0095e+00, -5.2567e-01,  ..., -2.0083e-01,\n",
            "           -1.2375e+00, -2.2502e-01],\n",
            "          [ 7.8791e-01,  1.2863e+00,  5.5057e-01,  ..., -5.1748e-01,\n",
            "           -2.6233e-01, -8.3196e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.5930e+00, -3.5339e-01, -1.4637e+00,  ...,  3.8824e+00,\n",
            "            4.3876e+00,  3.8354e+00],\n",
            "          [-9.0695e-01, -1.6115e+00, -1.4502e+00,  ..., -2.1123e+00,\n",
            "           -3.5724e+00, -2.9612e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9074e+00,  1.7239e+00,  5.9396e-01,  ...,  6.4154e-01,\n",
            "           -2.4542e-02,  1.4860e+00],\n",
            "          [-3.1409e+00, -1.5806e+00, -1.3827e+00,  ...,  1.6237e-01,\n",
            "            5.3532e-01, -7.2814e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9267e-01,  7.6081e-01, -6.1083e-01,  ..., -6.9214e-01,\n",
            "           -3.9519e-01, -6.2144e-01],\n",
            "          [ 5.3344e-02, -4.9606e-01,  9.8589e-02,  ...,  1.6353e-03,\n",
            "            5.3344e-02, -5.3484e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.2757e-01, -2.8500e-01, -8.5675e-02,  ...,  1.4379e+00,\n",
            "            2.6567e-01,  1.3839e+00],\n",
            "          [-9.8893e-03, -6.3239e-01, -2.7354e-01,  ..., -7.8619e-01,\n",
            "           -2.8086e-01, -7.0563e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6590e-02,  1.5886e+00,  4.5378e-03,  ..., -8.2977e-01,\n",
            "           -1.3627e+00, -8.8857e-01],\n",
            "          [-3.1627e-01, -6.8044e-01, -9.3722e-02,  ...,  1.3557e-01,\n",
            "            8.6391e-01,  5.8741e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-1.4072, -0.7982, -1.3026,  ...,  0.3059, -0.1493,  0.7180],\n",
            "          [ 1.4057,  0.7861,  1.2734,  ...,  0.7930,  0.6259,  0.4867]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4067,  1.1982,  0.2710,  ...,  2.1141,  0.8778,  2.0199],\n",
            "          [-0.0618, -0.1112, -0.5223,  ...,  0.3411,  0.1520,  0.5960]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5666,  1.3044,  0.5339,  ..., -0.7083, -0.3487, -1.4414],\n",
            "          [ 0.6870,  0.3921,  0.1587,  ..., -0.3512, -0.6460,  0.5088]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7882, -1.0360,  0.7662,  ..., -0.4822,  0.9508, -0.2184],\n",
            "          [-0.6111,  0.4124, -0.5781,  ...,  1.4690,  0.8637,  2.3715]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9294, -0.3016,  0.7134,  ...,  1.1944, -0.8967,  1.3737],\n",
            "          [ 1.7030,  1.9475, -0.0089,  ..., -1.6509, -0.6494, -1.1152]]],\n",
            "\n",
            "\n",
            "        [[[-1.1674,  0.9137, -1.5783,  ..., -0.8871, -1.3210, -0.7067],\n",
            "          [-0.3789, -0.6156, -0.3568,  ..., -0.7192, -0.2532, -0.9558]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.8177e+00, -1.0804e+00, -1.9772e+00,  ..., -8.4754e-01,\n",
            "            2.1404e+00, -3.8620e-01],\n",
            "          [-6.1184e-01, -1.2021e+00, -2.2450e-01,  ..., -3.7205e-01,\n",
            "           -4.4583e-01,  4.5796e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1911e+00, -1.7157e+00,  1.5065e+00,  ..., -6.3315e-01,\n",
            "            1.0760e+00, -9.7838e-01],\n",
            "          [ 3.0957e-01,  1.5615e+00,  8.5606e-01,  ...,  1.5567e-03,\n",
            "           -4.0582e-01, -4.8124e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0722e+00, -1.0656e+00,  1.0439e+00,  ...,  2.7205e-01,\n",
            "           -2.0480e-01,  5.0643e-01],\n",
            "          [-5.7850e-01, -4.6414e-01, -9.6729e-01,  ...,  2.5627e-01,\n",
            "           -2.1257e-01, -2.1257e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-8.2742e-01,  7.7598e-01, -1.3592e+00,  ...,  1.1173e+00,\n",
            "           -7.0041e-01,  9.4664e-01],\n",
            "          [ 5.5418e-01,  2.4038e-01,  2.8521e-01,  ...,  8.8293e-01,\n",
            "            9.7259e-01,  4.1222e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.1252e+00,  7.8723e-01, -1.1953e+00,  ..., -1.8533e+00,\n",
            "            6.7884e-02, -1.6954e+00],\n",
            "          [ 3.8485e-01, -1.0994e-02, -1.0994e-02,  ...,  1.1176e+00,\n",
            "            5.1118e-01,  1.4124e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2458e-01, -1.2489e+00,  9.8455e-01,  ...,  1.5965e-02,\n",
            "           -3.3343e-01,  1.0597e+00],\n",
            "          [ 6.0060e-01,  1.3344e+00,  1.7107e-01,  ..., -7.2379e-01,\n",
            "           -9.7387e-02, -1.5649e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[ 0.3103,  0.9159,  0.1863,  ..., -0.6920, -1.5668, -0.8124],\n",
            "          [-0.3220, -0.9824,  0.2177,  ...,  1.9077,  2.6746,  1.7941]]],\n",
            "\n",
            "\n",
            "        [[[-1.9565, -0.9713, -1.6698,  ..., -0.8260,  0.8819, -0.3576],\n",
            "          [ 2.9776,  1.8565,  2.2563,  ...,  0.9706, -0.6678,  0.0221]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1993, -0.3150,  0.9323,  ...,  0.8685,  0.5338,  0.5896],\n",
            "          [-0.8832,  0.1511, -0.6643,  ...,  1.6081,  0.6267,  1.2911]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8930, -0.3396,  0.8549,  ...,  0.9338,  0.4604,  0.7869],\n",
            "          [-0.2743,  0.6209,  0.2343,  ..., -0.2607,  0.2072,  0.3496]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1157,  0.3452,  0.1932,  ...,  0.3878, -0.4102,  0.1339],\n",
            "          [ 0.2577,  0.6732,  0.1344,  ..., -0.5083, -0.2227, -0.8004]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3187,  0.3015,  0.6266,  ..., -0.8178, -0.9746, -0.6595],\n",
            "          [ 1.4074, -3.1752, -0.7654,  ..., -0.7851,  0.2486,  0.2025]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.2217, -1.5755, -0.9888,  ...,  0.3184,  0.3572,  0.2968],\n",
            "          [-3.5490, -1.8379, -1.9061,  ...,  0.3503, -0.2496, -0.1746]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7533,  0.3148,  0.4328,  ..., -0.5237,  0.4995,  0.2507],\n",
            "          [ 0.4995,  0.5919,  0.4934,  ..., -4.2665, -4.0386, -2.2899]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5744, -0.1638,  0.8688,  ..., -0.7027, -0.7933,  0.0241],\n",
            "          [-4.3116, -3.4787, -2.9815,  ...,  0.1034,  0.0225,  0.0104]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4941,  0.1253, -0.0290,  ..., -0.4017, -0.6716,  0.1638],\n",
            "          [ 0.8845,  0.8751,  0.2832,  ...,  0.3020,  0.4523,  0.3959]]],\n",
            "\n",
            "\n",
            "        [[[-0.0345, -0.5424, -0.4715,  ..., -0.2707,  0.9575,  0.3434],\n",
            "          [ 0.7480,  0.6491,  0.2658,  ...,  0.6243,  0.4265,  0.1051]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3130, -0.5357, -1.0007,  ..., -0.1055, -0.5589, -0.7682],\n",
            "          [ 0.3976,  0.5812,  0.8336,  ...,  0.7992,  0.0533,  0.0762]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.2622, -1.2743, -1.3950,  ...,  0.6940,  0.5853,  0.5008],\n",
            "          [ 0.2132, -0.1170, -0.2638,  ..., -1.3768, -1.1445, -1.3524]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8743,  0.2338,  0.6092,  ...,  2.2989,  1.7246,  1.6142],\n",
            "          [-1.9679, -2.0011, -2.0842,  ..., -1.8349, -1.2699, -1.6687]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1635,  1.5791,  1.1856,  ..., -0.6152, -1.5573, -1.4619],\n",
            "          [-1.8481, -1.9428, -1.7061,  ...,  1.3719,  1.4508,  1.5298]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4415, -1.3707, -1.2433,  ..., -0.5776, -0.6229, -0.6541],\n",
            "          [ 0.2306,  0.3826,  0.7202,  ...,  0.5640,  0.6189,  0.7244]]],\n",
            "\n",
            "\n",
            "        [[[-0.8393, -0.8699, -0.9709,  ..., -0.2820, -0.1289,  0.0548],\n",
            "          [ 0.8523,  0.9976,  1.0376,  ...,  1.3130,  1.1328,  1.0927]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2051,  0.0457,  0.0903,  ..., -0.4137, -0.5190, -0.5062],\n",
            "          [ 0.9121,  0.7195,  0.3523,  ..., -0.2857, -0.2917, -0.2736]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-5.1446e-01, -5.8856e-01, -6.3178e-01,  ...,  7.1433e-01,\n",
            "            7.3286e-01,  7.4212e-01],\n",
            "          [-3.5784e-01, -3.7758e-01, -3.2329e-01,  ...,  4.3176e-01,\n",
            "            1.3073e-01,  2.2156e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2049e-01,  6.8367e-01,  6.8980e-01,  ..., -4.8843e-01,\n",
            "           -5.5594e-01, -4.2707e-01],\n",
            "          [ 2.8044e-03,  5.9561e-02, -2.7757e-02,  ...,  9.8076e-01,\n",
            "            9.1091e-01,  9.0654e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.4072e-01, -3.1685e-01, -3.4414e-01,  ...,  8.8048e-01,\n",
            "            8.5319e-01,  7.5768e-01],\n",
            "          [ 9.6726e-01,  8.2066e-01,  7.8401e-01,  ..., -5.2490e-01,\n",
            "           -4.4637e-01, -5.4061e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4284e+00,  1.5864e+00,  1.7082e+00,  ..., -4.9087e-01,\n",
            "           -4.0199e-01, -2.6701e-01],\n",
            "          [-1.0029e-01, -2.1810e-01, -4.0464e-01,  ..., -1.5582e+00,\n",
            "           -1.6613e+00, -1.8184e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.0490e-01, -1.3317e-01, -4.8368e-02,  ...,  2.1632e-01,\n",
            "           -7.2511e-03,  3.0281e-03],\n",
            "          [-9.5205e-01, -9.8119e-01, -1.0006e+00,  ...,  6.8911e-01,\n",
            "            8.8333e-01,  9.0032e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.7750e-02,  4.7809e-01,  2.6118e-01,  ...,  1.5601e-01,\n",
            "            8.3303e-01,  1.4969e+00],\n",
            "          [ 1.3940e+00,  1.2699e+00,  1.1251e+00,  ..., -4.6410e+00,\n",
            "           -4.5624e+00, -4.4714e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.4888e-01,  4.6943e-01,  7.4358e-01,  ..., -8.8447e-01,\n",
            "           -1.0194e+00, -1.1628e+00],\n",
            "          [-4.9384e+00, -4.8508e+00, -4.7678e+00,  ...,  1.3925e+00,\n",
            "            1.6969e+00,  1.9920e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.7058e+00, -1.4000e+00, -8.7911e-01,  ...,  8.3656e-01,\n",
            "            9.7812e-01,  8.5355e-01],\n",
            "          [ 3.4348e+00,  3.7954e+00,  3.4348e+00,  ..., -1.7181e-01,\n",
            "           -3.9918e-01, -2.5021e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 6.0160e-01,  3.2159e-01,  2.1270e-01,  ..., -2.8510e-01,\n",
            "            1.0899e-01,  4.3567e-01],\n",
            "          [-1.3918e-01,  4.5912e-03,  9.8046e-02,  ..., -8.7963e-01,\n",
            "           -1.0090e+00, -1.1384e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.9740e-01,  2.7301e-02, -4.0551e-02,  ..., -1.3051e+00,\n",
            "           -1.2619e+00, -1.3482e+00],\n",
            "          [-5.0762e-01, -4.4020e-01, -3.3312e-01,  ...,  8.7651e-01,\n",
            "            8.5272e-01,  7.0994e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.2107e+00, -1.7602e+00, -1.7602e+00,  ..., -6.5285e-01,\n",
            "           -7.2793e-01, -7.7485e-01],\n",
            "          [ 9.3570e-01,  5.7293e-01, -2.8216e-02,  ..., -2.7697e-01,\n",
            "           -1.6296e-01, -7.4867e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2263e-01, -8.0617e-01, -9.1575e-01,  ...,  2.2987e+00,\n",
            "            2.0430e+00,  1.1937e+00],\n",
            "          [-2.7229e-01, -2.3197e-01,  3.3264e-01,  ...,  7.3593e-01,\n",
            "            1.0082e+00,  1.0586e+00]]]], dtype=torch.float64)\n",
            "tensor([[[[ 1.0719,  1.2491,  1.4746,  ..., -0.4826, -0.7806, -0.6276],\n",
            "          [ 0.7759,  0.2827,  0.1131,  ...,  0.1748,  0.6912,  0.8684]]],\n",
            "\n",
            "\n",
            "        [[[-0.8226, -0.1977, -0.0588,  ..., -0.9384, -1.0232, -0.7995],\n",
            "          [ 0.8398,  0.3998,  0.1230,  ...,  0.2791,  0.2294,  0.3075]]],\n",
            "\n",
            "\n",
            "        [[[-0.7787, -0.8738, -1.0799,  ..., -0.9135, -0.9293, -1.1274],\n",
            "          [ 0.2149,  0.1491,  0.2089,  ...,  1.0638,  0.8725,  0.5975]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8809,  0.9759,  1.5166,  ..., -0.5951, -0.7121, -0.4855],\n",
            "          [-1.3427, -1.3996, -1.4850,  ..., -0.1690, -0.1690, -0.4891]]],\n",
            "\n",
            "\n",
            "        [[[-0.2481, -0.1443, -0.2237,  ...,  0.8455,  0.7599,  0.6927],\n",
            "          [-0.5502, -0.6938, -0.7618,  ..., -2.1896, -2.1065, -1.9705]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6707,  0.3179,  0.2262,  ...,  0.2897,  0.7906,  1.0516],\n",
            "          [-1.5090, -1.3062, -0.9075,  ..., -0.3263, -0.2452, -0.2587]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 1.2541e+00,  1.4767e+00,  1.5324e+00,  ..., -8.8108e-01,\n",
            "           -8.6717e-01, -1.0828e+00],\n",
            "          [ 1.3951e-02, -2.4197e-01, -4.6508e-01,  ...,  8.2682e-04,\n",
            "            4.0199e-02,  1.4519e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.0050e+00, -1.1637e+00, -1.2065e+00,  ...,  3.1401e-01,\n",
            "            4.6667e-01,  5.5827e-01],\n",
            "          [ 1.1797e-01,  3.2563e-01,  4.5023e-01,  ..., -8.7190e-01,\n",
            "           -8.8575e-01, -1.0380e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4330e-01,  5.9586e-01,  4.9553e-01,  ..., -1.7810e-01,\n",
            "           -2.8320e-01, -1.1121e-01],\n",
            "          [-1.0093e+00, -1.1235e+00, -9.2511e-01,  ...,  4.6361e-01,\n",
            "            3.0731e-01,  2.7124e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3388e+00,  1.3388e+00,  1.9157e+00,  ...,  1.3659e+00,\n",
            "            1.5822e+00,  2.2853e+00],\n",
            "          [-7.1224e-01, -1.0411e+00, -1.1233e+00,  ..., -6.4768e-02,\n",
            "           -2.0865e-01, -4.2448e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1670e+00,  1.5403e+00,  1.1478e+00,  ..., -2.0205e-01,\n",
            "           -2.5026e-01, -4.4309e-01],\n",
            "          [-6.6131e-01, -5.0146e-01, -1.3968e-01,  ...,  6.2243e-02,\n",
            "            7.9070e-02,  2.3051e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.2311e-01, -4.7275e-01, -7.8714e-01,  ..., -5.1412e-01,\n",
            "           -7.5405e-01, -8.7815e-01],\n",
            "          [ 9.7355e-02,  2.2148e-01,  2.8354e-01,  ..., -9.1334e-01,\n",
            "           -1.1439e+00, -9.9313e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-1.0353e+00, -6.3062e-01, -8.5133e-01,  ..., -5.9383e-01,\n",
            "           -6.8580e-01, -5.7544e-01],\n",
            "          [-8.4463e-01, -7.7203e-01, -2.4571e-01,  ...,  3.0784e-01,\n",
            "            3.6228e-01,  4.2580e-01]]],\n",
            "\n",
            "\n",
            "        [[[-6.6612e-01, -6.2664e-01, -3.5033e-01,  ...,  2.9111e-01,\n",
            "            6.8584e-01,  2.9111e-01],\n",
            "          [ 4.2431e-01,  4.6267e-01,  5.7777e-01,  ...,  9.4362e-02,\n",
            "           -8.2121e-02,  1.1738e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 8.0107e-02,  2.3162e-01,  4.2228e-02,  ..., -2.6838e-01,\n",
            "           -3.1384e-01, -3.5929e-01],\n",
            "          [ 2.9772e-01,  2.7345e-01,  2.2489e-01,  ...,  1.4873e+00,\n",
            "            1.4064e+00,  1.7058e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.0410e-01, -6.4411e-03,  4.9419e-02,  ...,  1.6543e-01,\n",
            "            2.9434e-01,  3.5020e-01],\n",
            "          [ 3.3040e-01,  1.9715e-01,  4.3150e-04,  ...,  1.6503e+00,\n",
            "            1.3330e+00,  1.0601e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6330e-01,  2.9957e-01,  2.5869e-01,  ..., -1.9397e+00,\n",
            "           -1.8897e+00, -1.8170e+00],\n",
            "          [ 9.4614e-01,  1.0086e+00,  7.8381e-01,  ..., -5.9028e-02,\n",
            "           -3.7743e-01, -5.6473e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.8387e+00, -1.7233e+00, -1.6345e+00,  ..., -6.0930e-01,\n",
            "           -6.4480e-01, -4.0958e-01],\n",
            "          [-6.3173e-01, -6.2509e-01, -6.3837e-01,  ...,  4.6351e-01,\n",
            "            9.8433e-02, -5.7199e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.1507, -0.1235, -0.0107,  ..., -2.2814, -2.1064, -1.8109],\n",
            "          [-1.3576, -1.6557, -1.6400,  ...,  2.3296,  2.3531,  2.1335]]],\n",
            "\n",
            "\n",
            "        [[[-1.9420, -1.8068, -1.7303,  ...,  0.2116,  0.3918,  0.5720],\n",
            "          [ 1.3828,  1.1570,  0.8847,  ...,  1.7348,  1.5688,  1.3363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7466,  0.7554,  1.1570,  ...,  0.7335,  0.5022,  0.4192],\n",
            "          [ 1.3877,  1.2231,  1.1967,  ...,  0.9926,  1.0584,  1.0716]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.3515, -0.5745, -0.3218,  ..., -0.0914,  0.1018,  0.1984],\n",
            "          [-0.6184, -0.8521, -1.2483,  ..., -2.3659, -2.3354, -2.2338]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4970,  0.6518,  1.0357,  ...,  0.4723,  0.2989,  0.2060],\n",
            "          [-1.1333, -1.0843, -0.9646,  ..., -0.1702, -0.1974, -0.0885]]],\n",
            "\n",
            "\n",
            "        [[[-0.0952, -0.4707, -0.8139,  ..., -0.6638, -1.2537, -1.0928],\n",
            "          [ 0.1610,  0.7922,  1.4472,  ..., -0.0653,  0.0062,  0.4111]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.8287, -0.6184, -0.5318,  ..., -0.8101, -1.1008, -1.2245],\n",
            "          [ 0.4309,  0.4360,  0.3901,  ...,  0.4462,  0.6708,  0.8036]]],\n",
            "\n",
            "\n",
            "        [[[-1.4773, -1.0001, -1.0711,  ..., -0.6548, -0.0253,  0.1169],\n",
            "          [ 1.5842,  0.8793, -0.4640,  ...,  0.7463, -0.1448, -0.7300]]],\n",
            "\n",
            "\n",
            "        [[[-0.6177, -0.8301, -0.8393,  ..., -0.4330, -0.1376, -0.1098],\n",
            "          [-0.3896, -0.0085,  0.1265,  ..., -0.2149, -0.4532, -0.5643]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.3850, -1.5371, -1.3156,  ...,  0.1654,  0.1699, -0.0583],\n",
            "          [ 0.7476,  1.0552,  1.8882,  ..., -0.5901,  0.2533, -0.2756]]],\n",
            "\n",
            "\n",
            "        [[[-0.1298, -0.1441,  0.0598,  ...,  0.5198,  0.4486,  0.2922],\n",
            "          [-0.4813, -0.0774, -0.3057,  ..., -0.2823, -0.0949, -0.4169]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3691,  0.1053,  0.2676,  ..., -1.2924, -2.7916, -0.6690],\n",
            "          [-0.5980, -0.7469,  0.0339,  ..., -1.1711, -1.9610, -0.9635]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-2.0221, -1.7198, -0.9354,  ..., -0.8276, -1.0162, -0.9025],\n",
            "          [-1.2791, -0.9778, -1.1542,  ...,  2.5613,  2.7671,  2.5098]]],\n",
            "\n",
            "\n",
            "        [[[-0.0333,  0.0358,  0.2660,  ...,  1.9693,  1.6931,  1.5809],\n",
            "          [ 0.3892, -0.2629,  0.2015,  ...,  1.9503,  1.5353,  1.6440]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7749,  1.3083,  1.4910,  ...,  0.1755,  0.5915,  1.2802],\n",
            "          [ 0.7312,  1.3952,  0.0937,  ...,  1.9796,  0.5718,  0.4213]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1586, -0.0810, -0.1529,  ...,  0.1227,  0.7577,  1.3888],\n",
            "          [ 0.2342,  0.0255,  0.1667,  ...,  0.6576,  0.0992, -0.6802]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8974,  2.0128,  2.1211,  ..., -0.2389, -0.2179, -0.2494],\n",
            "          [-1.2167, -1.4527, -1.7124,  ..., -0.7682, -0.7092, -0.5499]]],\n",
            "\n",
            "\n",
            "        [[[-0.3690, -0.0343,  0.2849,  ..., -0.2406, -0.0537, -0.1082],\n",
            "          [-0.3885, -0.3287, -0.6407,  ...,  1.4963,  1.2441,  1.1977]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1753,  0.1713,  0.3694,  ...,  0.8011,  1.2368,  1.5418],\n",
            "          [ 0.8343,  0.7169,  0.5787,  ..., -0.5961, -1.1213, -1.4875]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5826,  1.6263,  1.4782,  ..., -0.3731, -0.2418, -0.5077],\n",
            "          [-1.7154, -1.8083, -1.4831,  ..., -1.2972, -1.4632, -1.3172]]],\n",
            "\n",
            "\n",
            "        [[[-0.2342, -0.3036, -0.0192,  ...,  0.7300,  0.6468,  0.5601],\n",
            "          [-1.4770, -1.4097, -1.4403,  ..., -1.5931, -1.5259, -1.1897]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3532,  0.2894,  0.3566,  ..., -0.3120, -0.2818, -0.2179],\n",
            "          [-0.4092, -0.4146, -0.7801,  ..., -0.8822, -0.7102, -0.7586]]],\n",
            "\n",
            "\n",
            "        [[[-0.3956, -0.1940, -0.5510,  ..., -0.0260,  0.0202,  0.5830],\n",
            "          [-0.9705, -0.9094, -0.6109,  ..., -1.4590, -1.5879, -1.8660]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3977,  0.8927,  0.9222,  ...,  0.1026,  0.1288, -0.0744],\n",
            "          [-1.4463, -1.6013, -1.2854,  ..., -0.3557, -0.4868, -0.4571]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.1863,  0.0789,  0.4160,  ..., -0.3175, -0.3730, -0.4768],\n",
            "          [-0.6580, -0.5405, -0.8514,  ...,  1.3113,  1.7397,  1.9401]]],\n",
            "\n",
            "\n",
            "        [[[-0.6763, -0.6320, -0.6602,  ..., -0.8371, -0.7165, -0.7848],\n",
            "          [ 1.9750,  1.6503,  1.7033,  ...,  1.4515,  1.2792,  1.2460]]],\n",
            "\n",
            "\n",
            "        [[[-0.7076, -0.6940, -0.6497,  ..., -2.0229, -1.9207, -1.6583],\n",
            "          [ 1.0732,  1.1124,  1.2201,  ...,  1.4551,  1.5138,  1.2739]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2951, -0.7118, -0.7919,  ..., -1.2322, -0.7862, -0.3515],\n",
            "          [ 1.2092,  0.4763,  0.4857,  ...,  1.8293,  1.3689,  0.7018]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4547,  0.6233,  1.0404,  ..., -0.4300, -0.0087, -0.3710],\n",
            "          [-0.2354, -0.6355, -1.3085,  ...,  0.1284, -0.1081,  0.2829]]],\n",
            "\n",
            "\n",
            "        [[[-0.2375, -0.5294, -0.0682,  ..., -0.1441, -0.3601,  0.2587],\n",
            "          [ 0.0140,  0.4416,  0.2743,  ..., -0.0789, -0.0139, -0.3299]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-1.1352e-01,  2.5933e-01, -8.2451e-03,  ..., -2.1002e-01,\n",
            "           -2.8898e-01, -2.7143e-01],\n",
            "          [ 1.0963e-01, -8.4288e-02,  4.2506e-02,  ..., -1.6356e+00,\n",
            "           -1.3895e+00, -1.5238e+00]]],\n",
            "\n",
            "\n",
            "        [[[-3.8126e-01, -9.9968e-02, -3.7632e-01,  ..., -7.0359e-02,\n",
            "           -3.0723e-01,  1.2704e-01],\n",
            "          [-9.4127e-01, -1.1316e+00, -7.2275e-01,  ...,  1.4427e-01,\n",
            "            1.3017e-01, -2.0818e-01]]],\n",
            "\n",
            "\n",
            "        [[[-2.3963e-01, -8.7767e-02, -2.6902e-01,  ...,  2.1069e+00,\n",
            "            1.9501e+00,  1.8081e+00],\n",
            "          [ 9.4221e-02, -2.1194e-01, -9.9141e-02,  ...,  2.0037e+00,\n",
            "            2.1326e+00,  2.5999e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 8.4222e-01,  3.5401e-01,  5.3323e-01,  ...,  2.5513e-01,\n",
            "           -7.2130e-01, -4.1506e-02],\n",
            "          [-1.0622e-01, -8.1515e-02,  2.0264e-01,  ...,  1.2851e-01,\n",
            "            5.8563e-01,  4.4973e-01]]],\n",
            "\n",
            "\n",
            "        [[[-8.6470e-01, -1.2327e-01, -1.1435e+00,  ...,  1.9992e-01,\n",
            "           -8.9638e-01,  2.8823e-02],\n",
            "          [ 9.0308e-01,  5.9472e-01,  1.0958e+00,  ...,  6.7934e-02,\n",
            "            4.6624e-01, -3.6891e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.8808e-01, -4.7523e-02, -5.5674e-01,  ..., -5.5960e-01,\n",
            "           -5.2241e-01, -5.5388e-01],\n",
            "          [-4.4752e-02, -1.2248e-01,  5.9090e-04,  ...,  2.9856e-01,\n",
            "            2.7049e-01,  2.7481e-01]]]], dtype=torch.float64)\n",
            "tensor([[[[-0.2337, -0.4353, -0.1950,  ...,  0.5647,  0.5585,  0.8091],\n",
            "          [ 0.9340,  0.9291,  1.0117,  ..., -1.3063, -1.1362, -1.4958]]],\n",
            "\n",
            "\n",
            "        [[[ 0.7685,  1.6000,  0.7317,  ..., -1.8823, -2.7919, -2.6495],\n",
            "          [-0.9300, -0.8229,  0.7003,  ..., -0.7540, -0.1646, -0.4478]]],\n",
            "\n",
            "\n",
            "        [[[-3.4153, -2.7850, -3.2238,  ..., -0.5066,  0.3757, -0.1425],\n",
            "          [ 0.2532, -0.5982, -0.2155,  ...,  0.0619, -0.9521, -0.9043]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.3703,  1.3290,  0.4783,  ..., -0.0485, -0.0616,  0.3343],\n",
            "          [-0.8684, -1.2632, -0.9365,  ..., -1.5695, -1.6035, -1.7192]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4049,  0.1162,  0.5807,  ..., -0.6324, -0.9978,  0.6304],\n",
            "          [-2.9995, -3.2112, -3.5236,  ...,  2.0193,  1.7976,  1.0216]]],\n",
            "\n",
            "\n",
            "        [[[-0.1240,  1.3646,  0.1485,  ...,  2.0648,  0.3792,  1.7336],\n",
            "          [ 1.2461,  0.3294,  0.5755,  ..., -0.5704, -0.1375, -0.3497]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.0552,  1.2498, -0.6444,  ..., -1.2423,  0.2678, -1.4998],\n",
            "          [ 0.3958, -0.1026,  0.6650,  ...,  0.3061, -0.2522,  0.4457]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3525, -1.5513,  0.3067,  ..., -0.2668,  0.0222, -0.1383],\n",
            "          [-0.6571,  0.0706, -0.7403,  ...,  0.4760,  0.6007,  0.8814]]],\n",
            "\n",
            "\n",
            "        [[[-0.1117, -0.2469, -0.0029,  ...,  0.2223,  0.5076, -0.1117],\n",
            "          [ 1.0754,  1.1503,  0.9755,  ..., -0.5635, -0.4221, -0.2058]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1567,  0.1770,  0.5052,  ..., -0.3014,  0.9447, -0.2346],\n",
            "          [-0.8274, -1.2163, -2.0415,  ..., -0.4100, -1.1119, -0.1823]]],\n",
            "\n",
            "\n",
            "        [[[ 0.8446, -0.2356,  0.6917,  ..., -0.1591, -0.8235, -0.3647],\n",
            "          [-1.0236, -0.0193, -0.6101,  ..., -0.7577, -0.1670, -0.8365]]],\n",
            "\n",
            "\n",
            "        [[[-0.5965,  0.1062, -0.1605,  ...,  0.5217,  0.6961,  0.7884],\n",
            "          [-0.1997, -0.6832, -0.2203,  ..., -0.5083, -0.5598, -0.8067]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.7534,  0.1298, -0.1485,  ..., -1.1741, -0.9525, -0.8804],\n",
            "          [-0.2162, -0.3448, -0.0600,  ...,  1.5659,  1.0147,  1.4189]]],\n",
            "\n",
            "\n",
            "        [[[-0.4439, -0.6379, -0.6102,  ...,  0.1657,  0.2766,  0.4816],\n",
            "          [ 1.0015,  2.0146,  1.9395,  ...,  0.3261,  0.4105,  0.1103]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1079,  0.1280,  0.2348,  ..., -0.5467, -1.2414,  0.1480],\n",
            "          [ 0.3468, -0.0812,  0.3300,  ...,  0.6237,  0.7916,  0.3132]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2470, -0.0278,  0.2720,  ..., -0.8321, -1.2817, -0.1626],\n",
            "          [ 0.8346,  0.9173,  0.3846,  ..., -0.6164, -0.1756, -0.9654]]],\n",
            "\n",
            "\n",
            "        [[[-0.3871, -0.0680, -0.4984,  ...,  0.6501,  0.6417,  0.6102],\n",
            "          [-0.4887, -0.7158, -0.6084,  ..., -1.9171, -0.5176, -1.4093]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9245,  0.8731,  0.8474,  ..., -0.3569, -0.1835, -0.0904],\n",
            "          [-1.3857, -2.2982, -0.4048,  ...,  0.2978,  0.2704,  0.1199]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[-0.0827,  0.5024,  0.5779,  ...,  0.3262,  0.9743,  1.2700],\n",
            "          [ 0.4015, -0.1589, -0.6341,  ...,  0.7548,  0.3162, -0.3904]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6428,  1.5694,  2.1764,  ..., -0.9717, -1.3185, -0.8049],\n",
            "          [-0.4175, -0.4845, -0.9087,  ..., -0.6296, -0.1943,  2.1946]]],\n",
            "\n",
            "\n",
            "        [[[-0.4008,  0.6021,  0.3446,  ...,  0.0991,  0.0658,  0.1234],\n",
            "          [ 0.8667,  0.4111,  1.2563,  ...,  0.2592,  1.0648,  1.3487]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.9131,  0.7529,  0.6155,  ...,  0.9532, -0.1800,  1.2222],\n",
            "          [-0.9900, -1.0757, -0.6350,  ..., -0.5983,  0.0750, -0.7207]]],\n",
            "\n",
            "\n",
            "        [[[-0.0262,  0.6081, -0.1470,  ..., -0.1652,  1.5686,  0.1973],\n",
            "          [-0.2544, -0.4611,  0.1017,  ..., -0.6334, -1.5867, -1.1847]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4655, -0.0477,  1.2671,  ..., -1.3172,  0.0827, -1.1641],\n",
            "          [-1.4677, -0.8523, -1.4571,  ...,  0.1664, -1.0963, -0.9053]]]],\n",
            "       dtype=torch.float64)\n",
            "tensor([[[[ 0.3329, -1.1312, -0.2829,  ..., -0.3004, -0.5328,  0.9430],\n",
            "          [-1.7232, -0.6179, -0.6592,  ...,  0.8077,  0.5701, -0.1634]]],\n",
            "\n",
            "\n",
            "        [[[-0.1325,  0.0220, -1.5107,  ..., -1.7008, -0.1562, -1.3265],\n",
            "          [ 0.3385,  0.9406,  2.1347,  ..., -0.2228, -0.6412,  0.3181]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4192, -0.9044,  0.4248,  ...,  0.3004, -0.7913,  0.3343],\n",
            "          [-0.2469,  0.5365, -0.0902,  ...,  0.7558,  1.2886,  0.7976]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1069,  0.2569,  0.0714,  ..., -1.7681, -1.5155, -1.6379],\n",
            "          [ 0.0709,  0.1748, -0.1714,  ...,  0.6050,  0.3182,  0.8523]]],\n",
            "\n",
            "\n",
            "        [[[-1.4839, -1.6899, -1.5803,  ...,  0.1410,  1.3333, -0.1481],\n",
            "          [ 0.5034,  0.6378,  0.2089,  ..., -0.0248,  0.3946, -0.0536]]],\n",
            "\n",
            "\n",
            "        [[[-1.7007, -0.3178, -0.1678,  ..., -0.1711,  0.1621,  0.4587],\n",
            "          [-0.5905,  0.0565, -0.3459,  ...,  0.5140,  0.1985,  2.4626]]]],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrhcTv-WNouk"
      },
      "source": [
        "train_batch_size = 1  # Important hyperparameter\n",
        "valid_batch_size = 1  # Can be made as large as what fits in memory; won't impact performance\n",
        "num_workers = 0  # Number of processes to use for the data loading process; 0 is the main Python process\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    train_ds, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\n",
        "loader_valid = DataLoader(\n",
        "    valid_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n",
        "loader_test = DataLoader(\n",
        "    test_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "-HkIjqU9RbAi",
        "outputId": "1aad89fd-6009-43ff-e1ab-691546ac165d"
      },
      "source": [
        "tr=np.array(train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-07f62f42d0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHVDuRucB3tb",
        "outputId": "25ac1524-3cdc-45df-9318-8ecac80b88ea"
      },
      "source": [
        "len(loader_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9850"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h21faDFGB1DM",
        "outputId": "a77bf0c2-bc9d-4e4a-f550-2e92e2003bad"
      },
      "source": [
        "len(loader_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyqp-6KgNtSL"
      },
      "source": [
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 100\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlFRZtmpOdxs"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, ZeroPadding1D, MaxPooling1D, BatchNormalization, Activation, Dropout, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nuqm-R3_R8QI"
      },
      "source": [
        "sfreq = raws[0].info['sfreq']  # Sampling frequency\n",
        "n_channels = raws[0].info['nchan']  # Number of channels\n",
        "input_size_s=30\n",
        "input_size=int(input_size_s * sfreq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi0MbhLs20oX",
        "outputId": "16a6ba91-9e92-4294-97ed-c5c62b66f39c"
      },
      "source": [
        "input_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhbARZKD2_IO"
      },
      "source": [
        "input_shape=(input_size, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feGyuKrdUESv"
      },
      "source": [
        "input_shape=(3000,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3RsO3Kpjr6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6532b345-cd0a-4bf6-c12d-fc5d1c883a64"
      },
      "source": [
        "n_channels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmoDHQzu2odl",
        "outputId": "300eedea-f1bd-40cd-ca0c-b40eeb5e641f"
      },
      "source": [
        "sfreq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91_NOSJ-XQaG",
        "outputId": "e167ea56-db32-4245-ddb1-50888739e109"
      },
      "source": [
        "input_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZezlgtsWUQ0P"
      },
      "source": [
        "from keras.layers import Input\n",
        "newInput = Input(batch_shape=(3000,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph0KIJO0jwcM",
        "outputId": "f61b3720-d770-47d1-a5ff-add8935295ec"
      },
      "source": [
        "newInput"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(3000, 1) dtype=float32 (created by layer 'input_2')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2r8DwBAOkLS",
        "outputId": "1e361230-98ef-4bdc-9c27-72b3be225b64"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=5,strides=3, padding = \"same\",activation=\"relu\", input_shape=input_shape))\n",
        "model.add(Conv1D(128, kernel_size=5,strides=1, padding = \"same\",activation=\"relu\", input_shape=input_shape))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(128, kernel_size=13,strides=1, padding = \"same\",activation=\"relu\"))\n",
        "model.add(Conv1D(256, kernel_size=7,strides=1, padding = \"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(256,kernel_size=7,strides=1, padding = \"same\", activation=\"relu\"))\n",
        "model.add(Conv1D(64,kernel_size=4,strides=1, padding = \"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(32,kernel_size=3,strides=1, padding = \"same\", activation=\"relu\"))\n",
        "model.add(Conv1D(64,kernel_size=6,strides=1, padding = \"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(8,kernel_size=5,strides=1, padding = \"same\", activation=\"relu\"))\n",
        "model.add(Conv1D(8,kernel_size=2,strides=1, padding = \"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 1000, 64)          384       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1000, 128)         41088     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 500, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 500, 128)          213120    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 500, 256)          229632    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 250, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 250, 256)          459008    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 250, 64)           65600     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 125, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 125, 32)           6176      \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 125, 64)           12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 62, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 62, 8)             2568      \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 62, 8)             136       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 31, 8)             0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 248)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                15936     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,046,325\n",
            "Trainable params: 1,046,325\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdqfGLTUA5ZJ"
      },
      "source": [
        "model.compile(loss=keras.losses.MeanSquaredError,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSiir6t5JkDg"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_x = pd.DataFrame(loader_train)\n",
        "test_x = pd.DataFrame(loader_test)\n",
        "train_y=pd.DataFrame(y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1IsoWsjiBwC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "37cIeFW_Wneu",
        "outputId": "77be9845-1cef-459f-c963-97b5c9e3f3f2"
      },
      "source": [
        "train_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15458</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15459</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15460</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15461</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15462</th>\n",
              "      <td>W</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15463 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "0      W\n",
              "1      W\n",
              "2      W\n",
              "3      W\n",
              "4      W\n",
              "...   ..\n",
              "15458  W\n",
              "15459  W\n",
              "15460  W\n",
              "15461  W\n",
              "15462  W\n",
              "\n",
              "[15463 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Qzx7D3VfGm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "NUVph71mPqFe",
        "outputId": "4e5117a5-b2d5-4cc4-88b6-fa6c08638950"
      },
      "source": [
        "train_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[tensor([-1.2933, -0.9369, -1.1186,  ..., -0...</td>\n",
              "      <td>[tensor(1)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[tensor([7.6767e-01, 1.1230e+00, 1.3045e+00,...</td>\n",
              "      <td>[tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[tensor([ 0.7409,  0.7311,  0.7197,  ..., -2...</td>\n",
              "      <td>[tensor(2)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[tensor([-0.1017,  0.5555, -0.3466,  ...,  2...</td>\n",
              "      <td>[tensor(1)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[tensor([-0.2683, -0.7251, -0.5561,  ..., -0...</td>\n",
              "      <td>[tensor(1)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15458</th>\n",
              "      <td>[[[tensor([-0.1434, -0.0687, -0.3242,  ...,  0...</td>\n",
              "      <td>[tensor(1)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15459</th>\n",
              "      <td>[[[tensor([1.2742, 1.1967, 1.1115,  ..., 0.659...</td>\n",
              "      <td>[tensor(4)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15460</th>\n",
              "      <td>[[[tensor([-0.1852, -0.1364, -0.0437,  ..., -1...</td>\n",
              "      <td>[tensor(0)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15461</th>\n",
              "      <td>[[[tensor([ 1.0656,  1.3737,  1.6616,  ...,  0...</td>\n",
              "      <td>[tensor(3)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15462</th>\n",
              "      <td>[[[tensor([-1.0261, -0.8454, -0.5660,  ...,  0...</td>\n",
              "      <td>[tensor(2)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15463 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                       0            1\n",
              "0      [[[tensor([-1.2933, -0.9369, -1.1186,  ..., -0...  [tensor(1)]\n",
              "1      [[[tensor([7.6767e-01, 1.1230e+00, 1.3045e+00,...  [tensor(0)]\n",
              "2      [[[tensor([ 0.7409,  0.7311,  0.7197,  ..., -2...  [tensor(2)]\n",
              "3      [[[tensor([-0.1017,  0.5555, -0.3466,  ...,  2...  [tensor(1)]\n",
              "4      [[[tensor([-0.2683, -0.7251, -0.5561,  ..., -0...  [tensor(1)]\n",
              "...                                                  ...          ...\n",
              "15458  [[[tensor([-0.1434, -0.0687, -0.3242,  ...,  0...  [tensor(1)]\n",
              "15459  [[[tensor([1.2742, 1.1967, 1.1115,  ..., 0.659...  [tensor(4)]\n",
              "15460  [[[tensor([-0.1852, -0.1364, -0.0437,  ..., -1...  [tensor(0)]\n",
              "15461  [[[tensor([ 1.0656,  1.3737,  1.6616,  ...,  0...  [tensor(3)]\n",
              "15462  [[[tensor([-1.0261, -0.8454, -0.5660,  ...,  0...  [tensor(2)]\n",
              "\n",
              "[15463 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-_0OCSiPlkK",
        "outputId": "fb1d08b1-8888-4220-981f-9a2847b46f12"
      },
      "source": [
        "len(train_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1DCF_QMdl_"
      },
      "source": [
        "train_x=np.asarray(loader_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "2Qz5NbEnjway",
        "outputId": "39c2ade5-b6be-4dbf-c142-a94b81531217"
      },
      "source": [
        "train_x=np.asarray(train_x).astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-9cbd40719628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'DataLoader'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "7zigLC2hKVwv",
        "outputId": "bf6ea2e2-edc1-48a3-8517-9e1b586d8ed3"
      },
      "source": [
        "len(train_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-9aafcb6c8146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FH4J328rkZrS",
        "outputId": "bc216d9a-154b-46c4-b3fe-420c66ce2b11"
      },
      "source": [
        "test_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[tensor([ 0.3842,  0.8294,  1.0075,  ..., -0...</td>\n",
              "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[tensor([-0.8096, -0.5088, -0.0043,  ...,  0...</td>\n",
              "      <td>[tensor(4), tensor(4), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[tensor([-0.9429, -0.8522, -0.7240,  ...,  0...</td>\n",
              "      <td>[tensor(3), tensor(3), tensor(3), tensor(3), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[tensor([0.6978, 1.4083, 1.7688,  ..., 0.803...</td>\n",
              "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[tensor([ 0.5288,  0.5753,  0.6863,  ..., -1...</td>\n",
              "      <td>[tensor(3), tensor(3), tensor(3), tensor(3), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[[[tensor([0.4944, 0.6718, 0.5796,  ..., 0.437...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[[[tensor([-0.8107, -1.0677, -1.1036,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[[[tensor([0.6215, 1.1584, 1.5782,  ..., 1.915...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[[[tensor([ 0.6945,  0.2766, -0.0764,  ...,  0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[[[tensor([0.4592, 0.4426, 0.4842,  ..., 0.800...</td>\n",
              "      <td>[tensor(4), tensor(0), tensor(1), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[[[tensor([ 0.1073,  0.1550,  0.2451,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(3), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[[[tensor([ 3.8256e-02, -5.0368e-02,  2.7431e-...</td>\n",
              "      <td>[tensor(1), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[[[tensor([ 1.3807,  1.4557,  1.5608,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(3), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[[[tensor([ 0.2945,  0.1529, -0.3722,  ...,  0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[[[tensor([-0.9781, -1.0938, -1.0533,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(3), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[[[tensor([ 0.0792,  0.5837,  0.4124,  ..., -0...</td>\n",
              "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[[[tensor([-0.2651, -0.7041, -0.4992,  ...,  0...</td>\n",
              "      <td>[tensor(2), tensor(4), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[[[tensor([-0.2677, -0.2284, -0.0579,  ..., -0...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[[[tensor([-1.0933, -1.0227, -0.7504,  ...,  0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[[[tensor([ 1.2154,  1.1756,  0.8277,  ...,  0...</td>\n",
              "      <td>[tensor(4), tensor(4), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[[[tensor([0.1735, 0.3565, 0.3220,  ..., 0.271...</td>\n",
              "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[[[tensor([-3.1622, -2.9935, -2.4406,  ...,  1...</td>\n",
              "      <td>[tensor(4), tensor(4), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[[[tensor([-0.7350, -0.6467, -0.3084,  ...,  0...</td>\n",
              "      <td>[tensor(4), tensor(4), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[[[tensor([ 0.4735,  0.7754,  0.2957,  ..., -1...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[[[tensor([-3.4840, -3.8189, -3.8362,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[[[tensor([ 0.1566, -0.5452, -0.7727,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[[[tensor([ 0.0189,  0.0961,  0.1460,  ..., -0...</td>\n",
              "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[[[tensor([-0.4657, -0.3851, -0.3937,  ..., -0...</td>\n",
              "      <td>[tensor(3), tensor(3), tensor(3), tensor(3), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[[[tensor([-0.4929, -1.3020, -0.6301,  ..., -1...</td>\n",
              "      <td>[tensor(4), tensor(4), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[[[tensor([-0.1002, -0.3673, -0.5454,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[[[tensor([-0.2988, -0.2988, -0.4285,  ...,  1...</td>\n",
              "      <td>[tensor(1), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[[[tensor([-1.3228, -1.3563, -1.3396,  ..., -0...</td>\n",
              "      <td>[tensor(3), tensor(3), tensor(3), tensor(3), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[[[tensor([0.6152, 0.6326, 0.5561,  ..., 0.076...</td>\n",
              "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[[[tensor([ 0.4595,  0.6037,  0.9991,  ...,  0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[[[tensor([-1.0940, -0.7996, -0.9276,  ..., -1...</td>\n",
              "      <td>[tensor(0), tensor(0), tensor(0), tensor(0), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[[[tensor([-0.2927, -0.2080, -0.3106,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(3), tensor(3), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[[[tensor([ 0.1554,  0.1907,  0.1413,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[[[tensor([-1.3128, -1.7088, -1.6777,  ..., -0...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(2), tensor(2), t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[[[tensor([ 0.1039, -0.0427, -0.8616,  ..., -1...</td>\n",
              "      <td>[tensor(2), tensor(2), tensor(4), tensor(4), t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    0                                                  1\n",
              "0   [[[tensor([ 0.3842,  0.8294,  1.0075,  ..., -0...  [tensor(0), tensor(0), tensor(0), tensor(0), t...\n",
              "1   [[[tensor([-0.8096, -0.5088, -0.0043,  ...,  0...  [tensor(4), tensor(4), tensor(4), tensor(4), t...\n",
              "2   [[[tensor([-0.9429, -0.8522, -0.7240,  ...,  0...  [tensor(3), tensor(3), tensor(3), tensor(3), t...\n",
              "3   [[[tensor([0.6978, 1.4083, 1.7688,  ..., 0.803...  [tensor(0), tensor(0), tensor(0), tensor(0), t...\n",
              "4   [[[tensor([ 0.5288,  0.5753,  0.6863,  ..., -1...  [tensor(3), tensor(3), tensor(3), tensor(3), t...\n",
              "5   [[[tensor([0.4944, 0.6718, 0.5796,  ..., 0.437...  [tensor(2), tensor(2), tensor(2), tensor(1), t...\n",
              "6   [[[tensor([-0.8107, -1.0677, -1.1036,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "7   [[[tensor([0.6215, 1.1584, 1.5782,  ..., 1.915...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "8   [[[tensor([ 0.6945,  0.2766, -0.0764,  ...,  0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "9   [[[tensor([0.4592, 0.4426, 0.4842,  ..., 0.800...  [tensor(4), tensor(0), tensor(1), tensor(2), t...\n",
              "10  [[[tensor([ 0.1073,  0.1550,  0.2451,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(3), t...\n",
              "11  [[[tensor([ 3.8256e-02, -5.0368e-02,  2.7431e-...  [tensor(1), tensor(2), tensor(2), tensor(2), t...\n",
              "12  [[[tensor([ 1.3807,  1.4557,  1.5608,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(3), t...\n",
              "13  [[[tensor([ 0.2945,  0.1529, -0.3722,  ...,  0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "14  [[[tensor([-0.9781, -1.0938, -1.0533,  ..., -0...  [tensor(2), tensor(2), tensor(3), tensor(2), t...\n",
              "15  [[[tensor([ 0.0792,  0.5837,  0.4124,  ..., -0...  [tensor(0), tensor(0), tensor(0), tensor(0), t...\n",
              "16  [[[tensor([-0.2651, -0.7041, -0.4992,  ...,  0...  [tensor(2), tensor(4), tensor(4), tensor(4), t...\n",
              "17  [[[tensor([-0.2677, -0.2284, -0.0579,  ..., -0...  [tensor(1), tensor(1), tensor(2), tensor(2), t...\n",
              "18  [[[tensor([-1.0933, -1.0227, -0.7504,  ...,  0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "19  [[[tensor([ 1.2154,  1.1756,  0.8277,  ...,  0...  [tensor(4), tensor(4), tensor(4), tensor(4), t...\n",
              "20  [[[tensor([0.1735, 0.3565, 0.3220,  ..., 0.271...  [tensor(0), tensor(0), tensor(0), tensor(0), t...\n",
              "21  [[[tensor([-3.1622, -2.9935, -2.4406,  ...,  1...  [tensor(4), tensor(4), tensor(4), tensor(4), t...\n",
              "22  [[[tensor([-0.7350, -0.6467, -0.3084,  ...,  0...  [tensor(4), tensor(4), tensor(4), tensor(4), t...\n",
              "23  [[[tensor([ 0.4735,  0.7754,  0.2957,  ..., -1...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "24  [[[tensor([-3.4840, -3.8189, -3.8362,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "25  [[[tensor([ 0.1566, -0.5452, -0.7727,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "26  [[[tensor([ 0.0189,  0.0961,  0.1460,  ..., -0...  [tensor(0), tensor(0), tensor(0), tensor(0), t...\n",
              "27  [[[tensor([-0.4657, -0.3851, -0.3937,  ..., -0...  [tensor(3), tensor(3), tensor(3), tensor(3), t...\n",
              "28  [[[tensor([-0.4929, -1.3020, -0.6301,  ..., -1...  [tensor(4), tensor(4), tensor(4), tensor(4), t...\n",
              "29  [[[tensor([-0.1002, -0.3673, -0.5454,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "30  [[[tensor([-0.2988, -0.2988, -0.4285,  ...,  1...  [tensor(1), tensor(0), tensor(0), tensor(0), t...\n",
              "31  [[[tensor([-1.3228, -1.3563, -1.3396,  ..., -0...  [tensor(3), tensor(3), tensor(3), tensor(3), t...\n",
              "32  [[[tensor([0.6152, 0.6326, 0.5561,  ..., 0.076...  [tensor(1), tensor(1), tensor(1), tensor(1), t...\n",
              "33  [[[tensor([ 0.4595,  0.6037,  0.9991,  ...,  0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "34  [[[tensor([-1.0940, -0.7996, -0.9276,  ..., -1...  [tensor(0), tensor(0), tensor(0), tensor(0), t...\n",
              "35  [[[tensor([-0.2927, -0.2080, -0.3106,  ..., -0...  [tensor(2), tensor(3), tensor(3), tensor(2), t...\n",
              "36  [[[tensor([ 0.1554,  0.1907,  0.1413,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "37  [[[tensor([-1.3128, -1.7088, -1.6777,  ..., -0...  [tensor(2), tensor(2), tensor(2), tensor(2), t...\n",
              "38  [[[tensor([ 0.1039, -0.0427, -0.8616,  ..., -1...  [tensor(2), tensor(2), tensor(4), tensor(4), t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf0KbN9JeXtY",
        "outputId": "fda4eb12-325d-4cda-956a-caaf65073984"
      },
      "source": [
        "x = []\n",
        "for i in range(145):\n",
        "    x.append([])\n",
        "data = np.random.rand(2,145,3000, 1)\n",
        "for data_vector in data:\n",
        "    for index in range(145):\n",
        "        x[index].append(data_vector[index])  \n",
        "   \n",
        "y = np.random.rand(2,39)\n",
        "print('x',np.asarray(x).shape)\n",
        "print('y',y.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x (145, 2, 3000, 1)\n",
            "y (2, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilholpqDfFiH"
      },
      "source": [
        "import tensorflow as tf\n",
        "#Considering y variable holds numpy array\n",
        "y_tensor = tf.convert_to_tensor(train_y, dtype=tf.string) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-cXioTQgFMA",
        "outputId": "cde842dd-243b-47da-c752-296fe9155f13"
      },
      "source": [
        "tf.dtypes.as_dtype(y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.string"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g00Fm2zYhcNj",
        "outputId": "eb503652-b7db-4e50-ca2c-d48984962502"
      },
      "source": [
        "tf.dtypes.as_dtype(train_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.string"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "CI9qAHhvBCin",
        "outputId": "5ef3c3bb-c18e-4c01-fe8b-2b816a569b6b"
      },
      "source": [
        "model.fit(train_x, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-794ffb78f638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(train_x, y_train,\n\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           epochs=epochs)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                **kwargs):\n\u001b[1;32m    262\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    265\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type DataLoader)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUZqg0Wh-T3D"
      },
      "source": [
        "class SleepModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ml_zQ16-qar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xax5tda4ICeB"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class SleepModelRumana(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_channels, sfreq, n_classes=5):\n",
        "        super().__init__()\n",
        "\n",
        "        input_size = int(input_size_s * sfreq)\n",
        "        \n",
        "        len_last_layer = self._len_last_layer(\n",
        "            n_channels, input_size, max_pool_size, n_conv_chs)\n",
        "\n",
        "        if n_channels > 1:\n",
        "            self.spatial_conv = nn.Conv2d(1, n_channels, (n_channels, 1))\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1, max_pool_size)),\n",
        "            nn.Conv2d(\n",
        "                n_conv_chs, n_conv_chs, (1, time_conv_size),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1, max_pool_size))\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(len_last_layer, n_classes)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
        "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass.\n",
        "        \n",
        "        Parameters\n",
        "        ---------\n",
        "        x: torch.Tensor\n",
        "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
        "        \"\"\"\n",
        "        if self.n_channels > 1:\n",
        "            x = self.spatial_conv(x)\n",
        "            x = x.transpose(1, 2)\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        return self.fc(x.flatten(start_dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzIF6iOu3miV",
        "outputId": "ecfba99b-c5f8-4170-ca93-b92f28b002ba"
      },
      "source": [
        "model = Sequential()\n",
        "input_shape=(input_size, 1)\n",
        "model.add(Conv1D(128, kernel_size=3,padding = \"same\",activation=\"relu\", input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(128,kernel_size=3,padding = \"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation=\"tanh\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation=\"tanh\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(16, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 3000, 128)         512       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 3000, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 1500, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 1500, 128)         49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1500, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 750, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 96000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                6144064   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 85        \n",
            "=================================================================\n",
            "Total params: 6,197,573\n",
            "Trainable params: 6,197,061\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuRJIMrQ-Nx5"
      },
      "source": [
        "model = \"sequential_3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "HGqk9OcC-Wev",
        "outputId": "c48a7dc8-b144-4055-c5a1-551bd34b21c8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device 'cuda'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-17c5aa238ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Using device \\'{device}\\'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequential_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sequential_3' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP5KnpGYEb3R",
        "outputId": "8ef4d4b2-1cea-4ed0-cc04-ee7b94f6407d"
      },
      "source": [
        "from torch import nn\n",
        "x = torch.ones((239, 49, 5))\n",
        "x = x.permute((0, 2, 1))  # permuate feature and temporal channels\n",
        "print(x.shape)\n",
        "model = nn.Conv1d(5, 5, 49, groups=5, bias=False)  # remove bias and set window same as whole sequence of temporal data\n",
        "nn.init.constant_(model.weight, 2.)  # set kernel to one (instead of random)\n",
        "output = model(x)\n",
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([239, 5, 49])\n",
            "torch.Size([239, 5, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq4mWk3gKHrp"
      },
      "source": [
        "sfreq = raws[0].info['sfreq']  # Sampling frequency\n",
        "n_channels = raws[0].info['nchan']  # Number of channels\n",
        "input_size_s=30\n",
        "input_size=int(input_size_s * sfreq)\n",
        "n_conv_chs=64\n",
        "time_conv_size_s=0.05\n",
        "max_pool_size_s=0.125\n",
        "n_classes=5\n",
        "dropout=0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ79unX4KpYl",
        "outputId": "4699e24a-d42d-481c-9737-68112661b1b3"
      },
      "source": [
        "n_channels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_1FosLXKse4",
        "outputId": "e9282627-649c-4fcf-83c3-986cd09907e1"
      },
      "source": [
        "sfreq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN3mFYV2K1k-"
      },
      "source": [
        "time_conv_size = int(time_conv_size_s * sfreq)\n",
        "max_pool_size = int(max_pool_size_s * sfreq)\n",
        "input_size = int(input_size_s * sfreq)\n",
        "pad_size = time_conv_size // 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGn8KpjwLC3F",
        "outputId": "ba1752b7-7435-4a64-ae94-9c13c2353b0f"
      },
      "source": [
        "pad_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S0GUisCLA2k",
        "outputId": "24d93b65-504d-4803-8a15-85c574fd87ad"
      },
      "source": [
        "input_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApCZ3m9kK5nT",
        "outputId": "34725ab1-bde2-4df1-eb4d-1319d6d3f219"
      },
      "source": [
        "time_conv_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVroy-GrK8Zz",
        "outputId": "fe842795-77de-4a22-fbe1-61474606c66a"
      },
      "source": [
        "max_pool_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S74LULgLauC",
        "outputId": "afb7ecb5-4cb6-4b36-c801-511d17826d6b"
      },
      "source": [
        "nn.Conv2d(1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 8, kernel_size=(1, 50), stride=(1, 1), padding=(0, 25))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9EcuWpORx-j"
      },
      "source": [
        "x=torch.ones(3000,1,1,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ1gtieWLpBU"
      },
      "source": [
        "model=nn.Conv1d(1, n_conv_chs, (1, time_conv_size), padding=(0, pad_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YC4CKV5RVkl"
      },
      "source": [
        "output = model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMEDPTjXRFDg",
        "outputId": "1b41fc85-b41e-4845-a449-1e643bcd5ef7"
      },
      "source": [
        "print(output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3000, 64, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O836dfXTTdG0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udzrhD_XTdpX"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class SleepStageRumana(nn.Module):\n",
        "    \"\"\"Sleep staging architecture from [1]_.\n",
        "    \n",
        "    Convolutional neural network for sleep staging described in [1]_.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_channels : int\n",
        "        Number of EEG channels.\n",
        "    sfreq : float\n",
        "        EEG sampling frequency.\n",
        "    n_conv_chs : int\n",
        "        Number of convolutional channels. Set to 8 in [1]_.\n",
        "    time_conv_size_s : float\n",
        "        Size of filters in temporal convolution layers, in seconds. Set to 0.5\n",
        "        in [1]_ (64 samples at sfreq=128).\n",
        "    max_pool_size_s : float\n",
        "        Max pooling size, in seconds. Set to 0.125 in [1]_ (16 samples at\n",
        "        sfreq=128).\n",
        "    n_classes : int\n",
        "        Number of classes.\n",
        "    input_size_s : float\n",
        "        Size of the input, in seconds.\n",
        "    dropout : float\n",
        "        Dropout rate before the output dense layer.\n",
        "        \n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Chambon, S., Galtier, M. N., Arnal, P. J., Wainrib, G., &\n",
        "           Gramfort, A. (2018). A deep learning architecture for temporal sleep\n",
        "           stage classification using multivariate and multimodal time series.\n",
        "           IEEE Transactions on Neural Systems and Rehabilitation Engineering,\n",
        "           26(4), 758-769.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_channels, sfreq, n_conv_chs=64, time_conv_size_s=0.5,\n",
        "                 max_pool_size_s=0.125, n_classes=5, input_size_s=30,\n",
        "                 dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        time_conv_size = int(time_conv_size_s * sfreq)\n",
        "        max_pool_size = 2\n",
        "        input_size = int(input_size_s * sfreq)\n",
        "        pad_size = time_conv_size // 2\n",
        "        self.n_channels = n_channels\n",
        "        len_last_layer = self._len_last_layer(\n",
        "            n_channels, input_size, max_pool_size, n_conv_chs)\n",
        "\n",
        "        if n_channels > 1:\n",
        "            self.spatial_conv = nn.Conv2d(1, n_channels, (n_channels, 1))\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                1, 64, (1, 5),stride=3,  padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                64, 128, (1, 5), padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1,2), stride=2),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Conv2d(\n",
        "                128, 256, (1, 13),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                256, 256, (1, 7),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1,2), stride=2),\n",
        "            nn.Conv2d(\n",
        "                256, 128, (1, 7),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                128, 64, (1, 4),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1,2), stride=2),\n",
        "            nn.Conv2d(\n",
        "                64, 32, (1, 3),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                32, 64, (1, 6),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1,2), stride=2),\n",
        "            nn.Conv2d(\n",
        "                64, 8, (1, 5),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(\n",
        "                8, 8, (1, 2),\n",
        "                padding=(0, pad_size)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1,2), stride=2),\n",
        "           \n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1, n_classes)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _len_last_layer(n_channels, input_size, max_pool_size, n_conv_chs):\n",
        "        return n_channels * (input_size // (max_pool_size ** 2)) * n_conv_chs\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass.\n",
        "        \n",
        "        Parameters\n",
        "        ---------\n",
        "        x: torch.Tensor\n",
        "            Batch of EEG windows of shape (batch_size, n_channels, n_times).\n",
        "        \"\"\"\n",
        "        if self.n_channels > 1:\n",
        "            x = self.spatial_conv(x)\n",
        "            x = x.transpose(1, 2)\n",
        "\n",
        "        x = self.feature_extractor(x)\n",
        "        return self.fc(x.flatten(start_dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5Amp7dESg_PT",
        "outputId": "3530b48e-d753-4117-ec56-55a74814b6ef"
      },
      "source": [
        "sfreq = raws[0].info['sfreq']  # Sampling frequency\n",
        "n_channels = raws[0].info['nchan']  # Number of channels\n",
        "\n",
        "model = SleepStageRumana(n_channels, sfreq, n_classes=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9b37e50c7704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfreq'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Sampling frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nchan'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Number of channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSleepStageRumana\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raws' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO9yFanthObn",
        "outputId": "7dd343f8-9492-4bbc-f246-042738254786"
      },
      "source": [
        "print(f'Using device \\'{device}\\'.')\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device 'cpu'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O2DH6FshUsH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJOzP4dRICeC"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create dataloaders\n",
        "train_batch_size = 128  # Important hyperparameter\n",
        "valid_batch_size = 256  # Can be made as large as what fits in memory; won't impact performance\n",
        "num_workers = 0  # Number of processes to use for the data loading process; 0 is the main Python process\n",
        "\n",
        "loader_train = DataLoader(\n",
        "    train_ds, batch_size=train_batch_size, shuffle=True, num_workers=num_workers)\n",
        "loader_valid = DataLoader(\n",
        "    valid_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)\n",
        "loader_test = DataLoader(\n",
        "    test_ds, batch_size=valid_batch_size, shuffle=False, num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCVpJjeThb9t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el-kdSBaICeC"
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score\n",
        "\n",
        "def _do_train(model, loader, optimizer, criterion, device, metric):\n",
        "    # training loop\n",
        "    model.train()\n",
        "    \n",
        "    train_loss = np.zeros(len(loader))\n",
        "    y_pred_all, y_true_all = list(), list()\n",
        "    for idx_batch, (batch_x, batch_y) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "        batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "        y_true_all.append(batch_y.cpu().numpy())\n",
        "\n",
        "        train_loss[idx_batch] = loss.item()\n",
        "        \n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    perf = metric(y_true, y_pred)\n",
        "    \n",
        "    return np.mean(train_loss), perf\n",
        "        \n",
        "\n",
        "def _validate(model, loader, criterion, device, metric):\n",
        "    # validation loop\n",
        "    model.eval()\n",
        "    \n",
        "    val_loss = np.zeros(len(loader))\n",
        "    y_pred_all, y_true_all = list(), list()\n",
        "    with torch.no_grad():\n",
        "        for idx_batch, (batch_x, batch_y) in enumerate(loader):\n",
        "            batch_x = batch_x.to(device=device, dtype=torch.float32)\n",
        "            batch_y = batch_y.to(device=device, dtype=torch.int64)\n",
        "            output = model.forward(batch_x)\n",
        "\n",
        "            loss = criterion(output, batch_y)\n",
        "            val_loss[idx_batch] = loss.item()\n",
        "            \n",
        "            y_pred_all.append(torch.argmax(output, axis=1).cpu().numpy())\n",
        "            y_true_all.append(batch_y.cpu().numpy())\n",
        "            \n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    perf = metric(y_true, y_pred)\n",
        "\n",
        "    return np.mean(val_loss), perf\n",
        "\n",
        "\n",
        "def train(model, loader_train, loader_valid, optimizer, criterion, n_epochs, \n",
        "          patience, device, metric=None):\n",
        "    \"\"\"Training function.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : instance of nn.Module\n",
        "        The model.\n",
        "    loader_train : instance of Sampler\n",
        "        The generator of EEG samples the model has to train on.\n",
        "        It contains n_train samples\n",
        "    loader_valid : instance of Sampler\n",
        "        The generator of EEG samples the model has to validate on.\n",
        "        It contains n_val samples. The validation samples are used to\n",
        "        monitor the training process and to perform early stopping\n",
        "    optimizer : instance of optimizer\n",
        "        The optimizer to use for training.\n",
        "    n_epochs : int\n",
        "        The maximum of epochs to run.\n",
        "    patience : int\n",
        "        The patience parameter, i.e. how long to wait for the\n",
        "        validation error to go down.\n",
        "    metric : None | callable\n",
        "        Metric to use to evaluate performance on the training and\n",
        "        validation sets. Defaults to balanced accuracy.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    best_model : instance of nn.Module\n",
        "        The model that led to the best prediction on the validation\n",
        "        dataset.\n",
        "    history : list of dicts\n",
        "        Training history (loss, accuracy, etc.)\n",
        "    \"\"\"\n",
        "    best_valid_loss = np.inf\n",
        "    best_model = copy.deepcopy(model)\n",
        "    waiting = 0\n",
        "    history = list()\n",
        "    \n",
        "    if metric is None:\n",
        "        metric = balanced_accuracy_score\n",
        "        \n",
        "    print('epoch \\t train_loss \\t valid_loss \\t train_perf \\t valid_perf')\n",
        "    print('-------------------------------------------------------------------')\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train_loss, train_perf = _do_train(\n",
        "            model, loader_train, optimizer, criterion, device, metric=metric)\n",
        "        valid_loss, valid_perf = _validate(\n",
        "            model, loader_valid, criterion, device, metric=metric)\n",
        "        history.append(\n",
        "            {'epoch': epoch, \n",
        "             'train_loss': train_loss, 'valid_loss': valid_loss,\n",
        "             'train_perf': train_perf, 'valid_perf': valid_perf})\n",
        "        \n",
        "        print(f'{epoch} \\t {train_loss:0.4f} \\t {valid_loss:0.4f} '\n",
        "              f'\\t {train_perf:0.4f} \\t {valid_perf:0.4f}')\n",
        "\n",
        "        # model saving\n",
        "        if valid_loss < best_valid_loss:\n",
        "            print(f'best val loss {best_valid_loss:.4f} -> {valid_loss:.4f}')\n",
        "            best_valid_loss = valid_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            waiting = 0\n",
        "        else:\n",
        "            waiting += 1\n",
        "\n",
        "        # model early stopping\n",
        "        if waiting >= patience:\n",
        "            print(f'Stop training at epoch {epoch}')\n",
        "            print(f'Best val loss : {best_valid_loss:.4f}')\n",
        "            break\n",
        "\n",
        "    return best_model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHDmdvLMhjv0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AaX3mQFICeE"
      },
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=0)\n",
        "criterion = CrossEntropyLoss(weight=torch.Tensor(class_weights).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp9i2Ugvhou9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1mY8XklICeE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "0b3a74d8-9acf-4676-a0a6-d53d991ea19b"
      },
      "source": [
        "n_epochs = 10\n",
        "patience = 5\n",
        "\n",
        "best_model, history = train(\n",
        "    model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience, \n",
        "    device, metric=cohen_kappa_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch \t train_loss \t valid_loss \t train_perf \t valid_perf\n",
            "-------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-c9eea2261246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m best_model, history = train(\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     device, metric=cohen_kappa_score)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-184-c75ad8f2ddf6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, loader_valid, optimizer, criterion, n_epochs, patience, device, metric)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         train_loss, train_perf = _do_train(\n\u001b[0;32m--> 104\u001b[0;31m             model, loader_train, optimizer, criterion, device, metric=metric)\n\u001b[0m\u001b[1;32m    105\u001b[0m         valid_loss, valid_perf = _validate(\n\u001b[1;32m    106\u001b[0m             model, loader_valid, criterion, device, metric=metric)\n",
            "\u001b[0;32m<ipython-input-184-c75ad8f2ddf6>\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(model, loader, optimizer, criterion, device, metric)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-188-37ff71198b04>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x960 and 1x64)"
          ]
        }
      ]
    }
  ]
}